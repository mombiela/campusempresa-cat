<!DOCTYPE html>
<html lang="ca">
<head>
    <title> Aprenentatge per Reforç amb PyTorch </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, nofollow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/pytorch/06-02-reinforcement-learning" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/pytorch/06-02-reinforcement-learning" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/pytorch/06-02-reinforcement-learning" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.188a386f47.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "ca";
  		var CATEGORY = "frameworks";
  		var MOD_NAME = "pytorch";
  		var TEMA_NAME = "6-2";
  		var TYPE = "mod";
  		var PATH = "mod/pytorch/06-02-reinforcement-learning";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo_header.png" alt="Logo Campus Empresa"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/pytorch/06-02-reinforcement-learning" class="px-2">EN</a></b>
	|
	<a href="https://campusempresa.com/cursos/pytorch/06-02-reinforcement-learning" class="px-2">ES</a></b>
	|
	<b class="px-2">CA</b>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Tot el coneixement al teu abast</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objectiu" rel="nofollow">El Projecte</a> | 
<a href="/sobre-nosaltres" rel="nofollow">Sobre nosaltres</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donacions</a> | 
<a href="/llicencia" rel="nofollow">Llicència</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/els-meus-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Els meus cursos</b></i>
</a>
<a href="/cursos-finalitzats" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalitzats             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="pytorch">
		<a  href="#" class="text-secondary d-none" data-read-mod="pytorch" data-read-unit="6-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar com a llegit
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="pytorch" data-unread-unit="6-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar com a no llegit
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contingut del curs
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-01-gans' title="Xarxes Generatives Adversàries (GANs)" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-01-gans' title="Xarxes Generatives Adversàries (GANs)" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Aprenentatge per Reforç amb PyTorch</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-03-deploying-models' title="Desplegament de Models PyTorch" class="py-2 px-3 btn btn-primary"
				data-read-mod="pytorch" data-read-unit="6-2">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-03-deploying-models' title="Desplegament de Models PyTorch" class="py-2 px-3 btn btn-primary" 
				data-read-mod="pytorch" data-read-unit="6-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h2>Introducció</h2>
<div class='content'><p>L'aprenentatge per reforç (RL) és una branca de l'aprenentatge automàtic on un agent aprèn a prendre decisions mitjançant la interacció amb un entorn. L'objectiu és maximitzar una recompensa acumulada al llarg del temps. En aquest mòdul, explorarem els conceptes bàsics de l'aprenentatge per reforç i com implementar-lo utilitzant PyTorch.</p>
</div><h2>Conceptes Clau</h2>
<div class='content'><ol>
<li><strong>Agent</strong>: L'entitat que pren decisions.</li>
<li><strong>Entorn</strong>: El món amb el qual l'agent interactua.</li>
<li><strong>Acció (A)</strong>: Les decisions que l'agent pot prendre.</li>
<li><strong>Estat (S)</strong>: La representació de la situació actual de l'entorn.</li>
<li><strong>Recompensa (R)</strong>: El feedback que l'agent rep després de prendre una acció.</li>
<li><strong>Política (π)</strong>: La funció que l'agent utilitza per decidir quina acció prendre en cada estat.</li>
<li><strong>Funció de valor (V)</strong>: Una funció que estima la recompensa esperada a llarg termini des d'un estat donat.</li>
</ol>
</div><h2>Implementació d'un Agent de Q-Learning amb PyTorch</h2>
<div class='content'></div><h3>Pas 1: Configuració de l'Entorn</h3>
<div class='content'><p>Utilitzarem <code>gym</code>, una biblioteca popular per a l'aprenentatge per reforç, per crear el nostre entorn.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGd5bQppbXBvcnQgdG9yY2gKaW1wb3J0IHRvcmNoLm5uIGFzIG5uCmltcG9ydCB0b3JjaC5vcHRpbSBhcyBvcHRpbQppbXBvcnQgbnVtcHkgYXMgbnAKCiMgQ3JlZW0gbCdlbnRvcm4KZW52ID0gZ3ltLm1ha2UoJ0NhcnRQb2xlLXYxJyk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import gym
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np

# Creem l'entorn
env = gym.make('CartPole-v1')</pre></div><div class='content'></div><h3>Pas 2: Definició de la Xarxa Neuronal</h3>
<div class='content'><p>Definirem una xarxa neuronal simple per estimar la funció Q.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("Y2xhc3MgUU5ldHdvcmsobm4uTW9kdWxlKToKICAgIGRlZiBfX2luaXRfXyhzZWxmLCBzdGF0ZV9zaXplLCBhY3Rpb25fc2l6ZSk6CiAgICAgICAgc3VwZXIoUU5ldHdvcmssIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLmZjMSA9IG5uLkxpbmVhcihzdGF0ZV9zaXplLCA2NCkKICAgICAgICBzZWxmLmZjMiA9IG5uLkxpbmVhcig2NCwgNjQpCiAgICAgICAgc2VsZi5mYzMgPSBubi5MaW5lYXIoNjQsIGFjdGlvbl9zaXplKQogICAgCiAgICBkZWYgZm9yd2FyZChzZWxmLCB4KToKICAgICAgICB4ID0gdG9yY2gucmVsdShzZWxmLmZjMSh4KSkKICAgICAgICB4ID0gdG9yY2gucmVsdShzZWxmLmZjMih4KSkKICAgICAgICB4ID0gc2VsZi5mYzMoeCkKICAgICAgICByZXR1cm4geAoKc3RhdGVfc2l6ZSA9IGVudi5vYnNlcnZhdGlvbl9zcGFjZS5zaGFwZVswXQphY3Rpb25fc2l6ZSA9IGVudi5hY3Rpb25fc3BhY2UubgpxX25ldHdvcmsgPSBRTmV0d29yayhzdGF0ZV9zaXplLCBhY3Rpb25fc2l6ZSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>class QNetwork(nn.Module):
    def __init__(self, state_size, action_size):
        super(QNetwork, self).__init__()
        self.fc1 = nn.Linear(state_size, 64)
        self.fc2 = nn.Linear(64, 64)
        self.fc3 = nn.Linear(64, action_size)
    
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

state_size = env.observation_space.shape[0]
action_size = env.action_space.n
q_network = QNetwork(state_size, action_size)</pre></div><div class='content'></div><h3>Pas 3: Definició de la Política d'Exploració</h3>
<div class='content'><p>Utilitzarem una política epsilon-greedy per equilibrar l'exploració i l'explotació.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGVwc2lsb25fZ3JlZWR5X3BvbGljeShzdGF0ZSwgZXBzaWxvbik6CiAgICBpZiBucC5yYW5kb20ucmFuZCgpIDwgZXBzaWxvbjoKICAgICAgICByZXR1cm4gZW52LmFjdGlvbl9zcGFjZS5zYW1wbGUoKSAgIyBFeHBsb3JhY2nDswogICAgZWxzZToKICAgICAgICBzdGF0ZSA9IHRvcmNoLkZsb2F0VGVuc29yKHN0YXRlKS51bnNxdWVlemUoMCkKICAgICAgICBxX3ZhbHVlcyA9IHFfbmV0d29yayhzdGF0ZSkKICAgICAgICByZXR1cm4gdG9yY2guYXJnbWF4KHFfdmFsdWVzKS5pdGVtKCkgICMgRXhwbG90YWNpw7M="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def epsilon_greedy_policy(state, epsilon):
    if np.random.rand() &lt; epsilon:
        return env.action_space.sample()  # Exploraci&oacute;
    else:
        state = torch.FloatTensor(state).unsqueeze(0)
        q_values = q_network(state)
        return torch.argmax(q_values).item()  # Explotaci&oacute;</pre></div><div class='content'></div><h3>Pas 4: Entrenament de l'Agent</h3>
<div class='content'><p>Definirem el bucle d'entrenament per actualitzar la xarxa neuronal.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("b3B0aW1pemVyID0gb3B0aW0uQWRhbShxX25ldHdvcmsucGFyYW1ldGVycygpLCBscj0wLjAwMSkKY3JpdGVyaW9uID0gbm4uTVNFTG9zcygpCgpudW1fZXBpc29kZXMgPSAxMDAwCmdhbW1hID0gMC45OQplcHNpbG9uID0gMS4wCmVwc2lsb25fZGVjYXkgPSAwLjk5NQptaW5fZXBzaWxvbiA9IDAuMDEKCmZvciBlcGlzb2RlIGluIHJhbmdlKG51bV9lcGlzb2Rlcyk6CiAgICBzdGF0ZSA9IGVudi5yZXNldCgpCiAgICB0b3RhbF9yZXdhcmQgPSAwCiAgICAKICAgIGZvciB0IGluIHJhbmdlKDIwMCk6CiAgICAgICAgYWN0aW9uID0gZXBzaWxvbl9ncmVlZHlfcG9saWN5KHN0YXRlLCBlcHNpbG9uKQogICAgICAgIG5leHRfc3RhdGUsIHJld2FyZCwgZG9uZSwgXyA9IGVudi5zdGVwKGFjdGlvbikKICAgICAgICB0b3RhbF9yZXdhcmQgKz0gcmV3YXJkCiAgICAgICAgCiAgICAgICAgIyBDYWxjdWxhIGVsIHZhbG9yIG9iamVjdGl1CiAgICAgICAgbmV4dF9zdGF0ZSA9IHRvcmNoLkZsb2F0VGVuc29yKG5leHRfc3RhdGUpLnVuc3F1ZWV6ZSgwKQogICAgICAgIHRhcmdldCA9IHJld2FyZCArIGdhbW1hICogdG9yY2gubWF4KHFfbmV0d29yayhuZXh0X3N0YXRlKSkuaXRlbSgpICogKDEgLSBkb25lKQogICAgICAgIAogICAgICAgICMgQWN0dWFsaXR6YSBsYSB4YXJ4YSBuZXVyb25hbAogICAgICAgIHN0YXRlID0gdG9yY2guRmxvYXRUZW5zb3Ioc3RhdGUpLnVuc3F1ZWV6ZSgwKQogICAgICAgIHFfdmFsdWVzID0gcV9uZXR3b3JrKHN0YXRlKQogICAgICAgIHRhcmdldF9mID0gcV92YWx1ZXMuY2xvbmUoKQogICAgICAgIHRhcmdldF9mWzBdW2FjdGlvbl0gPSB0YXJnZXQKICAgICAgICAKICAgICAgICBvcHRpbWl6ZXIuemVyb19ncmFkKCkKICAgICAgICBsb3NzID0gY3JpdGVyaW9uKHFfdmFsdWVzLCB0YXJnZXRfZikKICAgICAgICBsb3NzLmJhY2t3YXJkKCkKICAgICAgICBvcHRpbWl6ZXIuc3RlcCgpCiAgICAgICAgCiAgICAgICAgc3RhdGUgPSBuZXh0X3N0YXRlLnNxdWVlemUoMCkubnVtcHkoKQogICAgICAgIAogICAgICAgIGlmIGRvbmU6CiAgICAgICAgICAgIGJyZWFrCiAgICAKICAgIGVwc2lsb24gPSBtYXgobWluX2Vwc2lsb24sIGVwc2lsb24gKiBlcHNpbG9uX2RlY2F5KQogICAgcHJpbnQoZidFcGlzb2RpIHtlcGlzb2RlKzF9L3tudW1fZXBpc29kZXN9LCBSZWNvbXBlbnNhOiB7dG90YWxfcmV3YXJkfSwgRXBzaWxvbjoge2Vwc2lsb246LjJmfScp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>optimizer = optim.Adam(q_network.parameters(), lr=0.001)
criterion = nn.MSELoss()

num_episodes = 1000
gamma = 0.99
epsilon = 1.0
epsilon_decay = 0.995
min_epsilon = 0.01

for episode in range(num_episodes):
    state = env.reset()
    total_reward = 0
    
    for t in range(200):
        action = epsilon_greedy_policy(state, epsilon)
        next_state, reward, done, _ = env.step(action)
        total_reward += reward
        
        # Calcula el valor objectiu
        next_state = torch.FloatTensor(next_state).unsqueeze(0)
        target = reward + gamma * torch.max(q_network(next_state)).item() * (1 - done)
        
        # Actualitza la xarxa neuronal
        state = torch.FloatTensor(state).unsqueeze(0)
        q_values = q_network(state)
        target_f = q_values.clone()
        target_f[0][action] = target
        
        optimizer.zero_grad()
        loss = criterion(q_values, target_f)
        loss.backward()
        optimizer.step()
        
        state = next_state.squeeze(0).numpy()
        
        if done:
            break
    
    epsilon = max(min_epsilon, epsilon * epsilon_decay)
    print(f'Episodi {episode+1}/{num_episodes}, Recompensa: {total_reward}, Epsilon: {epsilon:.2f}')</pre></div><div class='content'></div><h3>Pas 5: Validació de l'Agent</h3>
<div class='content'><p>Després de l'entrenament, validarem l'agent per veure com de bé ha après a jugar.</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("c3RhdGUgPSBlbnYucmVzZXQoKQp0b3RhbF9yZXdhcmQgPSAwCgpmb3IgdCBpbiByYW5nZSgyMDApOgogICAgZW52LnJlbmRlcigpCiAgICBhY3Rpb24gPSBlcHNpbG9uX2dyZWVkeV9wb2xpY3koc3RhdGUsIDAuMDEpICAjIFV0aWxpdHplbSB1biBlcHNpbG9uIG1vbHQgYmFpeCBwZXIgbWF4aW1pdHphciBsJ2V4cGxvdGFjacOzCiAgICBuZXh0X3N0YXRlLCByZXdhcmQsIGRvbmUsIF8gPSBlbnYuc3RlcChhY3Rpb24pCiAgICB0b3RhbF9yZXdhcmQgKz0gcmV3YXJkCiAgICBzdGF0ZSA9IG5leHRfc3RhdGUKICAgIAogICAgaWYgZG9uZToKICAgICAgICBicmVhawoKcHJpbnQoZidSZWNvbXBlbnNhIHRvdGFsIGR1cmFudCBsYSB2YWxpZGFjacOzOiB7dG90YWxfcmV3YXJkfScpCmVudi5jbG9zZSgp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>state = env.reset()
total_reward = 0

for t in range(200):
    env.render()
    action = epsilon_greedy_policy(state, 0.01)  # Utilitzem un epsilon molt baix per maximitzar l'explotaci&oacute;
    next_state, reward, done, _ = env.step(action)
    total_reward += reward
    state = next_state
    
    if done:
        break

print(f'Recompensa total durant la validaci&oacute;: {total_reward}')
env.close()</pre></div><div class='content'></div><h2>Exercicis Pràctics</h2>
<div class='content'><ol>
<li><strong>Modifica la Xarxa Neuronal</strong>: Prova d'afegir més capes o canviar la mida de les capes existents per veure com afecta el rendiment de l'agent.</li>
<li><strong>Canvia l'Entorn</strong>: Utilitza un entorn diferent de <code>gym</code> i adapta el codi per entrenar l'agent en aquest nou entorn.</li>
<li><strong>Implementa DQN</strong>: Implementa Deep Q-Learning Network (DQN) amb una xarxa de target per millorar l'estabilitat de l'entrenament.</li>
</ol>
</div><h2>Conclusió</h2>
<div class='content'><p>En aquest mòdul, hem après els conceptes bàsics de l'aprenentatge per reforç i hem implementat un agent de Q-Learning utilitzant PyTorch. Hem explorat com definir una xarxa neuronal, una política d'exploració i com entrenar l'agent. Els exercicis pràctics proporcionats us ajudaran a aprofundir en aquests conceptes i a experimentar amb diferents configuracions.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-01-gans' title="Xarxes Generatives Adversàries (GANs)" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-01-gans' title="Xarxes Generatives Adversàries (GANs)" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='06-03-deploying-models' title="Desplegament de Models PyTorch" class="py-2 px-3 btn btn-primary"
				data-read-mod="pytorch" data-read-unit="6-2">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='06-03-deploying-models' title="Desplegament de Models PyTorch" class="py-2 px-3 btn btn-primary" 
				data-read-mod="pytorch" data-read-unit="6-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>PyTorch: De Principiant a Avançat</h1>
<h2>Mòdul 1: Introducció a PyTorch</h2>
<ul>
<li><a href="01-01-what-is-pytorch">Què és PyTorch?</a></li>
<li><a href="01-02-setting-up-environment">Configuració de l'Entorn</a></li>
<li><a href="01-03-basic-tensor-operations">Operacions Bàsiques amb Tensor</a></li>
<li><a href="01-04-autograd">Autograd: Diferenciació Automàtica</a></li>
</ul>
<h2>Mòdul 2: Construcció de Xarxes Neuronals</h2>
<ul>
<li><a href="02-01-introduction-to-neural-networks">Introducció a les Xarxes Neuronals</a></li>
<li><a href="02-02-creating-simple-neural-network">Creació d'una Xarxa Neuronal Simple</a></li>
<li><a href="02-03-activation-functions">Funcions d'Activació</a></li>
<li><a href="02-04-loss-functions-optimization">Funcions de Pèrdua i Optimització</a></li>
</ul>
<h2>Mòdul 3: Entrenament de Xarxes Neuronals</h2>
<ul>
<li><a href="03-01-data-loading-preprocessing">Càrrega i Preprocessament de Dades</a></li>
<li><a href="03-02-training-loop">Bucle d'Entrenament</a></li>
<li><a href="03-03-validation-testing">Validació i Prova</a></li>
<li><a href="03-04-saving-loading-models">Desament i Càrrega de Models</a></li>
</ul>
<h2>Mòdul 4: Xarxes Neuronals Convolucionals (CNNs)</h2>
<ul>
<li><a href="04-01-introduction-to-cnns">Introducció a les CNNs</a></li>
<li><a href="04-02-building-cnn-from-scratch">Construcció d'una CNN des de Zero</a></li>
<li><a href="04-03-transfer-learning">Aprenentatge per Transferència amb Models Preentrenats</a></li>
<li><a href="04-04-fine-tuning-cnns">Ajust Fi de les CNNs</a></li>
</ul>
<h2>Mòdul 5: Xarxes Neuronals Recurrents (RNNs)</h2>
<ul>
<li><a href="05-01-introduction-to-rnns">Introducció a les RNNs</a></li>
<li><a href="05-02-building-rnn-from-scratch">Construcció d'una RNN des de Zero</a></li>
<li><a href="05-03-lstm-networks">Xarxes de Memòria a Llarg i Curt Termini (LSTM)</a></li>
<li><a href="05-04-gru-networks">Unitats Recurrents Gated (GRUs)</a></li>
</ul>
<h2>Mòdul 6: Temes Avançats</h2>
<ul>
<li><a href="06-01-gans">Xarxes Generatives Adversàries (GANs)</a></li>
<li><a href="06-02-reinforcement-learning">Aprenentatge per Reforç amb PyTorch</a></li>
<li><a href="06-03-deploying-models">Desplegament de Models PyTorch</a></li>
<li><a href="06-04-optimizing-performance">Optimització del Rendiment</a></li>
</ul>
<h2>Mòdul 7: Estudis de Cas i Projectes</h2>
<ul>
<li><a href="07-01-image-classification-project">Projecte de Classificació d'Imatges</a></li>
<li><a href="07-02-nlp-project">Projecte de Processament del Llenguatge Natural</a></li>
<li><a href="07-03-time-series-forecasting-project">Projecte de Predicció de Sèries Temporals</a></li>
<li><a href="07-04-custom-project">Projecte Personalitzat</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objectiu" rel="nofollow">El Projecte</a> | 
<a href="/sobre-nosaltres" rel="nofollow">Sobre nosaltres</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donacions</a> | 
<a href="/llicencia" rel="nofollow">Llicència</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuari no autentificat</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
