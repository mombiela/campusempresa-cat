<!DOCTYPE html>
<html lang="ca">
<head>
    <title> Autoencoders </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/deep-learning/05-02-autoencoders" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/deep-learning/05-02-autoencoders" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/deep-learning/05-02-autoencoders" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "ca";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "deep_learning";
  		var TEMA_NAME = "5-2";
  		var TYPE = "mod";
  		var PATH = "mod/deep_learning/05-02-autoencoders";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.902a5a267d.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo_header.png" alt="Logo Campus Empresa"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/deep-learning/05-02-autoencoders" class="px-2">EN</a></b>
	|
	<a href="https://campusempresa.com/cursos/deep-learning/05-02-autoencoders" class="px-2">ES</a></b>
	|
	<b class="px-2">CA</b>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Tot el coneixement al teu abast</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objectiu" rel="nofollow">El Projecte</a> | 
<a href="/sobre-nosaltres" rel="nofollow">Sobre nosaltres</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donacions</a> | 
<a href="/llicencia" rel="nofollow">Llicència</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/els-meus-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Els meus cursos</b></i>
</a>
<a href="/cursos-finalitzats" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalitzats             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="deep_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="deep_learning" data-read-unit="5-2" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar com a llegit
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="deep_learning" data-unread-unit="5-2" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar com a no llegit
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contingut del curs
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-01-redes-generativas-adversariales' title="Xarxes Generatives Adversarials (GAN)" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-01-redes-generativas-adversariales' title="Xarxes Generatives Adversarials (GAN)" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Autoencoders</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="5-2">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="5-2">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h2>Introducció als Autoencoders</h2>
<div class='content'><p>Els autoencoders són un tipus de xarxa neuronal utilitzada per aprendre representacions eficients (codificacions) d'un conjunt de dades, típicament per a la reducció de dimensionalitat o per a la detecció d'anomalies. La idea principal darrere dels autoencoders és aprendre una representació comprimida (codificació) de les dades d'entrada i després reconstruir-les a partir d'aquesta codificació.</p>
</div><h3>Components d'un Autoencoder</h3>
<div class='content'><p>Un autoencoder consta de dues parts principals:</p>
<ol>
<li><strong>Codificador (Encoder)</strong>: Transforma l'entrada en una representació comprimida.</li>
<li><strong>Decodificador (Decoder)</strong>: Reconstrueix l'entrada original a partir de la representació comprimida.</li>
</ol>
</div><h3>Arquitectura Bàsica</h3>
<div class='content'><p>L'arquitectura bàsica d'un autoencoder es pot representar de la següent manera:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("RW50cmFkYSAtPiBDb2RpZmljYWRvciAtPiBDb2RpZmljYWNpw7MgKExhdGVudCBTcGFjZSkgLT4gRGVjb2RpZmljYWRvciAtPiBTb3J0aWRhIChSZWNvbnN0cnVjdGVkIElucHV0KQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>Entrada -&gt; Codificador -&gt; Codificaci&oacute; (Latent Space) -&gt; Decodificador -&gt; Sortida (Reconstructed Input)</pre></div><div class='content'></div><h3>Funció de Pèrdua</h3>
<div class='content'><p>La funció de pèrdua en un autoencoder mesura la diferència entre l'entrada original i la sortida reconstruïda. La funció de pèrdua més comuna és l'error quadràtic mitjà (MSE):</p>
<p>\[ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \hat{x}_i)^2 \]</p>
<p>on \( x_i \) és l'entrada original i \( \hat{x}_i \) és la sortida reconstruïda.</p>
</div><h2>Tipus d'Autoencoders</h2>
<div class='content'></div><h3>Autoencoders Clàssics</h3>
<div class='content'><p>Els autoencoders clàssics tenen una estructura simètrica amb el mateix nombre de neurones a les capes d'entrada i sortida. La capa latent té menys neurones que les capes d'entrada i sortida, forçant així la xarxa a aprendre una representació comprimida.</p>
</div><h3>Variational Autoencoders (VAE)</h3>
<div class='content'><p>Els VAE són una variant dels autoencoders que imposen una distribució probabilística sobre la capa latent. Això permet generar noves dades similars a les dades d'entrenament.</p>
</div><h3>Denoising Autoencoders</h3>
<div class='content'><p>Els denoising autoencoders estan dissenyats per eliminar el soroll de les dades. S'entrenen amb dades sorolloses com a entrada i dades netes com a sortida.</p>
</div><h3>Sparse Autoencoders</h3>
<div class='content'><p>Els sparse autoencoders imposen una penalització de sparsity (escassetat) a la capa latent, forçant la xarxa a aprendre representacions on només unes poques unitats estan actives alhora.</p>
</div><h2>Exemple Pràctic amb Keras</h2>
<div class='content'><p>A continuació, es presenta un exemple pràctic d'un autoencoder simple utilitzant Keras:</p>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmZyb20ga2VyYXMubGF5ZXJzIGltcG9ydCBJbnB1dCwgRGVuc2UKZnJvbSBrZXJhcy5tb2RlbHMgaW1wb3J0IE1vZGVsCmZyb20ga2VyYXMuZGF0YXNldHMgaW1wb3J0IG1uaXN0CgojIENhcnJlZ2FyIGxlcyBkYWRlcyBkZSBNTklTVAooeF90cmFpbiwgXyksICh4X3Rlc3QsIF8pID0gbW5pc3QubG9hZF9kYXRhKCkKeF90cmFpbiA9IHhfdHJhaW4uYXN0eXBlKCdmbG9hdDMyJykgLyAyNTUuCnhfdGVzdCA9IHhfdGVzdC5hc3R5cGUoJ2Zsb2F0MzInKSAvIDI1NS4KeF90cmFpbiA9IHhfdHJhaW4ucmVzaGFwZSgobGVuKHhfdHJhaW4pLCBucC5wcm9kKHhfdHJhaW4uc2hhcGVbMTpdKSkpCnhfdGVzdCA9IHhfdGVzdC5yZXNoYXBlKChsZW4oeF90ZXN0KSwgbnAucHJvZCh4X3Rlc3Quc2hhcGVbMTpdKSkpCgojIERpbWVuc2lvbnMgZGUgbCdlbnRyYWRhCmlucHV0X2RpbSA9IHhfdHJhaW4uc2hhcGVbMV0KZW5jb2RpbmdfZGltID0gMzIgICMgRGltZW5zaW9uYWxpdGF0IGRlIGxhIGNhcGEgbGF0ZW50CgojIERlZmluaXIgZWwgbW9kZWwKaW5wdXRfaW1nID0gSW5wdXQoc2hhcGU9KGlucHV0X2RpbSwpKQplbmNvZGVkID0gRGVuc2UoZW5jb2RpbmdfZGltLCBhY3RpdmF0aW9uPSdyZWx1JykoaW5wdXRfaW1nKQpkZWNvZGVkID0gRGVuc2UoaW5wdXRfZGltLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykoZW5jb2RlZCkKCiMgQ3JlYXIgbCdhdXRvZW5jb2RlcgphdXRvZW5jb2RlciA9IE1vZGVsKGlucHV0X2ltZywgZGVjb2RlZCkKCiMgQ29tcGlsYXIgZWwgbW9kZWwKYXV0b2VuY29kZXIuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdiaW5hcnlfY3Jvc3NlbnRyb3B5JykKCiMgRW50cmVuYXIgbCdhdXRvZW5jb2RlcgphdXRvZW5jb2Rlci5maXQoeF90cmFpbiwgeF90cmFpbiwKICAgICAgICAgICAgICAgIGVwb2Nocz01MCwKICAgICAgICAgICAgICAgIGJhdGNoX3NpemU9MjU2LAogICAgICAgICAgICAgICAgc2h1ZmZsZT1UcnVlLAogICAgICAgICAgICAgICAgdmFsaWRhdGlvbl9kYXRhPSh4X3Rlc3QsIHhfdGVzdCkpCgojIENvZGlmaWNhZG9yIHBlciBvYnRlbmlyIGxlcyByZXByZXNlbnRhY2lvbnMgY29tcHJpbWlkZXMKZW5jb2RlciA9IE1vZGVsKGlucHV0X2ltZywgZW5jb2RlZCkKCiMgRGVjb2RpZmljYWRvciBwZXIgcmVjb25zdHJ1aXIgbGVzIGltYXRnZXMKZW5jb2RlZF9pbnB1dCA9IElucHV0KHNoYXBlPShlbmNvZGluZ19kaW0sKSkKZGVjb2Rlcl9sYXllciA9IGF1dG9lbmNvZGVyLmxheWVyc1stMV0KZGVjb2RlciA9IE1vZGVsKGVuY29kZWRfaW5wdXQsIGRlY29kZXJfbGF5ZXIoZW5jb2RlZF9pbnB1dCkpCgojIENvZGlmaWNhciBpIGRlY29kaWZpY2FyIGFsZ3VuZXMgaW1hdGdlcwplbmNvZGVkX2ltZ3MgPSBlbmNvZGVyLnByZWRpY3QoeF90ZXN0KQpkZWNvZGVkX2ltZ3MgPSBkZWNvZGVyLnByZWRpY3QoZW5jb2RlZF9pbWdzKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
from keras.layers import Input, Dense
from keras.models import Model
from keras.datasets import mnist

# Carregar les dades de MNIST
(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))

# Dimensions de l'entrada
input_dim = x_train.shape[1]
encoding_dim = 32  # Dimensionalitat de la capa latent

# Definir el model
input_img = Input(shape=(input_dim,))
encoded = Dense(encoding_dim, activation='relu')(input_img)
decoded = Dense(input_dim, activation='sigmoid')(encoded)

# Crear l'autoencoder
autoencoder = Model(input_img, decoded)

# Compilar el model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Entrenar l'autoencoder
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))

# Codificador per obtenir les representacions comprimides
encoder = Model(input_img, encoded)

# Decodificador per reconstruir les imatges
encoded_input = Input(shape=(encoding_dim,))
decoder_layer = autoencoder.layers[-1]
decoder = Model(encoded_input, decoder_layer(encoded_input))

# Codificar i decodificar algunes imatges
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)</pre></div><div class='content'></div><h3>Explicació del Codi</h3>
<div class='content'><ol>
<li><strong>Carregar les dades</strong>: Es carreguen les dades de MNIST i es normalitzen.</li>
<li><strong>Definir el model</strong>: Es defineix l'arquitectura de l'autoencoder amb una capa d'entrada, una capa latent (codificador) i una capa de sortida (decodificador).</li>
<li><strong>Compilar el model</strong>: Es compila el model amb l'optimitzador 'adam' i la funció de pèrdua 'binary_crossentropy'.</li>
<li><strong>Entrenar l'autoencoder</strong>: Es realitza l'entrenament de l'autoencoder amb les dades d'entrenament.</li>
<li><strong>Codificador i Decodificador</strong>: Es defineixen models separats per al codificador i el decodificador per obtenir les representacions comprimides i reconstruir les imatges.</li>
</ol>
</div><h2>Exercici Pràctic</h2>
<div class='content'></div><h3>Objectiu</h3>
<div class='content'><p>Crear un autoencoder per reduir la dimensionalitat de les dades de MNIST i visualitzar les representacions comprimides.</p>
</div><h3>Passos</h3>
<div class='content'><ol>
<li>Carregar les dades de MNIST.</li>
<li>Definir l'arquitectura de l'autoencoder.</li>
<li>Entrenar l'autoencoder.</li>
<li>Visualitzar les representacions comprimides utilitzant tècniques de visualització com PCA o t-SNE.</li>
</ol>
</div><h3>Solució</h3>
<div class='content'></div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG1hdHBsb3RsaWIucHlwbG90IGFzIHBsdApmcm9tIHNrbGVhcm4ubWFuaWZvbGQgaW1wb3J0IFRTTkUKCiMgVmlzdWFsaXR6YXIgbGVzIHJlcHJlc2VudGFjaW9ucyBjb21wcmltaWRlcwplbmNvZGVkX2ltZ3MgPSBlbmNvZGVyLnByZWRpY3QoeF90ZXN0KQoKIyBVdGlsaXR6YXIgdC1TTkUgcGVyIHJlZHVpciBsYSBkaW1lbnNpb25hbGl0YXQgYSAyRAp0c25lID0gVFNORShuX2NvbXBvbmVudHM9MiwgcmFuZG9tX3N0YXRlPTApCmVuY29kZWRfaW1nc18yZCA9IHRzbmUuZml0X3RyYW5zZm9ybShlbmNvZGVkX2ltZ3MpCgojIFZpc3VhbGl0emFyIGxlcyByZXByZXNlbnRhY2lvbnMgY29tcHJpbWlkZXMKcGx0LmZpZ3VyZShmaWdzaXplPSg2LCA2KSkKcGx0LnNjYXR0ZXIoZW5jb2RlZF9pbWdzXzJkWzosIDBdLCBlbmNvZGVkX2ltZ3NfMmRbOiwgMV0sIGM9eV90ZXN0LCBjbWFwPSd2aXJpZGlzJykKcGx0LmNvbG9yYmFyKCkKcGx0LnNob3coKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# Visualitzar les representacions comprimides
encoded_imgs = encoder.predict(x_test)

# Utilitzar t-SNE per reduir la dimensionalitat a 2D
tsne = TSNE(n_components=2, random_state=0)
encoded_imgs_2d = tsne.fit_transform(encoded_imgs)

# Visualitzar les representacions comprimides
plt.figure(figsize=(6, 6))
plt.scatter(encoded_imgs_2d[:, 0], encoded_imgs_2d[:, 1], c=y_test, cmap='viridis')
plt.colorbar()
plt.show()</pre></div><div class='content'></div><h3>Explicació del Codi</h3>
<div class='content'><ol>
<li><strong>Visualitzar les representacions comprimides</strong>: Es codifiquen les imatges de test utilitzant el codificador.</li>
<li><strong>t-SNE</strong>: Es redueix la dimensionalitat de les representacions comprimides a 2D utilitzant t-SNE.</li>
<li><strong>Visualització</strong>: Es visualitzen les representacions comprimides en un gràfic de dispersió.</li>
</ol>
</div><h2>Conclusió</h2>
<div class='content'><p>Els autoencoders són una eina poderosa per a la reducció de dimensionalitat i la detecció d'anomalies. Amb una comprensió clara de la seva arquitectura i funcionament, es poden aplicar a una àmplia varietat de problemes en el camp del deep learning.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='05-01-redes-generativas-adversariales' title="Xarxes Generatives Adversarials (GAN)" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='05-01-redes-generativas-adversariales' title="Xarxes Generatives Adversarials (GAN)" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="5-2">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='05-03-transfer-learning' title="Transfer Learning" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="5-2">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curs de Deep Learning</h1>
<h2>Mòdul 1: Introducció a Deep Learning</h2>
<ul>
<li><a href="01-01-que-es-deep-learning">Què és Deep Learning?</a></li>
<li><a href="01-02-historia-evolucion-deep-learning">Història i evolució del Deep Learning</a></li>
<li><a href="01-03-aplicaciones-deep-learning">Aplicacions de Deep Learning</a></li>
<li><a href="01-04-conceptos-basicos-redes-neuronales">Conceptes bàsics de xarxes neuronals</a></li>
</ul>
<h2>Mòdul 2: Fonaments de Xarxes Neuronals</h2>
<ul>
<li><a href="02-01-perceptron-perceptron-multicapa">Perceptró i Perceptró Multicapa</a></li>
<li><a href="02-02-funcion-de-activacion">Funció d'activació</a></li>
<li><a href="02-03-propagacion-hacia-adelante-atras">Propagació cap endavant i cap enrere</a></li>
<li><a href="02-04-optimizacion-funcion-de-perdida">Optimització i funció de pèrdua</a></li>
</ul>
<h2>Mòdul 3: Xarxes Neuronals Convolucionals (CNN)</h2>
<ul>
<li><a href="03-01-introduccion-cnn">Introducció a les CNN</a></li>
<li><a href="03-02-capas-convolucionales-pooling">Capes convolutionals i de pooling</a></li>
<li><a href="03-03-arquitecturas-populares-cnn">Arquitectures populars de CNN</a></li>
<li><a href="03-04-aplicaciones-cnn-reconocimiento-imagenes">Aplicacions de CNN en reconeixement d'imatges</a></li>
</ul>
<h2>Mòdul 4: Xarxes Neuronals Recurrentes (RNN)</h2>
<ul>
<li><a href="04-01-introduccion-rnn">Introducció a les RNN</a></li>
<li><a href="04-02-lstm-gru">LSTM i GRU</a></li>
<li><a href="04-03-aplicaciones-rnn-pln">Aplicacions de RNN en processament del llenguatge natural</a></li>
<li><a href="04-04-secuencias-series-temporales">Seqüències i sèries temporals</a></li>
</ul>
<h2>Mòdul 5: Tècniques Avançades en Deep Learning</h2>
<ul>
<li><a href="05-01-redes-generativas-adversariales">Xarxes Generatives Adversarials (GAN)</a></li>
<li><a href="05-02-autoencoders">Autoencoders</a></li>
<li><a href="05-03-transfer-learning">Transfer Learning</a></li>
<li><a href="05-04-regularizacion-tecnicas-mejora">Regularització i tècniques de millora</a></li>
</ul>
<h2>Mòdul 6: Eines i Frameworks</h2>
<ul>
<li><a href="06-01-introduccion-tensorflow">Introducció a TensorFlow</a></li>
<li><a href="06-02-introduccion-pytorch">Introducció a PyTorch</a></li>
<li><a href="06-03-comparacion-frameworks">Comparació de frameworks</a></li>
<li><a href="06-04-entornos-desarrollo-recursos">Entorns de desenvolupament i recursos addicionals</a></li>
</ul>
<h2>Mòdul 7: Projectes Pràctics</h2>
<ul>
<li><a href="07-01-clasificacion-imagenes-cnn">Classificació d'imatges amb CNN</a></li>
<li><a href="07-02-generacion-texto-rnn">Generació de text amb RNN</a></li>
<li><a href="07-03-deteccion-anomalias-autoencoders">Detecció d'anomalies amb Autoencoders</a></li>
<li><a href="07-04-creacion-gan-generacion-imagenes">Creació d'una GAN per generació d'imatges</a></li>
</ul>
<h2>Mòdul 8: Consideracions Ètiques i Futur del Deep Learning</h2>
<ul>
<li><a href="08-01-etica-deep-learning">Ètica en Deep Learning</a></li>
<li><a href="08-02-impacto-social-economico">Impacte social i econòmic</a></li>
<li><a href="08-03-tendencias-futuras-deep-learning">Tendències futures en Deep Learning</a></li>
<li><a href="08-04-desafios-oportunidades">Desafiaments i oportunitats</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objectiu" rel="nofollow">El Projecte</a> | 
<a href="/sobre-nosaltres" rel="nofollow">Sobre nosaltres</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donacions</a> | 
<a href="/llicencia" rel="nofollow">Llicència</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuari no autentificat</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
