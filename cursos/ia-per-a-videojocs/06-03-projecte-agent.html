<!DOCTYPE html>
<html lang="ca">
<head>
    <title> Projecte 3: Desenvolupament d'un Agent amb Aprenentatge Automàtic </title>
        
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    
    <link rel="alternate" href="https://campusempresa.com/cursos/ia-para-videojuegos/06-03-proyecto-agente" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/cursos/ia-per-a-videojocs/06-03-projecte-agent" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/courses/ai-for-video-games/06-03-project-agent" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.1ab297bfa4.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "ca";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "ia_videojuegos";
  		var TEMA_NAME = "6-3";
  		var TYPE = "mod";
  		var PATH = "mod/ia_videojuegos/06-03-projecte-agent";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.e0e4cfcd99.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>
	  	
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-VVPMPJSR3P"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());	
	  gtag('config', 'G-VVPMPJSR3P');
	</script>
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<a href="/"><img src="/img/logo_header.png" alt="Logo Campus Empresa"></a>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/courses/ai-for-video-games/06-03-project-agent" class="px-2">EN</a></b>
	|
	<a href="https://campusempresa.com/cursos/ia-para-videojuegos/06-03-proyecto-agente" class="px-2">ES</a></b>
	|
	<b class="px-2">CA</b>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Tot el coneixement al teu abast</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objectiu" rel="nofollow">El Projecte</a> | 
<a href="/sobre-nosaltres" rel="nofollow">Sobre nosaltres</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donacions</a> | 
<a href="/llicencia" rel="nofollow">Llicència</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/els-meus-cursos" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Els meus cursos</b></i>
</a>
<a href="/cursos-finalitzats" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalitzats             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="ia_videojuegos">
		<a  href="#" class="text-secondary d-none" data-read-mod="ia_videojuegos" data-read-unit="6-3" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar com a llegit
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="ia_videojuegos" data-unread-unit="6-3" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar com a no llegit
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contingut del curs
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-02-projecte-npc' title="Projecte 2: Creació d'un NPC amb Presa de Decisions" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-02-projecte-npc' title="Projecte 2: Creació d'un NPC amb Presa de Decisions" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h1 style="text-decoration:underline">Projecte 3: Desenvolupament d'un Agent amb Aprenentatge Automàtic</h1>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='07-01-llibres-articles' title="Llibres i Articles Recomanats" class="py-2 px-3 btn btn-primary"
				data-read-mod="ia_videojuegos" data-read-unit="6-3">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='07-01-llibres-articles' title="Llibres i Articles Recomanats" class="py-2 px-3 btn btn-primary" 
				data-read-mod="ia_videojuegos" data-read-unit="6-3">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>En aquest projecte, desenvoluparem un agent de joc que utilitza tècniques d'aprenentatge automàtic per millorar el seu comportament a mesura que interactua amb l'entorn. Aquest projecte combinarà conceptes apresos en els mòduls anteriors, especialment del Mòdul 4: Aprenentatge Automàtic.</p>
</div><h2>Objectius del Projecte</h2>
<div class='content'><ol>
<li><strong>Implementar un agent bàsic amb capacitat d'aprenentatge automàtic.</strong></li>
<li><strong>Utilitzar xarxes neuronals per a la presa de decisions.</strong></li>
<li><strong>Aplicar aprenentatge per reforç per millorar el comportament de l'agent.</strong></li>
<li><strong>Integrar l'agent en un entorn de joc i avaluar el seu rendiment.</strong></li>
</ol>
</div><h2>Requisits Previs</h2>
<div class='content'><ul>
<li>Coneixements bàsics de programació en Python.</li>
<li>Familiaritat amb biblioteques d'aprenentatge automàtic com TensorFlow o PyTorch.</li>
<li>Comprensió dels conceptes d'aprenentatge per reforç.</li>
</ul>
</div><h2>Passos del Projecte</h2>
<div class='content'></div><h3><ol>
<li>Definició de l'Entorn de Joc</li>
</ol></h3>
<div class='content'><p>Primer, definirem l'entorn en què l'agent operarà. Per a aquest projecte, utilitzarem un entorn senzill on l'agent ha de trobar un objectiu mentre evita obstacles.</p>
<h4>Exemple de Codi: Definició de l'Entorn</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGd5bQpmcm9tIGd5bSBpbXBvcnQgc3BhY2VzCmltcG9ydCBudW1weSBhcyBucAoKY2xhc3MgU2ltcGxlRW52KGd5bS5FbnYpOgogICAgZGVmIF9faW5pdF9fKHNlbGYpOgogICAgICAgIHN1cGVyKFNpbXBsZUVudiwgc2VsZikuX19pbml0X18oKQogICAgICAgIHNlbGYuYWN0aW9uX3NwYWNlID0gc3BhY2VzLkRpc2NyZXRlKDQpICAjIDQgYWNjaW9uczogYW11bnQsIGF2YWxsLCBlc3F1ZXJyYSwgZHJldGEKICAgICAgICBzZWxmLm9ic2VydmF0aW9uX3NwYWNlID0gc3BhY2VzLkJveChsb3c9MCwgaGlnaD0xMCwgc2hhcGU9KDIsKSwgZHR5cGU9bnAuZmxvYXQzMikKICAgICAgICBzZWxmLnN0YXRlID0gbnAuYXJyYXkoWzUsIDVdKQogICAgICAgIHNlbGYuZ29hbCA9IG5wLmFycmF5KFs5LCA5XSkKICAgICAgICBzZWxmLm9ic3RhY2xlcyA9IFtucC5hcnJheShbMywgM10pLCBucC5hcnJheShbNywgN10pXQoKICAgIGRlZiByZXNldChzZWxmKToKICAgICAgICBzZWxmLnN0YXRlID0gbnAuYXJyYXkoWzUsIDVdKQogICAgICAgIHJldHVybiBzZWxmLnN0YXRlCgogICAgZGVmIHN0ZXAoc2VsZiwgYWN0aW9uKToKICAgICAgICBpZiBhY3Rpb24gPT0gMDoKICAgICAgICAgICAgc2VsZi5zdGF0ZVsxXSArPSAxICAjIGFtdW50CiAgICAgICAgZWxpZiBhY3Rpb24gPT0gMToKICAgICAgICAgICAgc2VsZi5zdGF0ZVsxXSAtPSAxICAjIGF2YWxsCiAgICAgICAgZWxpZiBhY3Rpb24gPT0gMjoKICAgICAgICAgICAgc2VsZi5zdGF0ZVswXSAtPSAxICAjIGVzcXVlcnJhCiAgICAgICAgZWxpZiBhY3Rpb24gPT0gMzoKICAgICAgICAgICAgc2VsZi5zdGF0ZVswXSArPSAxICAjIGRyZXRhCgogICAgICAgIHJld2FyZCA9IC0xCiAgICAgICAgZG9uZSA9IEZhbHNlCiAgICAgICAgaWYgbnAuYXJyYXlfZXF1YWwoc2VsZi5zdGF0ZSwgc2VsZi5nb2FsKToKICAgICAgICAgICAgcmV3YXJkID0gMTAKICAgICAgICAgICAgZG9uZSA9IFRydWUKICAgICAgICBlbGlmIGFueShucC5hcnJheV9lcXVhbChzZWxmLnN0YXRlLCBvYnMpIGZvciBvYnMgaW4gc2VsZi5vYnN0YWNsZXMpOgogICAgICAgICAgICByZXdhcmQgPSAtMTAKICAgICAgICAgICAgZG9uZSA9IFRydWUKCiAgICAgICAgcmV0dXJuIHNlbGYuc3RhdGUsIHJld2FyZCwgZG9uZSwge30KCiAgICBkZWYgcmVuZGVyKHNlbGYpOgogICAgICAgIGdyaWQgPSBucC56ZXJvcygoMTEsIDExKSkKICAgICAgICBncmlkW3NlbGYuc3RhdGVbMF0sIHNlbGYuc3RhdGVbMV1dID0gMQogICAgICAgIGdyaWRbc2VsZi5nb2FsWzBdLCBzZWxmLmdvYWxbMV1dID0gMgogICAgICAgIGZvciBvYnMgaW4gc2VsZi5vYnN0YWNsZXM6CiAgICAgICAgICAgIGdyaWRbb2JzWzBdLCBvYnNbMV1dID0gLTEKICAgICAgICBwcmludChncmlkKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import gym
from gym import spaces
import numpy as np

class SimpleEnv(gym.Env):
    def __init__(self):
        super(SimpleEnv, self).__init__()
        self.action_space = spaces.Discrete(4)  # 4 accions: amunt, avall, esquerra, dreta
        self.observation_space = spaces.Box(low=0, high=10, shape=(2,), dtype=np.float32)
        self.state = np.array([5, 5])
        self.goal = np.array([9, 9])
        self.obstacles = [np.array([3, 3]), np.array([7, 7])]

    def reset(self):
        self.state = np.array([5, 5])
        return self.state

    def step(self, action):
        if action == 0:
            self.state[1] += 1  # amunt
        elif action == 1:
            self.state[1] -= 1  # avall
        elif action == 2:
            self.state[0] -= 1  # esquerra
        elif action == 3:
            self.state[0] += 1  # dreta

        reward = -1
        done = False
        if np.array_equal(self.state, self.goal):
            reward = 10
            done = True
        elif any(np.array_equal(self.state, obs) for obs in self.obstacles):
            reward = -10
            done = True

        return self.state, reward, done, {}

    def render(self):
        grid = np.zeros((11, 11))
        grid[self.state[0], self.state[1]] = 1
        grid[self.goal[0], self.goal[1]] = 2
        for obs in self.obstacles:
            grid[obs[0], obs[1]] = -1
        print(grid)</pre></div><div class='content'></div><h3><ol start="2">
<li>Creació de l'Agent amb Xarxes Neuronals</li>
</ol></h3>
<div class='content'><p>Implementarem una xarxa neuronal que l'agent utilitzarà per prendre decisions basades en l'estat actual de l'entorn.</p>
<h4>Exemple de Codi: Xarxa Neuronal amb TensorFlow</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRlbnNvcmZsb3cgYXMgdGYKZnJvbSB0ZW5zb3JmbG93LmtlcmFzIGltcG9ydCBsYXllcnMKCmRlZiBjcmVhdGVfbW9kZWwoKToKICAgIG1vZGVsID0gdGYua2VyYXMuU2VxdWVudGlhbCgpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDI0LCBpbnB1dF9zaGFwZT0oMiwpLCBhY3RpdmF0aW9uPSdyZWx1JykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDI0LCBhY3RpdmF0aW9uPSdyZWx1JykpCiAgICBtb2RlbC5hZGQobGF5ZXJzLkRlbnNlKDQsIGFjdGl2YXRpb249J2xpbmVhcicpKQogICAgbW9kZWwuY29tcGlsZShvcHRpbWl6ZXI9dGYua2VyYXMub3B0aW1pemVycy5BZGFtKGxlYXJuaW5nX3JhdGU9MC4wMDEpLCBsb3NzPSdtc2UnKQogICAgcmV0dXJuIG1vZGVsCgptb2RlbCA9IGNyZWF0ZV9tb2RlbCgp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import tensorflow as tf
from tensorflow.keras import layers

def create_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(24, input_shape=(2,), activation='relu'))
    model.add(layers.Dense(24, activation='relu'))
    model.add(layers.Dense(4, activation='linear'))
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')
    return model

model = create_model()</pre></div><div class='content'></div><h3><ol start="3">
<li>Implementació de l'Aprenentatge per Reforç</li>
</ol></h3>
<div class='content'><p>Utilitzarem l'algoritme Q-learning amb xarxes neuronals (Deep Q-Learning) per entrenar l'agent.</p>
<h4>Exemple de Codi: Entrenament amb Deep Q-Learning</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("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"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import random
from collections import deque

def train_agent(env, model, episodes=1000, gamma=0.99, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):
    memory = deque(maxlen=2000)
    for episode in range(episodes):
        state = env.reset()
        state = np.reshape(state, [1, 2])
        total_reward = 0
        for time in range(500):
            if np.random.rand() &lt;= epsilon:
                action = random.randrange(4)
            else:
                q_values = model.predict(state)
                action = np.argmax(q_values[0])
            
            next_state, reward, done, _ = env.step(action)
            next_state = np.reshape(next_state, [1, 2])
            memory.append((state, action, reward, next_state, done))
            state = next_state
            total_reward += reward
            
            if done:
                print(f&quot;Episode: {episode}/{episodes}, Score: {total_reward}, Epsilon: {epsilon:.2}&quot;)
                break
            
            if len(memory) &gt; 32:
                minibatch = random.sample(memory, 32)
                for state, action, reward, next_state, done in minibatch:
                    target = reward
                    if not done:
                        target = reward + gamma * np.amax(model.predict(next_state)[0])
                    target_f = model.predict(state)
                    target_f[0][action] = target
                    model.fit(state, target_f, epochs=1, verbose=0)
        
        if epsilon &gt; epsilon_min:
            epsilon *= epsilon_decay

train_agent(env, model)</pre></div><div class='content'></div><h3><ol start="4">
<li>Integració i Avaluació de l'Agent</li>
</ol></h3>
<div class='content'><p>Després d'entrenar l'agent, l'integrarem en l'entorn de joc i avaluarem el seu rendiment.</p>
<h4>Exemple de Codi: Avaluació de l'Agent</h4>
</div><div style='position:relative'><a class='copy_button d-none d-md-inline' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGV2YWx1YXRlX2FnZW50KGVudiwgbW9kZWwsIGVwaXNvZGVzPTEwMCk6CiAgICB0b3RhbF9yZXdhcmRzID0gMAogICAgZm9yIGVwaXNvZGUgaW4gcmFuZ2UoZXBpc29kZXMpOgogICAgICAgIHN0YXRlID0gZW52LnJlc2V0KCkKICAgICAgICBzdGF0ZSA9IG5wLnJlc2hhcGUoc3RhdGUsIFsxLCAyXSkKICAgICAgICBlcGlzb2RlX3Jld2FyZCA9IDAKICAgICAgICBmb3IgdGltZSBpbiByYW5nZSg1MDApOgogICAgICAgICAgICBxX3ZhbHVlcyA9IG1vZGVsLnByZWRpY3Qoc3RhdGUpCiAgICAgICAgICAgIGFjdGlvbiA9IG5wLmFyZ21heChxX3ZhbHVlc1swXSkKICAgICAgICAgICAgbmV4dF9zdGF0ZSwgcmV3YXJkLCBkb25lLCBfID0gZW52LnN0ZXAoYWN0aW9uKQogICAgICAgICAgICBzdGF0ZSA9IG5wLnJlc2hhcGUobmV4dF9zdGF0ZSwgWzEsIDJdKQogICAgICAgICAgICBlcGlzb2RlX3Jld2FyZCArPSByZXdhcmQKICAgICAgICAgICAgaWYgZG9uZToKICAgICAgICAgICAgICAgIGJyZWFrCiAgICAgICAgdG90YWxfcmV3YXJkcyArPSBlcGlzb2RlX3Jld2FyZAogICAgYXZnX3Jld2FyZCA9IHRvdGFsX3Jld2FyZHMgLyBlcGlzb2RlcwogICAgcHJpbnQoZiJBdmVyYWdlIFJld2FyZCBvdmVyIHtlcGlzb2Rlc30gZXBpc29kZXM6IHthdmdfcmV3YXJkfSIpCgpldmFsdWF0ZV9hZ2VudChlbnYsIG1vZGVsKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def evaluate_agent(env, model, episodes=100):
    total_rewards = 0
    for episode in range(episodes):
        state = env.reset()
        state = np.reshape(state, [1, 2])
        episode_reward = 0
        for time in range(500):
            q_values = model.predict(state)
            action = np.argmax(q_values[0])
            next_state, reward, done, _ = env.step(action)
            state = np.reshape(next_state, [1, 2])
            episode_reward += reward
            if done:
                break
        total_rewards += episode_reward
    avg_reward = total_rewards / episodes
    print(f&quot;Average Reward over {episodes} episodes: {avg_reward}&quot;)

evaluate_agent(env, model)</pre></div><div class='content'></div><h2>Conclusió</h2>
<div class='content'><p>En aquest projecte, hem desenvolupat un agent de joc que utilitza tècniques d'aprenentatge automàtic per millorar el seu comportament. Hem definit un entorn de joc, creat una xarxa neuronal per a la presa de decisions, implementat l'aprenentatge per reforç i avaluat el rendiment de l'agent. Aquest projecte proporciona una base sòlida per a desenvolupar agents més complexos i intel·ligents en futurs jocs.</p>
</div><h2>Exercicis Pràctics</h2>
<div class='content'><ol>
<li><strong>Modifica l'entorn de joc per incloure més obstacles i objectius. Com afecta això l'entrenament de l'agent?</strong></li>
<li><strong>Implementa una variant de l'algoritme Deep Q-Learning, com Double DQN, i compara els resultats.</strong></li>
<li><strong>Ajusta els hiperparàmetres de l'algoritme d'aprenentatge per veure com afecten el rendiment de l'agent.</strong></li>
</ol>
</div><h2>Errors Comuns i Consells</h2>
<div class='content'><ul>
<li><strong>Sobreentrenament:</strong> Evita entrenar l'agent durant massa episodis sense variació en l'entorn, ja que pot conduir a sobreentrenament.</li>
<li><strong>Exploració vs. Explotació:</strong> Assegura't de mantenir un bon equilibri entre exploració (provar noves accions) i explotació (utilitzar accions conegudes que donen bons resultats).</li>
<li><strong>Escalatge de les Entrades:</strong> Escala les entrades de l'agent per assegurar-te que la xarxa neuronal pugui aprendre de manera eficient.</li>
</ul>
<p>Amb aquests coneixements i pràctiques, estaràs ben preparat per desenvolupar agents intel·ligents i eficients per als teus propis projectes de videojocs.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='06-02-projecte-npc' title="Projecte 2: Creació d'un NPC amb Presa de Decisions" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='06-02-projecte-npc' title="Projecte 2: Creació d'un NPC amb Presa de Decisions" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='07-01-llibres-articles' title="Llibres i Articles Recomanats" class="py-2 px-3 btn btn-primary"
				data-read-mod="ia_videojuegos" data-read-unit="6-3">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='07-01-llibres-articles' title="Llibres i Articles Recomanats" class="py-2 px-3 btn btn-primary" 
				data-read-mod="ia_videojuegos" data-read-unit="6-3">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>IA per a Videojocs</h1>
<h2>Mòdul 1: Introducció a la IA en Videojocs</h2>
<ul>
<li><a href="01-01-historia-evolucio">Història i Evolució de la IA en Videojocs</a></li>
<li><a href="01-02-conceptes-basics">Conceptes Bàsics de IA</a></li>
<li><a href="01-03-eines-llenguatges">Eines i Llenguatges de Programació</a></li>
</ul>
<h2>Mòdul 2: Navegació en Videojocs</h2>
<ul>
<li><a href="02-01-algoritmes-cerca">Algoritmes de Cerca de Camins</a></li>
<li><a href="02-02-implementacio-a-estrella">Implementació de A*</a></li>
<li><a href="02-03-navegacio-navmesh">Navegació amb NavMesh</a></li>
<li><a href="02-04-evitacio-obstacles">Evitació d'Obstacles</a></li>
</ul>
<h2>Mòdul 3: Presa de Decisions</h2>
<ul>
<li><a href="03-01-maquines-estats-finis">Màquines d'Estats Finits (FSM)</a></li>
<li><a href="03-02-arbres-decisio">Arbres de Decisió</a></li>
<li><a href="03-03-behavior-trees">Behavior Trees</a></li>
<li><a href="03-04-sistemes-regles">Sistemes Basats en Regles</a></li>
</ul>
<h2>Mòdul 4: Aprenentatge Automàtic</h2>
<ul>
<li><a href="04-01-introduccio-aprenentatge">Introducció a l'Aprenentatge Automàtic</a></li>
<li><a href="04-02-xarxes-neuronals">Xarxes Neuronals en Videojocs</a></li>
<li><a href="04-03-aprenentatge-reforc">Aprenentatge per Reforç</a></li>
<li><a href="04-04-implementacio-agent">Implementació d'un Agent d'Aprenentatge</a></li>
</ul>
<h2>Mòdul 5: Integració i Optimització</h2>
<ul>
<li><a href="05-01-integracio-motors">Integració de IA en Motors de Joc</a></li>
<li><a href="05-02-optimitzacio-algoritmes">Optimització d'Algoritmes de IA</a></li>
<li><a href="05-03-proves-depuracio">Proves i Depuració de IA</a></li>
</ul>
<h2>Mòdul 6: Projectes Pràctics</h2>
<ul>
<li><a href="06-01-projecte-navegacio">Projecte 1: Implementació de Navegació Bàsica</a></li>
<li><a href="06-02-projecte-npc">Projecte 2: Creació d'un NPC amb Presa de Decisions</a></li>
<li><a href="06-03-projecte-agent">Projecte 3: Desenvolupament d'un Agent amb Aprenentatge Automàtic</a></li>
</ul>
<h2>Mòdul 7: Recursos Addicionals</h2>
<ul>
<li><a href="07-01-llibres-articles">Llibres i Articles Recomanats</a></li>
<li><a href="07-02-comunitats-forums">Comunitats i Fòrums</a></li>
<li><a href="07-03-eines-llibreries">Eines i Llibreries Útils</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objectiu" rel="nofollow">El Projecte</a> | 
<a href="/sobre-nosaltres" rel="nofollow">Sobre nosaltres</a> | 
<a href="/contribuir" rel="nofollow">Contribuir</a> | 
<a href="/donar" rel="nofollow">Donacions</a> | 
<a href="/llicencia" rel="nofollow">Llicència</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuari no autentificat</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
