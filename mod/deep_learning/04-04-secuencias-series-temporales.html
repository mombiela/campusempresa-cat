<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Seqüències i sèries temporals</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/04-04-secuencias-series-temporales" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/04-04-secuencias-series-temporales" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/04-04-sequences-time-series" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
							<a href="https://enterprisecampus.net/mod/deep_learning/04-04-sequences-time-series" class="px-2">EN</a></b>
				|
				<a href="https://campusempresa.com/mod/deep_learning/04-04-secuencias-series-temporales" class="px-2">ES</a></b>
				|
				<b class="px-2">CA</b>
											</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<!-- <a href="/">Home</a>  -->
									<a href="./">Contingut del curs</a>
					<span class="sep">|</span>
								<a href="/all/competencias">Competències tècniques</a>
				<a href="/all/conocimientos">Coneixements</a>
				<a href="/all/soft_skills">Competències socials</a>
			</div>
		</div>
	</div>
</div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-03-aplicaciones-rnn-pln' title="Aplicacions de RNN en processament del llenguatge natural">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Seqüències i sèries temporals</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-01-redes-generativas-adversariales' title="Xarxes Generatives Adversarials (GAN)">
				<span class="d-none d-md-inline">Següent &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1><p>Introducció</p>
</h1>
<div class='content'><p>Les seqüències i les sèries temporals són dades que es presenten en un ordre específic, normalment en funció del temps. Aquest tipus de dades són comuns en molts camps, com ara la meteorologia, les finances, el processament del llenguatge natural (PLN) i molts altres. En aquest tema, explorarem com les xarxes neuronals recurrents (RNN) poden ser utilitzades per modelar i predir aquestes dades.</p>
</div><h1><p>Conceptes Clau</p>
</h1>
<div class='content'></div><h2><p>Seqüències</p>
</h2>
<div class='content'><ul>
<li><strong>Definició</strong>: Una seqüència és una col·lecció d'elements ordenats, on l'ordre dels elements és important.</li>
<li><strong>Exemples</strong>: Text, seqüències de paraules, seqüències d'ADN.</li>
</ul>
</div><h2><p>Sèries Temporals</p>
</h2>
<div class='content'><ul>
<li><strong>Definició</strong>: Una sèrie temporal és una seqüència d'observacions ordenades en el temps.</li>
<li><strong>Exemples</strong>: Preus d'accions, temperatures diàries, senyals d'àudio.</li>
</ul>
</div><h1><p>Xarxes Neuronals Recurrentes (RNN)</p>
</h1>
<div class='content'><p>Les RNN són especialment adequades per treballar amb dades seqüencials i sèries temporals perquè poden mantenir una &quot;memòria&quot; dels estats anteriors a través de les seves connexions recurrents.</p>
</div><h2><p>Arquitectura Bàsica d'una RNN</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("RW50cmFkYSAoeF90KSAtPiBDYXBhIFJlY3VycmVudCAoaF90KSAtPiBTb3J0aWRhICh5X3Qp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>Entrada (x_t) -&gt; Capa Recurrent (h_t) -&gt; Sortida (y_t)</pre></div><div class='content'><ul>
<li><strong>x_t</strong>: Entrada en el temps t.</li>
<li><strong>h_t</strong>: Estat ocult en el temps t.</li>
<li><strong>y_t</strong>: Sortida en el temps t.</li>
</ul>
</div><h2><p>Propagació cap endavant en una RNN</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIEZ1bmNpw7MgZCdhY3RpdmFjacOzICh0YW5oKQpkZWYgdGFuaCh4KToKICAgIHJldHVybiBucC50YW5oKHgpCgojIEluaWNpYWxpdHphY2nDsyBkZSBwZXNvcwpXeGggPSBucC5yYW5kb20ucmFuZG4oaGlkZGVuX3NpemUsIGlucHV0X3NpemUpICogMC4wMSAgIyBQZXNvcyBlbnRyYWRhIGEgZXN0YXQgb2N1bHQKV2hoID0gbnAucmFuZG9tLnJhbmRuKGhpZGRlbl9zaXplLCBoaWRkZW5fc2l6ZSkgKiAwLjAxICAjIFBlc29zIGVzdGF0IG9jdWx0IGEgZXN0YXQgb2N1bHQKV2h5ID0gbnAucmFuZG9tLnJhbmRuKG91dHB1dF9zaXplLCBoaWRkZW5fc2l6ZSkgKiAwLjAxICAjIFBlc29zIGVzdGF0IG9jdWx0IGEgc29ydGlkYQpiaCA9IG5wLnplcm9zKChoaWRkZW5fc2l6ZSwgMSkpICAjIEJpYXMgZXN0YXQgb2N1bHQKYnkgPSBucC56ZXJvcygob3V0cHV0X3NpemUsIDEpKSAgIyBCaWFzIHNvcnRpZGEKCiMgUHJvcGFnYWNpw7MgY2FwIGVuZGF2YW50CmRlZiBmb3J3YXJkKHgsIGhfcHJldik6CiAgICBoX25leHQgPSB0YW5oKG5wLmRvdChXeGgsIHgpICsgbnAuZG90KFdoaCwgaF9wcmV2KSArIGJoKQogICAgeSA9IG5wLmRvdChXaHksIGhfbmV4dCkgKyBieQogICAgcmV0dXJuIHksIGhfbmV4dA=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Funci&oacute; d'activaci&oacute; (tanh)
def tanh(x):
    return np.tanh(x)

# Inicialitzaci&oacute; de pesos
Wxh = np.random.randn(hidden_size, input_size) * 0.01  # Pesos entrada a estat ocult
Whh = np.random.randn(hidden_size, hidden_size) * 0.01  # Pesos estat ocult a estat ocult
Why = np.random.randn(output_size, hidden_size) * 0.01  # Pesos estat ocult a sortida
bh = np.zeros((hidden_size, 1))  # Bias estat ocult
by = np.zeros((output_size, 1))  # Bias sortida

# Propagaci&oacute; cap endavant
def forward(x, h_prev):
    h_next = tanh(np.dot(Wxh, x) + np.dot(Whh, h_prev) + bh)
    y = np.dot(Why, h_next) + by
    return y, h_next</pre></div><div class='content'></div><h2><p>Long Short-Term Memory (LSTM) i Gated Recurrent Unit (GRU)</p>
</h2>
<div class='content'><p>Les LSTM i les GRU són variants de les RNN que aborden el problema del gradient que desapareix, permetent a les xarxes aprendre dependències a llarg termini.</p>
<h4>LSTM</h4>
<ul>
<li><strong>Components</strong>: Cèl·lula, porta d'entrada, porta de sortida, porta d'oblit.</li>
<li><strong>Avantatges</strong>: Capacitat per recordar informació durant períodes de temps més llargs.</li>
</ul>
<h4>GRU</h4>
<ul>
<li><strong>Components</strong>: Porta de restabliment, porta de posada al dia.</li>
<li><strong>Avantatges</strong>: Més simple que les LSTM, però igualment efectiva en molts casos.</li>
</ul>
</div><h1><p>Aplicacions de RNN en Seqüències i Sèries Temporals</p>
</h1>
<div class='content'></div><h2><p>Predicció de Sèries Temporals</p>
</h2>
<div class='content'><ul>
<li><strong>Objectiu</strong>: Predir valors futurs basats en valors històrics.</li>
<li><strong>Exemple</strong>: Predicció del preu de les accions.</li>
</ul>
</div><h2><p>Processament del Llenguatge Natural (PLN)</p>
</h2>
<div class='content'><ul>
<li><strong>Objectiu</strong>: Modelar i generar text.</li>
<li><strong>Exemple</strong>: Generació automàtica de text, traducció automàtica.</li>
</ul>
</div><h2><p>Reconeixement de Veu</p>
</h2>
<div class='content'><ul>
<li><strong>Objectiu</strong>: Convertir senyals d'àudio en text.</li>
<li><strong>Exemple</strong>: Assistents virtuals com Siri o Google Assistant.</li>
</ul>
</div><h1><p>Exercici Pràctic: Predicció de Sèries Temporals amb RNN</p>
</h1>
<div class='content'></div><h2><p>Descripció de l'Exercici</p>
</h2>
<div class='content'><p>En aquest exercici, utilitzarem una RNN per predir una sèrie temporal senzilla, com ara una funció sinusoïdal.</p>
</div><h2><p>Pas 1: Generació de Dades</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKCiMgR2VuZXJhciBkYWRlcyBzaW51c2/Dr2RhbHMKZGVmIGdlbmVyYXRlX3NpbmVfd2F2ZShzZXFfbGVuZ3RoLCBudW1fc2FtcGxlcyk6CiAgICBYID0gW10KICAgIHkgPSBbXQogICAgZm9yIF8gaW4gcmFuZ2UobnVtX3NhbXBsZXMpOgogICAgICAgIHN0YXJ0ID0gbnAucmFuZG9tLnJhbmQoKSAqIDIgKiBucC5waQogICAgICAgIHggPSBucC5hcnJheShbbnAuc2luKHN0YXJ0ICsgaSkgZm9yIGkgaW4gcmFuZ2Uoc2VxX2xlbmd0aCldKQogICAgICAgIFguYXBwZW5kKHhbOi0xXSkKICAgICAgICB5LmFwcGVuZCh4WzE6XSkKICAgIHJldHVybiBucC5hcnJheShYKSwgbnAuYXJyYXkoeSkKCnNlcV9sZW5ndGggPSA1MApudW1fc2FtcGxlcyA9IDEwMDAKWCwgeSA9IGdlbmVyYXRlX3NpbmVfd2F2ZShzZXFfbGVuZ3RoLCBudW1fc2FtcGxlcykKCiMgVmlzdWFsaXR6YXIgbGVzIGRhZGVzCnBsdC5wbG90KFhbMF0pCnBsdC50aXRsZSgiRXhlbXBsZSBkZSBTZXHDvMOobmNpYSBTaW51c2/Dr2RhbCIpCnBsdC5zaG93KCk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt

# Generar dades sinuso&iuml;dals
def generate_sine_wave(seq_length, num_samples):
    X = []
    y = []
    for _ in range(num_samples):
        start = np.random.rand() * 2 * np.pi
        x = np.array([np.sin(start + i) for i in range(seq_length)])
        X.append(x[:-1])
        y.append(x[1:])
    return np.array(X), np.array(y)

seq_length = 50
num_samples = 1000
X, y = generate_sine_wave(seq_length, num_samples)

# Visualitzar les dades
plt.plot(X[0])
plt.title(&quot;Exemple de Seq&uuml;&egrave;ncia Sinuso&iuml;dal&quot;)
plt.show()</pre></div><div class='content'></div><h2><p>Pas 2: Construcció de la RNN</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoCmltcG9ydCB0b3JjaC5ubiBhcyBubgoKY2xhc3MgU2ltcGxlUk5OKG5uLk1vZHVsZSk6CiAgICBkZWYgX19pbml0X18oc2VsZiwgaW5wdXRfc2l6ZSwgaGlkZGVuX3NpemUsIG91dHB1dF9zaXplKToKICAgICAgICBzdXBlcihTaW1wbGVSTk4sIHNlbGYpLl9faW5pdF9fKCkKICAgICAgICBzZWxmLmhpZGRlbl9zaXplID0gaGlkZGVuX3NpemUKICAgICAgICBzZWxmLnJubiA9IG5uLlJOTihpbnB1dF9zaXplLCBoaWRkZW5fc2l6ZSwgYmF0Y2hfZmlyc3Q9VHJ1ZSkKICAgICAgICBzZWxmLmZjID0gbm4uTGluZWFyKGhpZGRlbl9zaXplLCBvdXRwdXRfc2l6ZSkKICAgIAogICAgZGVmIGZvcndhcmQoc2VsZiwgeCk6CiAgICAgICAgaDAgPSB0b3JjaC56ZXJvcygxLCB4LnNpemUoMCksIHNlbGYuaGlkZGVuX3NpemUpLnRvKHguZGV2aWNlKQogICAgICAgIG91dCwgXyA9IHNlbGYucm5uKHgsIGgwKQogICAgICAgIG91dCA9IHNlbGYuZmMob3V0KQogICAgICAgIHJldHVybiBvdXQKCmlucHV0X3NpemUgPSAxCmhpZGRlbl9zaXplID0gNTAKb3V0cHV0X3NpemUgPSAxCgptb2RlbCA9IFNpbXBsZVJOTihpbnB1dF9zaXplLCBoaWRkZW5fc2l6ZSwgb3V0cHV0X3NpemUp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch
import torch.nn as nn

class SimpleRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SimpleRNN, self).__init__()
        self.hidden_size = hidden_size
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)
    
    def forward(self, x):
        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.rnn(x, h0)
        out = self.fc(out)
        return out

input_size = 1
hidden_size = 50
output_size = 1

model = SimpleRNN(input_size, hidden_size, output_size)</pre></div><div class='content'></div><h2><p>Pas 3: Entrenament del Model</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IHRvcmNoLm9wdGltIGFzIG9wdGltCgojIENvbnZlcnRpciBkYWRlcyBhIHRlbnNvcnMKWF90ZW5zb3IgPSB0b3JjaC50ZW5zb3IoWCwgZHR5cGU9dG9yY2guZmxvYXQzMikudW5zcXVlZXplKC0xKQp5X3RlbnNvciA9IHRvcmNoLnRlbnNvcih5LCBkdHlwZT10b3JjaC5mbG9hdDMyKS51bnNxdWVlemUoLTEpCgojIERlZmluaXIgcMOocmR1YSBpIG9wdGltaXR6YWRvcgpjcml0ZXJpb24gPSBubi5NU0VMb3NzKCkKb3B0aW1pemVyID0gb3B0aW0uQWRhbShtb2RlbC5wYXJhbWV0ZXJzKCksIGxyPTAuMDEpCgojIEVudHJlbmFtZW50Cm51bV9lcG9jaHMgPSAxMDAKZm9yIGVwb2NoIGluIHJhbmdlKG51bV9lcG9jaHMpOgogICAgbW9kZWwudHJhaW4oKQogICAgb3V0cHV0ID0gbW9kZWwoWF90ZW5zb3IpCiAgICBsb3NzID0gY3JpdGVyaW9uKG91dHB1dCwgeV90ZW5zb3IpCiAgICAKICAgIG9wdGltaXplci56ZXJvX2dyYWQoKQogICAgbG9zcy5iYWNrd2FyZCgpCiAgICBvcHRpbWl6ZXIuc3RlcCgpCiAgICAKICAgIGlmIChlcG9jaCsxKSAlIDEwID09IDA6CiAgICAgICAgcHJpbnQoZidFcG9jaCBbe2Vwb2NoKzF9L3tudW1fZXBvY2hzfV0sIExvc3M6IHtsb3NzLml0ZW0oKTouNGZ9Jyk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import torch.optim as optim

# Convertir dades a tensors
X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(-1)
y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(-1)

# Definir p&egrave;rdua i optimitzador
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# Entrenament
num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    output = model(X_tensor)
    loss = criterion(output, y_tensor)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if (epoch+1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')</pre></div><div class='content'></div><h2><p>Pas 4: Avaluació del Model</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBQcmVkaWNjacOzCm1vZGVsLmV2YWwoKQp3aXRoIHRvcmNoLm5vX2dyYWQoKToKICAgIHByZWRpY3RlZCA9IG1vZGVsKFhfdGVuc29yKS5zcXVlZXplKC0xKS5udW1weSgpCgojIFZpc3VhbGl0emFyIHJlc3VsdGF0cwpwbHQucGxvdCh5WzBdLCBsYWJlbD0nUmVhbCcpCnBsdC5wbG90KHByZWRpY3RlZFswXSwgbGFiZWw9J1ByZWRpY2Npw7MnKQpwbHQudGl0bGUoIlByZWRpY2Npw7MgZGUgbGEgU8OocmllIFRlbXBvcmFsIikKcGx0LmxlZ2VuZCgpCnBsdC5zaG93KCk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Predicci&oacute;
model.eval()
with torch.no_grad():
    predicted = model(X_tensor).squeeze(-1).numpy()

# Visualitzar resultats
plt.plot(y[0], label='Real')
plt.plot(predicted[0], label='Predicci&oacute;')
plt.title(&quot;Predicci&oacute; de la S&egrave;rie Temporal&quot;)
plt.legend()
plt.show()</pre></div><div class='content'></div><h1><p>Conclusió</p>
</h1>
<div class='content'><p>En aquest tema, hem explorat com les RNN poden ser utilitzades per modelar i predir seqüències i sèries temporals. Hem vist la importància de les RNN en el processament de dades seqüencials i hem implementat un exemple pràctic de predicció de sèries temporals utilitzant PyTorch. Aquest coneixement és fonamental per abordar problemes complexos en camps com el PLN, la predicció financera i el reconeixement de veu.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-03-aplicaciones-rnn-pln' title="Aplicacions de RNN en processament del llenguatge natural">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-01-redes-generativas-adversariales' title="Xarxes Generatives Adversarials (GAN)">
				<span class="d-none d-md-inline">Següent &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
