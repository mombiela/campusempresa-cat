<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    <title>Optimització i funció de pèrdua</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/02-04-optimizacion-funcion-de-perdida" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/02-04-optimizacion-funcion-de-perdida" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/02-04-optimization-loss-function" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "ca";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "deep_learning";
  		var TEMA_NAME = "2-4";
  		var TYPE = "mod";
  		var PATH = "mod/deep_learning/02-04-optimizacion-funcion-de-perdida";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.86da6c742a.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/deep_learning/02-04-optimization-loss-function" class="px-2">EN</a></b>
	|
	<a href="https://campusempresa.com/mod/deep_learning/02-04-optimizacion-funcion-de-perdida" class="px-2">ES</a></b>
	|
	<b class="px-2">CA</b>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Tot el coneixement al teu abast</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my_modules" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Els meus cursos</b></i>
</a>
<a href="/end_modules" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalitzats             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="deep_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="deep_learning" data-read-unit="2-4" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar com a llegit
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="deep_learning" data-unread-unit="2-4" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar com a no llegit
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contingut del curs
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='02-03-propagacion-hacia-adelante-atras' title="Propagació cap endavant i cap enrere" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='02-03-propagacion-hacia-adelante-atras' title="Propagació cap endavant i cap enrere" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Optimització i funció de pèrdua</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='03-01-introduccion-cnn' title="Introducció a les CNN" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="2-4">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='03-01-introduccion-cnn' title="Introducció a les CNN" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="2-4">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'></div><h1>Introducció</h1>
<div class='content'><p>En aquest tema, explorarem els conceptes d'optimització i funció de pèrdua, que són fonamentals per entrenar xarxes neuronals. La funció de pèrdua mesura com de bé està funcionant el model, mentre que els algoritmes d'optimització ajusten els pesos del model per minimitzar aquesta pèrdua.</p>
</div><h1>Conceptes Clau</h1>
<div class='content'></div><h2>Funció de Pèrdua</h2>
<div class='content'><p>La funció de pèrdua (o funció de cost) és una mètrica que quantifica la discrepància entre les prediccions del model i els valors reals. L'objectiu de l'entrenament és minimitzar aquesta pèrdua.</p>
<h4>Tipus de Funcions de Pèrdua</h4>
<ol>
<li>
<p><strong>Error Quadràtic Mitjà (MSE)</strong>:
\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]
Utilitzada principalment en problemes de regressió.</p>
</li>
<li>
<p><strong>Entropia Creuada (Cross-Entropy)</strong>:
\[
L = -\frac{1}{n} \sum_{i=1}^{n} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
\]
Utilitzada en problemes de classificació binària.</p>
</li>
<li>
<p><strong>Entropia Creuada Categòrica</strong>:
\[
L = -\sum_{i=1}^{n} \sum_{j=1}^{k} y_{ij} \log(\hat{y}_{ij})
\]
Utilitzada en problemes de classificació multiclasse.</p>
</li>
</ol>
</div><h2>Algoritmes d'Optimització</h2>
<div class='content'><p>Els algoritmes d'optimització ajusten els pesos del model per minimitzar la funció de pèrdua. Els més comuns són:</p>
<ol>
<li>
<p><strong>Gradient Descent</strong>:
\[
\theta = \theta - \alpha \nabla_\theta J(\theta)
\]
On \(\theta\) són els pesos del model, \(\alpha\) és la taxa d'aprenentatge, i \(\nabla_\theta J(\theta)\) és el gradient de la funció de pèrdua respecte als pesos.</p>
</li>
<li>
<p><strong>Stochastic Gradient Descent (SGD)</strong>:
Actualitza els pesos utilitzant un sol exemple de dades a cada iteració, el que pot accelerar l'entrenament però introduir més variabilitat.</p>
</li>
<li>
<p><strong>Mini-batch Gradient Descent</strong>:
Una combinació de Gradient Descent i SGD, utilitzant petits lots de dades per actualitzar els pesos.</p>
</li>
<li>
<p><strong>Optimitzadors Avançats</strong>:</p>
<ul>
<li><strong>Adam</strong>: Combina les millors propietats de AdaGrad i RMSProp.</li>
<li><strong>RMSProp</strong>: Ajusta la taxa d'aprenentatge per cada paràmetre.</li>
<li><strong>AdaGrad</strong>: Ajusta la taxa d'aprenentatge basant-se en la freqüència de les actualitzacions dels pesos.</li>
</ul>
</li>
</ol>
</div><h1>Exemples Pràctics</h1>
<div class='content'></div><h2>Implementació de la Funció de Pèrdua i Optimització en Python</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIEZ1bmNpw7MgZGUgcMOocmR1YSBNU0UKZGVmIG1zZV9sb3NzKHlfdHJ1ZSwgeV9wcmVkKToKICAgIHJldHVybiBucC5tZWFuKCh5X3RydWUgLSB5X3ByZWQpICoqIDIpCgojIEdyYWRpZW50IERlc2NlbnQKZGVmIGdyYWRpZW50X2Rlc2NlbnQoWCwgeSwgbGVhcm5pbmdfcmF0ZT0wLjAxLCBlcG9jaHM9MTAwMCk6CiAgICBtLCBuID0gWC5zaGFwZQogICAgdGhldGEgPSBucC56ZXJvcyhuKQogICAgZm9yIGVwb2NoIGluIHJhbmdlKGVwb2Nocyk6CiAgICAgICAgeV9wcmVkID0gWC5kb3QodGhldGEpCiAgICAgICAgbG9zcyA9IG1zZV9sb3NzKHksIHlfcHJlZCkKICAgICAgICBncmFkaWVudCA9ICgyL20pICogWC5ULmRvdCh5X3ByZWQgLSB5KQogICAgICAgIHRoZXRhIC09IGxlYXJuaW5nX3JhdGUgKiBncmFkaWVudAogICAgICAgIGlmIGVwb2NoICUgMTAwID09IDA6CiAgICAgICAgICAgIHByaW50KGYnRXBvY2gge2Vwb2NofSwgTG9zczoge2xvc3N9JykKICAgIHJldHVybiB0aGV0YQoKIyBFeGVtcGxlIGQnw7pzClggPSBucC5hcnJheShbWzEsIDFdLCBbMSwgMl0sIFsyLCAyXSwgWzIsIDNdXSkKeSA9IG5wLmRvdChYLCBucC5hcnJheShbMSwgMl0pKSArIDMKCnRoZXRhID0gZ3JhZGllbnRfZGVzY2VudChYLCB5KQpwcmludChmJ1dlaWdodHM6IHt0aGV0YX0nKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Funci&oacute; de p&egrave;rdua MSE
def mse_loss(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# Gradient Descent
def gradient_descent(X, y, learning_rate=0.01, epochs=1000):
    m, n = X.shape
    theta = np.zeros(n)
    for epoch in range(epochs):
        y_pred = X.dot(theta)
        loss = mse_loss(y, y_pred)
        gradient = (2/m) * X.T.dot(y_pred - y)
        theta -= learning_rate * gradient
        if epoch % 100 == 0:
            print(f'Epoch {epoch}, Loss: {loss}')
    return theta

# Exemple d'&uacute;s
X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
y = np.dot(X, np.array([1, 2])) + 3

theta = gradient_descent(X, y)
print(f'Weights: {theta}')</pre></div><div class='content'></div><h2>Explicació del Codi</h2>
<div class='content'><ol>
<li><strong>Funció de pèrdua MSE</strong>: Calcula l'error quadràtic mitjà entre les prediccions i els valors reals.</li>
<li><strong>Gradient Descent</strong>: Actualitza els pesos del model per minimitzar la funció de pèrdua. El codi imprimeix la pèrdua cada 100 iteracions per monitoritzar l'entrenament.</li>
<li><strong>Exemple d'ús</strong>: Genera dades sintètiques i aplica Gradient Descent per trobar els pesos òptims.</li>
</ol>
</div><h1>Exercicis Pràctics</h1>
<div class='content'></div><h2>Exercici 1: Implementar la funció de pèrdua d'entropia creuada</h2>
<div class='content'><p>Implementa la funció de pèrdua d'entropia creuada per un problema de classificació binària.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGJpbmFyeV9jcm9zc19lbnRyb3B5X2xvc3MoeV90cnVlLCB5X3ByZWQpOgogICAgZXBzaWxvbiA9IDFlLTE1CiAgICB5X3ByZWQgPSBucC5jbGlwKHlfcHJlZCwgZXBzaWxvbiwgMSAtIGVwc2lsb24pCiAgICByZXR1cm4gLW5wLm1lYW4oeV90cnVlICogbnAubG9nKHlfcHJlZCkgKyAoMSAtIHlfdHJ1ZSkgKiBucC5sb2coMSAtIHlfcHJlZCkpCgojIEV4ZW1wbGUgZCfDunMKeV90cnVlID0gbnAuYXJyYXkoWzEsIDAsIDEsIDFdKQp5X3ByZWQgPSBucC5hcnJheShbMC45LCAwLjEsIDAuOCwgMC43XSkKbG9zcyA9IGJpbmFyeV9jcm9zc19lbnRyb3B5X2xvc3MoeV90cnVlLCB5X3ByZWQpCnByaW50KGYnQmluYXJ5IENyb3NzLUVudHJvcHkgTG9zczoge2xvc3N9Jyk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def binary_cross_entropy_loss(y_true, y_pred):
    epsilon = 1e-15
    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

# Exemple d'&uacute;s
y_true = np.array([1, 0, 1, 1])
y_pred = np.array([0.9, 0.1, 0.8, 0.7])
loss = binary_cross_entropy_loss(y_true, y_pred)
print(f'Binary Cross-Entropy Loss: {loss}')</pre></div><div class='content'></div><h2>Solució</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGJpbmFyeV9jcm9zc19lbnRyb3B5X2xvc3MoeV90cnVlLCB5X3ByZWQpOgogICAgZXBzaWxvbiA9IDFlLTE1CiAgICB5X3ByZWQgPSBucC5jbGlwKHlfcHJlZCwgZXBzaWxvbiwgMSAtIGVwc2lsb24pCiAgICByZXR1cm4gLW5wLm1lYW4oeV90cnVlICogbnAubG9nKHlfcHJlZCkgKyAoMSAtIHlfdHJ1ZSkgKiBucC5sb2coMSAtIHlfcHJlZCkpCgojIEV4ZW1wbGUgZCfDunMKeV90cnVlID0gbnAuYXJyYXkoWzEsIDAsIDEsIDFdKQp5X3ByZWQgPSBucC5hcnJheShbMC45LCAwLjEsIDAuOCwgMC43XSkKbG9zcyA9IGJpbmFyeV9jcm9zc19lbnRyb3B5X2xvc3MoeV90cnVlLCB5X3ByZWQpCnByaW50KGYnQmluYXJ5IENyb3NzLUVudHJvcHkgTG9zczoge2xvc3N9Jyk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def binary_cross_entropy_loss(y_true, y_pred):
    epsilon = 1e-15
    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

# Exemple d'&uacute;s
y_true = np.array([1, 0, 1, 1])
y_pred = np.array([0.9, 0.1, 0.8, 0.7])
loss = binary_cross_entropy_loss(y_true, y_pred)
print(f'Binary Cross-Entropy Loss: {loss}')</pre></div><div class='content'></div><h1>Resum</h1>
<div class='content'><p>En aquesta secció, hem après sobre la funció de pèrdua i els algoritmes d'optimització, que són essencials per entrenar xarxes neuronals. Hem explorat diferents tipus de funcions de pèrdua i algoritmes d'optimització, i hem implementat exemples pràctics en Python. Aquests conceptes són fonamentals per comprendre com les xarxes neuronals aprenen i milloren amb el temps.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='02-03-propagacion-hacia-adelante-atras' title="Propagació cap endavant i cap enrere" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='02-03-propagacion-hacia-adelante-atras' title="Propagació cap endavant i cap enrere" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='03-01-introduccion-cnn' title="Introducció a les CNN" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="2-4">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='03-01-introduccion-cnn' title="Introducció a les CNN" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="2-4">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curs de Deep Learning</h1>
<h2>Mòdul 1: Introducció a Deep Learning</h2>
<ul>
<li><a href="01-01-que-es-deep-learning">Què és Deep Learning?</a></li>
<li><a href="01-02-historia-evolucion-deep-learning">Història i evolució del Deep Learning</a></li>
<li><a href="01-03-aplicaciones-deep-learning">Aplicacions de Deep Learning</a></li>
<li><a href="01-04-conceptos-basicos-redes-neuronales">Conceptes bàsics de xarxes neuronals</a></li>
</ul>
<h2>Mòdul 2: Fonaments de Xarxes Neuronals</h2>
<ul>
<li><a href="02-01-perceptron-perceptron-multicapa">Perceptró i Perceptró Multicapa</a></li>
<li><a href="02-02-funcion-de-activacion">Funció d'activació</a></li>
<li><a href="02-03-propagacion-hacia-adelante-atras">Propagació cap endavant i cap enrere</a></li>
<li><a href="02-04-optimizacion-funcion-de-perdida">Optimització i funció de pèrdua</a></li>
</ul>
<h2>Mòdul 3: Xarxes Neuronals Convolucionals (CNN)</h2>
<ul>
<li><a href="03-01-introduccion-cnn">Introducció a les CNN</a></li>
<li><a href="03-02-capas-convolucionales-pooling">Capes convolutionals i de pooling</a></li>
<li><a href="03-03-arquitecturas-populares-cnn">Arquitectures populars de CNN</a></li>
<li><a href="03-04-aplicaciones-cnn-reconocimiento-imagenes">Aplicacions de CNN en reconeixement d'imatges</a></li>
</ul>
<h2>Mòdul 4: Xarxes Neuronals Recurrentes (RNN)</h2>
<ul>
<li><a href="04-01-introduccion-rnn">Introducció a les RNN</a></li>
<li><a href="04-02-lstm-gru">LSTM i GRU</a></li>
<li><a href="04-03-aplicaciones-rnn-pln">Aplicacions de RNN en processament del llenguatge natural</a></li>
<li><a href="04-04-secuencias-series-temporales">Seqüències i sèries temporals</a></li>
</ul>
<h2>Mòdul 5: Tècniques Avançades en Deep Learning</h2>
<ul>
<li><a href="05-01-redes-generativas-adversariales">Xarxes Generatives Adversarials (GAN)</a></li>
<li><a href="05-02-autoencoders">Autoencoders</a></li>
<li><a href="05-03-transfer-learning">Transfer Learning</a></li>
<li><a href="05-04-regularizacion-tecnicas-mejora">Regularització i tècniques de millora</a></li>
</ul>
<h2>Mòdul 6: Eines i Frameworks</h2>
<ul>
<li><a href="06-01-introduccion-tensorflow">Introducció a TensorFlow</a></li>
<li><a href="06-02-introduccion-pytorch">Introducció a PyTorch</a></li>
<li><a href="06-03-comparacion-frameworks">Comparació de frameworks</a></li>
<li><a href="06-04-entornos-desarrollo-recursos">Entorns de desenvolupament i recursos addicionals</a></li>
</ul>
<h2>Mòdul 7: Projectes Pràctics</h2>
<ul>
<li><a href="07-01-clasificacion-imagenes-cnn">Classificació d'imatges amb CNN</a></li>
<li><a href="07-02-generacion-texto-rnn">Generació de text amb RNN</a></li>
<li><a href="07-03-deteccion-anomalias-autoencoders">Detecció d'anomalies amb Autoencoders</a></li>
<li><a href="07-04-creacion-gan-generacion-imagenes">Creació d'una GAN per generació d'imatges</a></li>
</ul>
<h2>Mòdul 8: Consideracions Ètiques i Futur del Deep Learning</h2>
<ul>
<li><a href="08-01-etica-deep-learning">Ètica en Deep Learning</a></li>
<li><a href="08-02-impacto-social-economico">Impacte social i econòmic</a></li>
<li><a href="08-03-tendencias-futuras-deep-learning">Tendències futures en Deep Learning</a></li>
<li><a href="08-04-desafios-oportunidades">Desafiaments i oportunitats</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuari no autentificat</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<p id="loginModalEmail"></p>
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
