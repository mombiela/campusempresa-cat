<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Optimització i funció de pèrdua</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/02-04-optimizacion-funcion-de-perdida" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/02-04-optimizacion-funcion-de-perdida" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/02-04-optimization-loss-function" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="https://enterprisecampus.net/mod/deep_learning/02-04-optimization-loss-function" class="px-2">EN</a></b>
				|
				<a href="https://campusempresa.com/mod/deep_learning/02-04-optimizacion-funcion-de-perdida" class="px-2">ES</a></b>
				|
				<b class="px-2">CA</b>
											</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Projecte</a>
				<a href="/about">Sobre nosaltres</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donacions</a>
				<a href="/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='02-03-propagacion-hacia-adelante-atras' title="Propagació cap endavant i cap enrere">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Optimització i funció de pèrdua</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='03-01-introduccion-cnn' title="Introducció a les CNN">Següent &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducció</h1>
<div class='content'><p>En aquest tema, explorarem els conceptes d'optimització i funció de pèrdua, que són fonamentals per entrenar xarxes neuronals. La funció de pèrdua mesura com de bé està funcionant el model, mentre que els algoritmes d'optimització ajusten els pesos del model per minimitzar aquesta pèrdua.</p>
</div><h1>Conceptes Clau</h1>
<div class='content'></div><h2>Funció de Pèrdua</h2>
<div class='content'><p>La funció de pèrdua (o funció de cost) és una mètrica que quantifica la discrepància entre les prediccions del model i els valors reals. L'objectiu de l'entrenament és minimitzar aquesta pèrdua.</p>
<h4>Tipus de Funcions de Pèrdua</h4>
<ol>
<li>
<p><strong>Error Quadràtic Mitjà (MSE)</strong>:
\[
MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]
Utilitzada principalment en problemes de regressió.</p>
</li>
<li>
<p><strong>Entropia Creuada (Cross-Entropy)</strong>:
\[
L = -\frac{1}{n} \sum_{i=1}^{n} \left[ y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right]
\]
Utilitzada en problemes de classificació binària.</p>
</li>
<li>
<p><strong>Entropia Creuada Categòrica</strong>:
\[
L = -\sum_{i=1}^{n} \sum_{j=1}^{k} y_{ij} \log(\hat{y}_{ij})
\]
Utilitzada en problemes de classificació multiclasse.</p>
</li>
</ol>
</div><h2>Algoritmes d'Optimització</h2>
<div class='content'><p>Els algoritmes d'optimització ajusten els pesos del model per minimitzar la funció de pèrdua. Els més comuns són:</p>
<ol>
<li>
<p><strong>Gradient Descent</strong>:
\[
\theta = \theta - \alpha \nabla_\theta J(\theta)
\]
On \(\theta\) són els pesos del model, \(\alpha\) és la taxa d'aprenentatge, i \(\nabla_\theta J(\theta)\) és el gradient de la funció de pèrdua respecte als pesos.</p>
</li>
<li>
<p><strong>Stochastic Gradient Descent (SGD)</strong>:
Actualitza els pesos utilitzant un sol exemple de dades a cada iteració, el que pot accelerar l'entrenament però introduir més variabilitat.</p>
</li>
<li>
<p><strong>Mini-batch Gradient Descent</strong>:
Una combinació de Gradient Descent i SGD, utilitzant petits lots de dades per actualitzar els pesos.</p>
</li>
<li>
<p><strong>Optimitzadors Avançats</strong>:</p>
<ul>
<li><strong>Adam</strong>: Combina les millors propietats de AdaGrad i RMSProp.</li>
<li><strong>RMSProp</strong>: Ajusta la taxa d'aprenentatge per cada paràmetre.</li>
<li><strong>AdaGrad</strong>: Ajusta la taxa d'aprenentatge basant-se en la freqüència de les actualitzacions dels pesos.</li>
</ul>
</li>
</ol>
</div><h1>Exemples Pràctics</h1>
<div class='content'></div><h2>Implementació de la Funció de Pèrdua i Optimització en Python</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIEZ1bmNpw7MgZGUgcMOocmR1YSBNU0UKZGVmIG1zZV9sb3NzKHlfdHJ1ZSwgeV9wcmVkKToKICAgIHJldHVybiBucC5tZWFuKCh5X3RydWUgLSB5X3ByZWQpICoqIDIpCgojIEdyYWRpZW50IERlc2NlbnQKZGVmIGdyYWRpZW50X2Rlc2NlbnQoWCwgeSwgbGVhcm5pbmdfcmF0ZT0wLjAxLCBlcG9jaHM9MTAwMCk6CiAgICBtLCBuID0gWC5zaGFwZQogICAgdGhldGEgPSBucC56ZXJvcyhuKQogICAgZm9yIGVwb2NoIGluIHJhbmdlKGVwb2Nocyk6CiAgICAgICAgeV9wcmVkID0gWC5kb3QodGhldGEpCiAgICAgICAgbG9zcyA9IG1zZV9sb3NzKHksIHlfcHJlZCkKICAgICAgICBncmFkaWVudCA9ICgyL20pICogWC5ULmRvdCh5X3ByZWQgLSB5KQogICAgICAgIHRoZXRhIC09IGxlYXJuaW5nX3JhdGUgKiBncmFkaWVudAogICAgICAgIGlmIGVwb2NoICUgMTAwID09IDA6CiAgICAgICAgICAgIHByaW50KGYnRXBvY2gge2Vwb2NofSwgTG9zczoge2xvc3N9JykKICAgIHJldHVybiB0aGV0YQoKIyBFeGVtcGxlIGQnw7pzClggPSBucC5hcnJheShbWzEsIDFdLCBbMSwgMl0sIFsyLCAyXSwgWzIsIDNdXSkKeSA9IG5wLmRvdChYLCBucC5hcnJheShbMSwgMl0pKSArIDMKCnRoZXRhID0gZ3JhZGllbnRfZGVzY2VudChYLCB5KQpwcmludChmJ1dlaWdodHM6IHt0aGV0YX0nKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Funci&oacute; de p&egrave;rdua MSE
def mse_loss(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# Gradient Descent
def gradient_descent(X, y, learning_rate=0.01, epochs=1000):
    m, n = X.shape
    theta = np.zeros(n)
    for epoch in range(epochs):
        y_pred = X.dot(theta)
        loss = mse_loss(y, y_pred)
        gradient = (2/m) * X.T.dot(y_pred - y)
        theta -= learning_rate * gradient
        if epoch % 100 == 0:
            print(f'Epoch {epoch}, Loss: {loss}')
    return theta

# Exemple d'&uacute;s
X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
y = np.dot(X, np.array([1, 2])) + 3

theta = gradient_descent(X, y)
print(f'Weights: {theta}')</pre></div><div class='content'></div><h2>Explicació del Codi</h2>
<div class='content'><ol>
<li><strong>Funció de pèrdua MSE</strong>: Calcula l'error quadràtic mitjà entre les prediccions i els valors reals.</li>
<li><strong>Gradient Descent</strong>: Actualitza els pesos del model per minimitzar la funció de pèrdua. El codi imprimeix la pèrdua cada 100 iteracions per monitoritzar l'entrenament.</li>
<li><strong>Exemple d'ús</strong>: Genera dades sintètiques i aplica Gradient Descent per trobar els pesos òptims.</li>
</ol>
</div><h1>Exercicis Pràctics</h1>
<div class='content'></div><h2>Exercici 1: Implementar la funció de pèrdua d'entropia creuada</h2>
<div class='content'><p>Implementa la funció de pèrdua d'entropia creuada per un problema de classificació binària.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGJpbmFyeV9jcm9zc19lbnRyb3B5X2xvc3MoeV90cnVlLCB5X3ByZWQpOgogICAgZXBzaWxvbiA9IDFlLTE1CiAgICB5X3ByZWQgPSBucC5jbGlwKHlfcHJlZCwgZXBzaWxvbiwgMSAtIGVwc2lsb24pCiAgICByZXR1cm4gLW5wLm1lYW4oeV90cnVlICogbnAubG9nKHlfcHJlZCkgKyAoMSAtIHlfdHJ1ZSkgKiBucC5sb2coMSAtIHlfcHJlZCkpCgojIEV4ZW1wbGUgZCfDunMKeV90cnVlID0gbnAuYXJyYXkoWzEsIDAsIDEsIDFdKQp5X3ByZWQgPSBucC5hcnJheShbMC45LCAwLjEsIDAuOCwgMC43XSkKbG9zcyA9IGJpbmFyeV9jcm9zc19lbnRyb3B5X2xvc3MoeV90cnVlLCB5X3ByZWQpCnByaW50KGYnQmluYXJ5IENyb3NzLUVudHJvcHkgTG9zczoge2xvc3N9Jyk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def binary_cross_entropy_loss(y_true, y_pred):
    epsilon = 1e-15
    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

# Exemple d'&uacute;s
y_true = np.array([1, 0, 1, 1])
y_pred = np.array([0.9, 0.1, 0.8, 0.7])
loss = binary_cross_entropy_loss(y_true, y_pred)
print(f'Binary Cross-Entropy Loss: {loss}')</pre></div><div class='content'></div><h2>Solució</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZGVmIGJpbmFyeV9jcm9zc19lbnRyb3B5X2xvc3MoeV90cnVlLCB5X3ByZWQpOgogICAgZXBzaWxvbiA9IDFlLTE1CiAgICB5X3ByZWQgPSBucC5jbGlwKHlfcHJlZCwgZXBzaWxvbiwgMSAtIGVwc2lsb24pCiAgICByZXR1cm4gLW5wLm1lYW4oeV90cnVlICogbnAubG9nKHlfcHJlZCkgKyAoMSAtIHlfdHJ1ZSkgKiBucC5sb2coMSAtIHlfcHJlZCkpCgojIEV4ZW1wbGUgZCfDunMKeV90cnVlID0gbnAuYXJyYXkoWzEsIDAsIDEsIDFdKQp5X3ByZWQgPSBucC5hcnJheShbMC45LCAwLjEsIDAuOCwgMC43XSkKbG9zcyA9IGJpbmFyeV9jcm9zc19lbnRyb3B5X2xvc3MoeV90cnVlLCB5X3ByZWQpCnByaW50KGYnQmluYXJ5IENyb3NzLUVudHJvcHkgTG9zczoge2xvc3N9Jyk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>def binary_cross_entropy_loss(y_true, y_pred):
    epsilon = 1e-15
    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))

# Exemple d'&uacute;s
y_true = np.array([1, 0, 1, 1])
y_pred = np.array([0.9, 0.1, 0.8, 0.7])
loss = binary_cross_entropy_loss(y_true, y_pred)
print(f'Binary Cross-Entropy Loss: {loss}')</pre></div><div class='content'></div><h1>Resum</h1>
<div class='content'><p>En aquesta secció, hem après sobre la funció de pèrdua i els algoritmes d'optimització, que són essencials per entrenar xarxes neuronals. Hem explorat diferents tipus de funcions de pèrdua i algoritmes d'optimització, i hem implementat exemples pràctics en Python. Aquests conceptes són fonamentals per comprendre com les xarxes neuronals aprenen i milloren amb el temps.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='02-03-propagacion-hacia-adelante-atras' title="Propagació cap endavant i cap enrere">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='03-01-introduccion-cnn' title="Introducció a les CNN">Següent &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
