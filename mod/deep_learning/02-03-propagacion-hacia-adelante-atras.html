<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    <title>Propagació cap endavant i cap enrere</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/02-03-propagacion-hacia-adelante-atras" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/02-03-propagacion-hacia-adelante-atras" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/02-03-forward-backward-propagation" hreflang="en" />
    
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.ea63f62b9e.css" rel="stylesheet">
	 
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>
  		var LANG = "ca";
  		var CATEGORY = "foundations";
  		var MOD_NAME = "deep_learning";
  		var TEMA_NAME = "2-3";
  		var TYPE = "mod";
  		var PATH = "mod/deep_learning/02-03-propagacion-hacia-adelante-atras";
  		var IS_INDEX = false;
  	</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="module" src="/js/app.86da6c742a.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
</head>

<body class="d-none">
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/deep_learning/02-03-forward-backward-propagation" class="px-2">EN</a></b>
	|
	<a href="https://campusempresa.com/mod/deep_learning/02-03-propagacion-hacia-adelante-atras" class="px-2">ES</a></b>
	|
	<b class="px-2">CA</b>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Tot el coneixement al teu abast</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col">
				<div class="d-flex justify-content-between">
					<div class="left">
						<a href="/" class="nav-link px-3" id="btnHome">
	<i class="bi bi-house-fill"></i>
	HOME
</a>

<a href="/my_modules" class="nav-link px-3 d-none" id="btnMyCourses">
	<i class="bi bi-rocket-takeoff-fill"></i>
	<i><b>Els meus cursos</b></i>
</a>
<a href="/end_modules" class="nav-link px-3 d-none" id="trophy_button">
	<i class="bi bi-trophy-fill"></i>
	Finalitzats             
</a>

					</div>
                    <div class="ms-auto right">
                        <a id="user_button" href="#" class="nav-link px-3" data-bs-toggle="modal" data-bs-target="#loginModal">
                            <i id="user_icon" class="bi"></i>                            
                        </a>
                    </div>					
				</div>
			</div>
		</div>
	</div>
</div>

		<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
										<div class="row py-1 m-0" id="buttonsModSection">
	<div class="col-6 p-0" data-mod="deep_learning">
		<a  href="#" class="text-secondary d-none" data-read-mod="deep_learning" data-read-unit="2-3" style="text-decoration:none;">
			<i class="bi bi-check-circle-fill"></i> 
			Marcar com a llegit
		</a>
		<a href="#" class="text-secondary d-none" data-unread-mod="deep_learning" data-unread-unit="2-3" style="text-decoration:none;">
			<i class="bi bi-x-circle-fill"></i>
			Marcar com a no llegit
		</a>
	</div>
	<div class="col-6 text-end p-0">
					<a href="./"  class="nav-link">
				<i class="bi bi-journal-text"></i>
				Contingut del curs
			</a>
			</div>
</div>						<div id="inner_content">
				<div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='02-02-funcion-de-activacion' title="Funció d'activació" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='02-02-funcion-de-activacion' title="Funció d'activació" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
					<h2 style="text-decoration:underline">Propagació cap endavant i cap enrere</h2>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='02-04-optimizacion-funcion-de-perdida' title="Optimització i funció de pèrdua" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="2-3">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='02-04-optimizacion-funcion-de-perdida' title="Optimització i funció de pèrdua" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="2-3">
				 &#x25BA;
			</a>
			</div>
</div>
<div class='content'><p>En aquest tema, explorarem dos conceptes fonamentals en el funcionament de les xarxes neuronals: la propagació cap endavant (forward propagation) i la propagació cap enrere (backward propagation). Aquests processos són essencials per entrenar una xarxa neuronal i ajustar els seus pesos per obtenir prediccions acurades.</p>
</div><h1>Propagació cap endavant</h1>
<div class='content'></div><h2>Què és la propagació cap endavant?</h2>
<div class='content'><p>La propagació cap endavant és el procés mitjançant el qual les dades d'entrada passen a través de la xarxa neuronal, capa per capa, fins a arribar a la sortida. Aquest procés implica calcular les sortides de cada neurona en cada capa utilitzant els pesos i les funcions d'activació.</p>
</div><h2>Passos de la propagació cap endavant</h2>
<div class='content'><ol>
<li>
<p><strong>Entrada de dades</strong>: Les dades d'entrada es presenten a la capa d'entrada de la xarxa neuronal.</p>
</li>
<li>
<p><strong>Càlcul de les sortides de les neurones</strong>: Per a cada capa, es calcula la sortida de cada neurona utilitzant la fórmula:
\[
z = W \cdot x + b
\]
on:</p>
<ul>
<li>\( z \) és la sortida de la neurona abans d'aplicar la funció d'activació.</li>
<li>\( W \) són els pesos de les connexions.</li>
<li>\( x \) és el vector d'entrada.</li>
<li>\( b \) és el biaix (bias).</li>
</ul>
</li>
<li>
<p><strong>Aplicació de la funció d'activació</strong>: La sortida \( z \) es passa a través d'una funció d'activació \( \sigma \) per obtenir la sortida final de la neurona:
\[
a = \sigma(z)
\]</p>
</li>
<li>
<p><strong>Repetició per a totes les capes</strong>: Aquest procés es repeteix per a totes les capes de la xarxa fins a arribar a la capa de sortida.</p>
</li>
</ol>
</div><h2>Exemple de codi</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIEZ1bmNpw7MgZCdhY3RpdmFjacOzIHNpZ21vaWRlCmRlZiBzaWdtb2lkKHopOgogICAgcmV0dXJuIDEgLyAoMSArIG5wLmV4cCgteikpCgojIFByb3BhZ2FjacOzIGNhcCBlbmRhdmFudApkZWYgZm9yd2FyZF9wcm9wYWdhdGlvbihYLCBXLCBiKToKICAgIHogPSBucC5kb3QoVywgWCkgKyBiCiAgICBhID0gc2lnbW9pZCh6KQogICAgcmV0dXJuIGEKCiMgRXhlbXBsZSBkJ8O6cwpYID0gbnAuYXJyYXkoWzAuNSwgMC4yLCAwLjFdKSAgIyBFbnRyYWRhClcgPSBucC5hcnJheShbMC40LCAwLjMsIDAuMl0pICAjIFBlc29zCmIgPSAwLjEgICMgQmlhaXgKCm91dHB1dCA9IGZvcndhcmRfcHJvcGFnYXRpb24oWCwgVywgYikKcHJpbnQoIlNvcnRpZGEgZGUgbGEgbmV1cm9uYToiLCBvdXRwdXQp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Funci&oacute; d'activaci&oacute; sigmoide
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

# Propagaci&oacute; cap endavant
def forward_propagation(X, W, b):
    z = np.dot(W, X) + b
    a = sigmoid(z)
    return a

# Exemple d'&uacute;s
X = np.array([0.5, 0.2, 0.1])  # Entrada
W = np.array([0.4, 0.3, 0.2])  # Pesos
b = 0.1  # Biaix

output = forward_propagation(X, W, b)
print(&quot;Sortida de la neurona:&quot;, output)</pre></div><div class='content'></div><h1>Propagació cap enrere</h1>
<div class='content'></div><h2>Què és la propagació cap enrere?</h2>
<div class='content'><p>La propagació cap enrere és el procés mitjançant el qual es calcula el gradient de la funció de pèrdua respecte als pesos de la xarxa neuronal. Aquest procés permet ajustar els pesos per minimitzar l'error de predicció.</p>
</div><h2>Passos de la propagació cap enrere</h2>
<div class='content'><ol>
<li>
<p><strong>Càlcul de l'error de sortida</strong>: Es calcula l'error de la sortida de la xarxa comparant la sortida prevista amb la sortida desitjada (etiqueta).
\[
\delta = \hat{y} - y
\]
on:</p>
<ul>
<li>\( \delta \) és l'error de la sortida.</li>
<li>\( \hat{y} \) és la sortida prevista.</li>
<li>\( y \) és la sortida desitjada.</li>
</ul>
</li>
<li>
<p><strong>Càlcul del gradient</strong>: Es calcula el gradient de l'error respecte als pesos utilitzant la regla de la cadena.
\[
\frac{\partial L}{\partial W} = \delta \cdot \frac{\partial \hat{y}}{\partial z} \cdot \frac{\partial z}{\partial W}
\]</p>
</li>
<li>
<p><strong>Actualització dels pesos</strong>: Els pesos es modifiquen en la direcció oposada al gradient per minimitzar l'error.
\[
W = W - \eta \cdot \frac{\partial L}{\partial W}
\]
on:</p>
<ul>
<li>\( \eta \) és la taxa d'aprenentatge.</li>
</ul>
</li>
</ol>
</div><h2>Exemple de codi</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("IyBGdW5jacOzIGRlIGRlcml2YWRhIGRlIGxhIHNpZ21vaWRlCmRlZiBzaWdtb2lkX2Rlcml2YXRpdmUoeik6CiAgICByZXR1cm4gc2lnbW9pZCh6KSAqICgxIC0gc2lnbW9pZCh6KSkKCiMgUHJvcGFnYWNpw7MgY2FwIGVucmVyZQpkZWYgYmFja3dhcmRfcHJvcGFnYXRpb24oWCwgeSwgVywgYiwgb3V0cHV0LCBsZWFybmluZ19yYXRlKToKICAgIGVycm9yID0gb3V0cHV0IC0geQogICAgZFcgPSBlcnJvciAqIHNpZ21vaWRfZGVyaXZhdGl2ZShvdXRwdXQpICogWAogICAgZGIgPSBlcnJvciAqIHNpZ21vaWRfZGVyaXZhdGl2ZShvdXRwdXQpCiAgICAKICAgICMgQWN0dWFsaXR6YWNpw7MgZGVscyBwZXNvcyBpIGVsIGJpYWl4CiAgICBXID0gVyAtIGxlYXJuaW5nX3JhdGUgKiBkVwogICAgYiA9IGIgLSBsZWFybmluZ19yYXRlICogZGIKICAgIAogICAgcmV0dXJuIFcsIGIKCiMgRXhlbXBsZSBkJ8O6cwp5ID0gMC42ICAjIFNvcnRpZGEgZGVzaXRqYWRhCmxlYXJuaW5nX3JhdGUgPSAwLjAxCgpXLCBiID0gYmFja3dhcmRfcHJvcGFnYXRpb24oWCwgeSwgVywgYiwgb3V0cHV0LCBsZWFybmluZ19yYXRlKQpwcmludCgiUGVzb3MgYWN0dWFsaXR6YXRzOiIsIFcpCnByaW50KCJCaWFpeCBhY3R1YWxpdHphdDoiLCBiKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'># Funci&oacute; de derivada de la sigmoide
def sigmoid_derivative(z):
    return sigmoid(z) * (1 - sigmoid(z))

# Propagaci&oacute; cap enrere
def backward_propagation(X, y, W, b, output, learning_rate):
    error = output - y
    dW = error * sigmoid_derivative(output) * X
    db = error * sigmoid_derivative(output)
    
    # Actualitzaci&oacute; dels pesos i el biaix
    W = W - learning_rate * dW
    b = b - learning_rate * db
    
    return W, b

# Exemple d'&uacute;s
y = 0.6  # Sortida desitjada
learning_rate = 0.01

W, b = backward_propagation(X, y, W, b, output, learning_rate)
print(&quot;Pesos actualitzats:&quot;, W)
print(&quot;Biaix actualitzat:&quot;, b)</pre></div><div class='content'></div><h1>Exercici pràctic</h1>
<div class='content'></div><h2>Exercici</h2>
<div class='content'><p>Implementa una xarxa neuronal simple amb una capa d'entrada, una capa oculta i una capa de sortida. Utilitza la propagació cap endavant i cap enrere per entrenar la xarxa amb un conjunt de dades d'exemple.</p>
</div><h2>Solució</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCgojIEZ1bmNpb25zIGQnYWN0aXZhY2nDsyBpIGxlcyBzZXZlcyBkZXJpdmFkZXMKZGVmIHNpZ21vaWQoeik6CiAgICByZXR1cm4gMSAvICgxICsgbnAuZXhwKC16KSkKCmRlZiBzaWdtb2lkX2Rlcml2YXRpdmUoeik6CiAgICByZXR1cm4gc2lnbW9pZCh6KSAqICgxIC0gc2lnbW9pZCh6KSkKCiMgUHJvcGFnYWNpw7MgY2FwIGVuZGF2YW50CmRlZiBmb3J3YXJkX3Byb3BhZ2F0aW9uKFgsIFcxLCBiMSwgVzIsIGIyKToKICAgIHoxID0gbnAuZG90KFcxLCBYKSArIGIxCiAgICBhMSA9IHNpZ21vaWQoejEpCiAgICB6MiA9IG5wLmRvdChXMiwgYTEpICsgYjIKICAgIGEyID0gc2lnbW9pZCh6MikKICAgIHJldHVybiBhMSwgYTIKCiMgUHJvcGFnYWNpw7MgY2FwIGVucmVyZQpkZWYgYmFja3dhcmRfcHJvcGFnYXRpb24oWCwgeSwgVzEsIGIxLCBXMiwgYjIsIGExLCBhMiwgbGVhcm5pbmdfcmF0ZSk6CiAgICBlcnJvcl9vdXRwdXQgPSBhMiAtIHkKICAgIGRXMiA9IGVycm9yX291dHB1dCAqIHNpZ21vaWRfZGVyaXZhdGl2ZShhMikgKiBhMQogICAgZGIyID0gZXJyb3Jfb3V0cHV0ICogc2lnbW9pZF9kZXJpdmF0aXZlKGEyKQogICAgCiAgICBlcnJvcl9oaWRkZW4gPSBucC5kb3QoVzIuVCwgZXJyb3Jfb3V0cHV0KSAqIHNpZ21vaWRfZGVyaXZhdGl2ZShhMSkKICAgIGRXMSA9IGVycm9yX2hpZGRlbiAqIFgKICAgIGRiMSA9IGVycm9yX2hpZGRlbgogICAgCiAgICAjIEFjdHVhbGl0emFjacOzIGRlbHMgcGVzb3MgaSBlbHMgYmlhaXhvcwogICAgVzEgPSBXMSAtIGxlYXJuaW5nX3JhdGUgKiBkVzEKICAgIGIxID0gYjEgLSBsZWFybmluZ19yYXRlICogZGIxCiAgICBXMiA9IFcyIC0gbGVhcm5pbmdfcmF0ZSAqIGRXMgogICAgYjIgPSBiMiAtIGxlYXJuaW5nX3JhdGUgKiBkYjIKICAgIAogICAgcmV0dXJuIFcxLCBiMSwgVzIsIGIyCgojIEluaWNpYWxpdHphY2nDsyBkZWxzIHBlc29zIGkgZWxzIGJpYWl4b3MKbnAucmFuZG9tLnNlZWQoNDIpClcxID0gbnAucmFuZG9tLnJhbmQoMywgMykKYjEgPSBucC5yYW5kb20ucmFuZCgzKQpXMiA9IG5wLnJhbmRvbS5yYW5kKDEsIDMpCmIyID0gbnAucmFuZG9tLnJhbmQoMSkKCiMgRGFkZXMgZCdleGVtcGxlClggPSBucC5hcnJheShbMC41LCAwLjIsIDAuMV0pCnkgPSBucC5hcnJheShbMC42XSkKbGVhcm5pbmdfcmF0ZSA9IDAuMDEKCiMgRW50cmVuYW1lbnQgZGUgbGEgeGFyeGEKZm9yIGVwb2NoIGluIHJhbmdlKDEwMDApOgogICAgYTEsIGEyID0gZm9yd2FyZF9wcm9wYWdhdGlvbihYLCBXMSwgYjEsIFcyLCBiMikKICAgIFcxLCBiMSwgVzIsIGIyID0gYmFja3dhcmRfcHJvcGFnYXRpb24oWCwgeSwgVzEsIGIxLCBXMiwgYjIsIGExLCBhMiwgbGVhcm5pbmdfcmF0ZSkKCnByaW50KCJQZXNvcyBpIGJpYWl4b3MgYWN0dWFsaXR6YXRzOiIpCnByaW50KCJXMToiLCBXMSkKcHJpbnQoImIxOiIsIGIxKQpwcmludCgiVzI6IiwgVzIpCnByaW50KCJiMjoiLCBiMik="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np

# Funcions d'activaci&oacute; i les seves derivades
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def sigmoid_derivative(z):
    return sigmoid(z) * (1 - sigmoid(z))

# Propagaci&oacute; cap endavant
def forward_propagation(X, W1, b1, W2, b2):
    z1 = np.dot(W1, X) + b1
    a1 = sigmoid(z1)
    z2 = np.dot(W2, a1) + b2
    a2 = sigmoid(z2)
    return a1, a2

# Propagaci&oacute; cap enrere
def backward_propagation(X, y, W1, b1, W2, b2, a1, a2, learning_rate):
    error_output = a2 - y
    dW2 = error_output * sigmoid_derivative(a2) * a1
    db2 = error_output * sigmoid_derivative(a2)
    
    error_hidden = np.dot(W2.T, error_output) * sigmoid_derivative(a1)
    dW1 = error_hidden * X
    db1 = error_hidden
    
    # Actualitzaci&oacute; dels pesos i els biaixos
    W1 = W1 - learning_rate * dW1
    b1 = b1 - learning_rate * db1
    W2 = W2 - learning_rate * dW2
    b2 = b2 - learning_rate * db2
    
    return W1, b1, W2, b2

# Inicialitzaci&oacute; dels pesos i els biaixos
np.random.seed(42)
W1 = np.random.rand(3, 3)
b1 = np.random.rand(3)
W2 = np.random.rand(1, 3)
b2 = np.random.rand(1)

# Dades d'exemple
X = np.array([0.5, 0.2, 0.1])
y = np.array([0.6])
learning_rate = 0.01

# Entrenament de la xarxa
for epoch in range(1000):
    a1, a2 = forward_propagation(X, W1, b1, W2, b2)
    W1, b1, W2, b2 = backward_propagation(X, y, W1, b1, W2, b2, a1, a2, learning_rate)

print(&quot;Pesos i biaixos actualitzats:&quot;)
print(&quot;W1:&quot;, W1)
print(&quot;b1:&quot;, b1)
print(&quot;W2:&quot;, W2)
print(&quot;b2:&quot;, b2)</pre></div><div class='content'></div><h1>Resum</h1>
<div class='content'><p>En aquesta secció, hem après sobre la propagació cap endavant i cap enrere, dos processos essencials per entrenar xarxes neuronals. La propagació cap endavant implica el càlcul de les sortides de les neurones a través de la xarxa, mentre que la propagació cap enrere calcula els gradients per ajustar els pesos i minimitzar l'error de predicció. Hem vist exemples de codi per implementar aquests processos i hem practicat amb un exercici pràctic per consolidar els conceptes apresos.</p>
</div><div class='row navigation'>
	<div class='col-2 d-none d-md-block'>
					<a href='02-02-funcion-de-activacion' title="Funció d'activació" class="py-2 px-3 btn btn-primary">
				&#x25C4; Anterior 
			</a>
			</div>
	<div class='col-2 d-md-none'>
					<a href='02-02-funcion-de-activacion' title="Funció d'activació" class="py-2 px-3 btn btn-primary">
				&#x25C4;
			</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end d-none d-md-block'>
					<a href='02-04-optimizacion-funcion-de-perdida' title="Optimització i funció de pèrdua" class="py-2 px-3 btn btn-primary"
				data-read-mod="deep_learning" data-read-unit="2-3">
				Següent &#x25BA;
			</a>
			</div>
	<div class='col-2 text-end d-md-none '>
					<a href='02-04-optimizacion-funcion-de-perdida' title="Optimització i funció de pèrdua" class="py-2 px-3 btn btn-primary" 
				data-read-mod="deep_learning" data-read-unit="2-3">
				 &#x25BA;
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
						
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curs de Deep Learning</h1>
<h2>Mòdul 1: Introducció a Deep Learning</h2>
<ul>
<li><a href="01-01-que-es-deep-learning">Què és Deep Learning?</a></li>
<li><a href="01-02-historia-evolucion-deep-learning">Història i evolució del Deep Learning</a></li>
<li><a href="01-03-aplicaciones-deep-learning">Aplicacions de Deep Learning</a></li>
<li><a href="01-04-conceptos-basicos-redes-neuronales">Conceptes bàsics de xarxes neuronals</a></li>
</ul>
<h2>Mòdul 2: Fonaments de Xarxes Neuronals</h2>
<ul>
<li><a href="02-01-perceptron-perceptron-multicapa">Perceptró i Perceptró Multicapa</a></li>
<li><a href="02-02-funcion-de-activacion">Funció d'activació</a></li>
<li><a href="02-03-propagacion-hacia-adelante-atras">Propagació cap endavant i cap enrere</a></li>
<li><a href="02-04-optimizacion-funcion-de-perdida">Optimització i funció de pèrdua</a></li>
</ul>
<h2>Mòdul 3: Xarxes Neuronals Convolucionals (CNN)</h2>
<ul>
<li><a href="03-01-introduccion-cnn">Introducció a les CNN</a></li>
<li><a href="03-02-capas-convolucionales-pooling">Capes convolutionals i de pooling</a></li>
<li><a href="03-03-arquitecturas-populares-cnn">Arquitectures populars de CNN</a></li>
<li><a href="03-04-aplicaciones-cnn-reconocimiento-imagenes">Aplicacions de CNN en reconeixement d'imatges</a></li>
</ul>
<h2>Mòdul 4: Xarxes Neuronals Recurrentes (RNN)</h2>
<ul>
<li><a href="04-01-introduccion-rnn">Introducció a les RNN</a></li>
<li><a href="04-02-lstm-gru">LSTM i GRU</a></li>
<li><a href="04-03-aplicaciones-rnn-pln">Aplicacions de RNN en processament del llenguatge natural</a></li>
<li><a href="04-04-secuencias-series-temporales">Seqüències i sèries temporals</a></li>
</ul>
<h2>Mòdul 5: Tècniques Avançades en Deep Learning</h2>
<ul>
<li><a href="05-01-redes-generativas-adversariales">Xarxes Generatives Adversarials (GAN)</a></li>
<li><a href="05-02-autoencoders">Autoencoders</a></li>
<li><a href="05-03-transfer-learning">Transfer Learning</a></li>
<li><a href="05-04-regularizacion-tecnicas-mejora">Regularització i tècniques de millora</a></li>
</ul>
<h2>Mòdul 6: Eines i Frameworks</h2>
<ul>
<li><a href="06-01-introduccion-tensorflow">Introducció a TensorFlow</a></li>
<li><a href="06-02-introduccion-pytorch">Introducció a PyTorch</a></li>
<li><a href="06-03-comparacion-frameworks">Comparació de frameworks</a></li>
<li><a href="06-04-entornos-desarrollo-recursos">Entorns de desenvolupament i recursos addicionals</a></li>
</ul>
<h2>Mòdul 7: Projectes Pràctics</h2>
<ul>
<li><a href="07-01-clasificacion-imagenes-cnn">Classificació d'imatges amb CNN</a></li>
<li><a href="07-02-generacion-texto-rnn">Generació de text amb RNN</a></li>
<li><a href="07-03-deteccion-anomalias-autoencoders">Detecció d'anomalies amb Autoencoders</a></li>
<li><a href="07-04-creacion-gan-generacion-imagenes">Creació d'una GAN per generació d'imatges</a></li>
</ul>
<h2>Mòdul 8: Consideracions Ètiques i Futur del Deep Learning</h2>
<ul>
<li><a href="08-01-etica-deep-learning">Ètica en Deep Learning</a></li>
<li><a href="08-02-impacto-social-economico">Impacte social i econòmic</a></li>
<li><a href="08-03-tendencias-futuras-deep-learning">Tendències futures en Deep Learning</a></li>
<li><a href="08-04-desafios-oportunidades">Desafiaments i oportunitats</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

		<div class="modal fade" id="loginModal" tabindex="-1" aria-labelledby="loginModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title" id="loginModalLabel">Usuari no autentificat</h5>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
            	<p id="loginModalEmail"></p>
            	<div id="modal-body-main"></div>
            </div>
        </div>
    </div>
</div>	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
