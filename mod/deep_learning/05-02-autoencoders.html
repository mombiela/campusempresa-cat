<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Autoencoders</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/05-02-autoencoders" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/05-02-autoencoders" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/05-02-autoencoders" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<a href="https://enterprisecampus.net/mod/deep_learning/05-02-autoencoders" class="px-2">EN</a></b>
	|
	<a href="https://campusempresa.com/mod/deep_learning/05-02-autoencoders" class="px-2">ES</a></b>
	|
	<b class="px-2">CA</b>
</span>
			<span class="d-none d-md-inline"><br><cite>Tot el coneixement al teu abast</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					 				<a href="/"><i class="bi bi-house-fill"></i> HOME</a>
											</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-01-redes-generativas-adversariales' title="Xarxes Generatives Adversarials (GAN)">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Autoencoders</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-03-transfer-learning' title="Transfer Learning">
				<span class="d-none d-md-inline">Següent &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1>Introducció als Autoencoders</h1>
<div class='content'><p>Els autoencoders són un tipus de xarxa neuronal utilitzada per aprendre representacions eficients (codificacions) d'un conjunt de dades, típicament per a la reducció de dimensionalitat o per a la detecció d'anomalies. La idea principal darrere dels autoencoders és aprendre una representació comprimida (codificació) de les dades d'entrada i després reconstruir-les a partir d'aquesta codificació.</p>
</div><h2>Components d'un Autoencoder</h2>
<div class='content'><p>Un autoencoder consta de dues parts principals:</p>
<ol>
<li><strong>Codificador (Encoder)</strong>: Transforma l'entrada en una representació comprimida.</li>
<li><strong>Decodificador (Decoder)</strong>: Reconstrueix l'entrada original a partir de la representació comprimida.</li>
</ol>
</div><h2>Arquitectura Bàsica</h2>
<div class='content'><p>L'arquitectura bàsica d'un autoencoder es pot representar de la següent manera:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("RW50cmFkYSAtPiBDb2RpZmljYWRvciAtPiBDb2RpZmljYWNpw7MgKExhdGVudCBTcGFjZSkgLT4gRGVjb2RpZmljYWRvciAtPiBTb3J0aWRhIChSZWNvbnN0cnVjdGVkIElucHV0KQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>Entrada -&gt; Codificador -&gt; Codificaci&oacute; (Latent Space) -&gt; Decodificador -&gt; Sortida (Reconstructed Input)</pre></div><div class='content'></div><h2>Funció de Pèrdua</h2>
<div class='content'><p>La funció de pèrdua en un autoencoder mesura la diferència entre l'entrada original i la sortida reconstruïda. La funció de pèrdua més comuna és l'error quadràtic mitjà (MSE):</p>
<p>\[ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (x_i - \hat{x}_i)^2 \]</p>
<p>on \( x_i \) és l'entrada original i \( \hat{x}_i \) és la sortida reconstruïda.</p>
</div><h1>Tipus d'Autoencoders</h1>
<div class='content'></div><h2>Autoencoders Clàssics</h2>
<div class='content'><p>Els autoencoders clàssics tenen una estructura simètrica amb el mateix nombre de neurones a les capes d'entrada i sortida. La capa latent té menys neurones que les capes d'entrada i sortida, forçant així la xarxa a aprendre una representació comprimida.</p>
</div><h2>Variational Autoencoders (VAE)</h2>
<div class='content'><p>Els VAE són una variant dels autoencoders que imposen una distribució probabilística sobre la capa latent. Això permet generar noves dades similars a les dades d'entrenament.</p>
</div><h2>Denoising Autoencoders</h2>
<div class='content'><p>Els denoising autoencoders estan dissenyats per eliminar el soroll de les dades. S'entrenen amb dades sorolloses com a entrada i dades netes com a sortida.</p>
</div><h2>Sparse Autoencoders</h2>
<div class='content'><p>Els sparse autoencoders imposen una penalització de sparsity (escassetat) a la capa latent, forçant la xarxa a aprendre representacions on només unes poques unitats estan actives alhora.</p>
</div><h1>Exemple Pràctic amb Keras</h1>
<div class='content'><p>A continuació, es presenta un exemple pràctic d'un autoencoder simple utilitzant Keras:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmZyb20ga2VyYXMubGF5ZXJzIGltcG9ydCBJbnB1dCwgRGVuc2UKZnJvbSBrZXJhcy5tb2RlbHMgaW1wb3J0IE1vZGVsCmZyb20ga2VyYXMuZGF0YXNldHMgaW1wb3J0IG1uaXN0CgojIENhcnJlZ2FyIGxlcyBkYWRlcyBkZSBNTklTVAooeF90cmFpbiwgXyksICh4X3Rlc3QsIF8pID0gbW5pc3QubG9hZF9kYXRhKCkKeF90cmFpbiA9IHhfdHJhaW4uYXN0eXBlKCdmbG9hdDMyJykgLyAyNTUuCnhfdGVzdCA9IHhfdGVzdC5hc3R5cGUoJ2Zsb2F0MzInKSAvIDI1NS4KeF90cmFpbiA9IHhfdHJhaW4ucmVzaGFwZSgobGVuKHhfdHJhaW4pLCBucC5wcm9kKHhfdHJhaW4uc2hhcGVbMTpdKSkpCnhfdGVzdCA9IHhfdGVzdC5yZXNoYXBlKChsZW4oeF90ZXN0KSwgbnAucHJvZCh4X3Rlc3Quc2hhcGVbMTpdKSkpCgojIERpbWVuc2lvbnMgZGUgbCdlbnRyYWRhCmlucHV0X2RpbSA9IHhfdHJhaW4uc2hhcGVbMV0KZW5jb2RpbmdfZGltID0gMzIgICMgRGltZW5zaW9uYWxpdGF0IGRlIGxhIGNhcGEgbGF0ZW50CgojIERlZmluaXIgZWwgbW9kZWwKaW5wdXRfaW1nID0gSW5wdXQoc2hhcGU9KGlucHV0X2RpbSwpKQplbmNvZGVkID0gRGVuc2UoZW5jb2RpbmdfZGltLCBhY3RpdmF0aW9uPSdyZWx1JykoaW5wdXRfaW1nKQpkZWNvZGVkID0gRGVuc2UoaW5wdXRfZGltLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykoZW5jb2RlZCkKCiMgQ3JlYXIgbCdhdXRvZW5jb2RlcgphdXRvZW5jb2RlciA9IE1vZGVsKGlucHV0X2ltZywgZGVjb2RlZCkKCiMgQ29tcGlsYXIgZWwgbW9kZWwKYXV0b2VuY29kZXIuY29tcGlsZShvcHRpbWl6ZXI9J2FkYW0nLCBsb3NzPSdiaW5hcnlfY3Jvc3NlbnRyb3B5JykKCiMgRW50cmVuYXIgbCdhdXRvZW5jb2RlcgphdXRvZW5jb2Rlci5maXQoeF90cmFpbiwgeF90cmFpbiwKICAgICAgICAgICAgICAgIGVwb2Nocz01MCwKICAgICAgICAgICAgICAgIGJhdGNoX3NpemU9MjU2LAogICAgICAgICAgICAgICAgc2h1ZmZsZT1UcnVlLAogICAgICAgICAgICAgICAgdmFsaWRhdGlvbl9kYXRhPSh4X3Rlc3QsIHhfdGVzdCkpCgojIENvZGlmaWNhZG9yIHBlciBvYnRlbmlyIGxlcyByZXByZXNlbnRhY2lvbnMgY29tcHJpbWlkZXMKZW5jb2RlciA9IE1vZGVsKGlucHV0X2ltZywgZW5jb2RlZCkKCiMgRGVjb2RpZmljYWRvciBwZXIgcmVjb25zdHJ1aXIgbGVzIGltYXRnZXMKZW5jb2RlZF9pbnB1dCA9IElucHV0KHNoYXBlPShlbmNvZGluZ19kaW0sKSkKZGVjb2Rlcl9sYXllciA9IGF1dG9lbmNvZGVyLmxheWVyc1stMV0KZGVjb2RlciA9IE1vZGVsKGVuY29kZWRfaW5wdXQsIGRlY29kZXJfbGF5ZXIoZW5jb2RlZF9pbnB1dCkpCgojIENvZGlmaWNhciBpIGRlY29kaWZpY2FyIGFsZ3VuZXMgaW1hdGdlcwplbmNvZGVkX2ltZ3MgPSBlbmNvZGVyLnByZWRpY3QoeF90ZXN0KQpkZWNvZGVkX2ltZ3MgPSBkZWNvZGVyLnByZWRpY3QoZW5jb2RlZF9pbWdzKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
from keras.layers import Input, Dense
from keras.models import Model
from keras.datasets import mnist

# Carregar les dades de MNIST
(x_train, _), (x_test, _) = mnist.load_data()
x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))

# Dimensions de l'entrada
input_dim = x_train.shape[1]
encoding_dim = 32  # Dimensionalitat de la capa latent

# Definir el model
input_img = Input(shape=(input_dim,))
encoded = Dense(encoding_dim, activation='relu')(input_img)
decoded = Dense(input_dim, activation='sigmoid')(encoded)

# Crear l'autoencoder
autoencoder = Model(input_img, decoded)

# Compilar el model
autoencoder.compile(optimizer='adam', loss='binary_crossentropy')

# Entrenar l'autoencoder
autoencoder.fit(x_train, x_train,
                epochs=50,
                batch_size=256,
                shuffle=True,
                validation_data=(x_test, x_test))

# Codificador per obtenir les representacions comprimides
encoder = Model(input_img, encoded)

# Decodificador per reconstruir les imatges
encoded_input = Input(shape=(encoding_dim,))
decoder_layer = autoencoder.layers[-1]
decoder = Model(encoded_input, decoder_layer(encoded_input))

# Codificar i decodificar algunes imatges
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)</pre></div><div class='content'></div><h2>Explicació del Codi</h2>
<div class='content'><ol>
<li><strong>Carregar les dades</strong>: Es carreguen les dades de MNIST i es normalitzen.</li>
<li><strong>Definir el model</strong>: Es defineix l'arquitectura de l'autoencoder amb una capa d'entrada, una capa latent (codificador) i una capa de sortida (decodificador).</li>
<li><strong>Compilar el model</strong>: Es compila el model amb l'optimitzador 'adam' i la funció de pèrdua 'binary_crossentropy'.</li>
<li><strong>Entrenar l'autoencoder</strong>: Es realitza l'entrenament de l'autoencoder amb les dades d'entrenament.</li>
<li><strong>Codificador i Decodificador</strong>: Es defineixen models separats per al codificador i el decodificador per obtenir les representacions comprimides i reconstruir les imatges.</li>
</ol>
</div><h1>Exercici Pràctic</h1>
<div class='content'></div><h2>Objectiu</h2>
<div class='content'><p>Crear un autoencoder per reduir la dimensionalitat de les dades de MNIST i visualitzar les representacions comprimides.</p>
</div><h2>Passos</h2>
<div class='content'><ol>
<li>Carregar les dades de MNIST.</li>
<li>Definir l'arquitectura de l'autoencoder.</li>
<li>Entrenar l'autoencoder.</li>
<li>Visualitzar les representacions comprimides utilitzant tècniques de visualització com PCA o t-SNE.</li>
</ol>
</div><h2>Solució</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG1hdHBsb3RsaWIucHlwbG90IGFzIHBsdApmcm9tIHNrbGVhcm4ubWFuaWZvbGQgaW1wb3J0IFRTTkUKCiMgVmlzdWFsaXR6YXIgbGVzIHJlcHJlc2VudGFjaW9ucyBjb21wcmltaWRlcwplbmNvZGVkX2ltZ3MgPSBlbmNvZGVyLnByZWRpY3QoeF90ZXN0KQoKIyBVdGlsaXR6YXIgdC1TTkUgcGVyIHJlZHVpciBsYSBkaW1lbnNpb25hbGl0YXQgYSAyRAp0c25lID0gVFNORShuX2NvbXBvbmVudHM9MiwgcmFuZG9tX3N0YXRlPTApCmVuY29kZWRfaW1nc18yZCA9IHRzbmUuZml0X3RyYW5zZm9ybShlbmNvZGVkX2ltZ3MpCgojIFZpc3VhbGl0emFyIGxlcyByZXByZXNlbnRhY2lvbnMgY29tcHJpbWlkZXMKcGx0LmZpZ3VyZShmaWdzaXplPSg2LCA2KSkKcGx0LnNjYXR0ZXIoZW5jb2RlZF9pbWdzXzJkWzosIDBdLCBlbmNvZGVkX2ltZ3NfMmRbOiwgMV0sIGM9eV90ZXN0LCBjbWFwPSd2aXJpZGlzJykKcGx0LmNvbG9yYmFyKCkKcGx0LnNob3coKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

# Visualitzar les representacions comprimides
encoded_imgs = encoder.predict(x_test)

# Utilitzar t-SNE per reduir la dimensionalitat a 2D
tsne = TSNE(n_components=2, random_state=0)
encoded_imgs_2d = tsne.fit_transform(encoded_imgs)

# Visualitzar les representacions comprimides
plt.figure(figsize=(6, 6))
plt.scatter(encoded_imgs_2d[:, 0], encoded_imgs_2d[:, 1], c=y_test, cmap='viridis')
plt.colorbar()
plt.show()</pre></div><div class='content'></div><h2>Explicació del Codi</h2>
<div class='content'><ol>
<li><strong>Visualitzar les representacions comprimides</strong>: Es codifiquen les imatges de test utilitzant el codificador.</li>
<li><strong>t-SNE</strong>: Es redueix la dimensionalitat de les representacions comprimides a 2D utilitzant t-SNE.</li>
<li><strong>Visualització</strong>: Es visualitzen les representacions comprimides en un gràfic de dispersió.</li>
</ol>
</div><h1>Conclusió</h1>
<div class='content'><p>Els autoencoders són una eina poderosa per a la reducció de dimensionalitat i la detecció d'anomalies. Amb una comprensió clara de la seva arquitectura i funcionament, es poden aplicar a una àmplia varietat de problemes en el camp del deep learning.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-01-redes-generativas-adversariales' title="Xarxes Generatives Adversarials (GAN)">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-03-transfer-learning' title="Transfer Learning">
				<span class="d-none d-md-inline">Següent &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<!-- 
<h1>Publicitat</h1>
<p>Aquest espai està destinat a publicitat.</p>
<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
<p>Gràcies per col·laborar!</p>
-->

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725"
     crossorigin="anonymous"></script>
<!-- enterprise_campus -->
<ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-0611338592562725"
     data-ad-slot="6914733106"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
			









		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
