<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="noindex, nofollow, noarchive">
    <title>Regularització i tècniques de millora</title>

    <link rel="alternate" href="https://campusempresa.com/mod/deep_learning/05-04-regularizacion-tecnicas-mejora" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/deep_learning/05-04-regularizacion-tecnicas-mejora" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/deep_learning/05-04-regularization-improvement-techniques" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-2 p-md-0 text-end">
			<span>	<a href="https://enterprisecampus.net/mod/deep_learning/05-04-regularization-improvement-techniques" class="px-2">EN</a></b>
	|
	<a href="https://campusempresa.com/mod/deep_learning/05-04-regularizacion-tecnicas-mejora" class="px-2">ES</a></b>
	|
	<b class="px-2">CA</b>
</span>
			<span class="d-none d-md-inline"><br><cite>Tot el coneixement al teu abast</cite></span>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>

<div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
					 				<a href="/"><i class="bi bi-house-fill"></i> HOME</a>
											</div>
		</div>
	</div>
</div>
		
<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-03-transfer-learning' title="Transfer Learning">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Regularització i tècniques de millora</h2></a>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-introduccion-tensorflow' title="Introducció a TensorFlow">
				<span class="d-none d-md-inline">Següent &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1>Introducció</h1>
<div class='content'><p>La regularització és una tècnica essencial en el deep learning per prevenir el sobreajustament (overfitting) i millorar la capacitat de generalització dels models. En aquesta secció, explorarem diverses tècniques de regularització i altres estratègies per millorar el rendiment dels models de deep learning.</p>
</div><h1>Objectius d'Aprenentatge</h1>
<div class='content'><p>Al final d'aquest tema, hauràs après:</p>
<ul>
<li>Què és la regularització i per què és important.</li>
<li>Diferents tècniques de regularització com la regularització L1 i L2, Dropout, i Data Augmentation.</li>
<li>Estratègies addicionals per millorar el rendiment dels models de deep learning.</li>
</ul>
</div><h1><ol>
<li>Què és la Regularització?</li>
</ol></h1>
<div class='content'><p>La regularització és un conjunt de tècniques utilitzades per reduir l'error de generalització d'un model de deep learning, és a dir, l'error que el model comet quan es troba amb dades noves i no vistes durant l'entrenament. Això es fa afegint informació addicional o restriccions al model per evitar que s'ajusti massa a les dades d'entrenament.</p>
</div><h2>1.1. Importància de la Regularització</h2>
<div class='content'><ul>
<li><strong>Prevenció del sobreajustament:</strong> El sobreajustament ocorre quan un model aprèn massa bé les dades d'entrenament, incloent-hi el soroll i les anomalies, i per tant, no generalitza bé a noves dades.</li>
<li><strong>Millora de la capacitat de generalització:</strong> Un model ben regularitzat és capaç de capturar els patrons subjacents de les dades sense ajustar-se massa a les particularitats de les dades d'entrenament.</li>
</ul>
</div><h1><ol start="2">
<li>Tècniques de Regularització</li>
</ol></h1>
<div class='content'></div><h2>2.1. Regularització L1 i L2</h2>
<div class='content'><h4>Regularització L1 (Lasso)</h4>
<p>La regularització L1 afegeix la suma dels valors absoluts dels pesos al terme de pèrdua. Això tendeix a produir models amb molts pesos iguals a zero, resultant en models més simples i esparsos.</p>
<p><strong>Funció de pèrdua amb regularització L1:</strong>
\[ \text{Loss} = \text{Loss}<em>{\text{original}} + \lambda \sum</em>{i} |w_i| \]</p>
<h4>Regularització L2 (Ridge)</h4>
<p>La regularització L2 afegeix la suma dels quadrats dels pesos al terme de pèrdua. Això tendeix a produir models amb pesos petits però no necessàriament iguals a zero.</p>
<p><strong>Funció de pèrdua amb regularització L2:</strong>
\[ \text{Loss} = \text{Loss}<em>{\text{original}} + \lambda \sum</em>{i} w_i^2 \]</p>
<h4>Exemple de codi en Python:</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLm1vZGVscyBpbXBvcnQgU2VxdWVudGlhbApmcm9tIHRlbnNvcmZsb3cua2VyYXMubGF5ZXJzIGltcG9ydCBEZW5zZQpmcm9tIHRlbnNvcmZsb3cua2VyYXMucmVndWxhcml6ZXJzIGltcG9ydCBsMSwgbDIKCm1vZGVsID0gU2VxdWVudGlhbChbCiAgICBEZW5zZSg2NCwgaW5wdXRfZGltPTEwMCwgYWN0aXZhdGlvbj0ncmVsdScsIGtlcm5lbF9yZWd1bGFyaXplcj1sMSgwLjAxKSksCiAgICBEZW5zZSg2NCwgYWN0aXZhdGlvbj0ncmVsdScsIGtlcm5lbF9yZWd1bGFyaXplcj1sMigwLjAxKSksCiAgICBEZW5zZSgxLCBhY3RpdmF0aW9uPSdzaWdtb2lkJykKXSkKCm1vZGVsLmNvbXBpbGUob3B0aW1pemVyPSdhZGFtJywgbG9zcz0nYmluYXJ5X2Nyb3NzZW50cm9weScsIG1ldHJpY3M9WydhY2N1cmFjeSddKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.regularizers import l1, l2

model = Sequential([
    Dense(64, input_dim=100, activation='relu', kernel_regularizer=l1(0.01)),
    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</pre></div><div class='content'></div><h2>2.2. Dropout</h2>
<div class='content'><p>El Dropout és una tècnica de regularització que consisteix a desactivar aleatòriament un percentatge de neurones durant l'entrenament. Això ajuda a prevenir que les neurones es basin massa en altres neurones específiques, promovent una millor generalització.</p>
<p><strong>Exemple de codi en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgRHJvcG91dAoKbW9kZWwgPSBTZXF1ZW50aWFsKFsKICAgIERlbnNlKDY0LCBpbnB1dF9kaW09MTAwLCBhY3RpdmF0aW9uPSdyZWx1JyksCiAgICBEcm9wb3V0KDAuNSksCiAgICBEZW5zZSg2NCwgYWN0aXZhdGlvbj0ncmVsdScpLAogICAgRHJvcG91dCgwLjUpLAogICAgRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpCl0pCgptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import Dropout

model = Sequential([
    Dense(64, input_dim=100, activation='relu'),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</pre></div><div class='content'></div><h2>2.3. Data Augmentation</h2>
<div class='content'><p>El Data Augmentation és una tècnica que consisteix a generar noves mostres de dades d'entrenament a partir de les existents mitjançant transformacions com rotacions, translacions, i canvis d'escala. Això ajuda a augmentar la diversitat de les dades d'entrenament i millorar la capacitat de generalització del model.</p>
<p><strong>Exemple de codi en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLnByZXByb2Nlc3NpbmcuaW1hZ2UgaW1wb3J0IEltYWdlRGF0YUdlbmVyYXRvcgoKZGF0YWdlbiA9IEltYWdlRGF0YUdlbmVyYXRvcigKICAgIHJvdGF0aW9uX3JhbmdlPTIwLAogICAgd2lkdGhfc2hpZnRfcmFuZ2U9MC4yLAogICAgaGVpZ2h0X3NoaWZ0X3JhbmdlPTAuMiwKICAgIHNoZWFyX3JhbmdlPTAuMiwKICAgIHpvb21fcmFuZ2U9MC4yLAogICAgaG9yaXpvbnRhbF9mbGlwPVRydWUsCiAgICBmaWxsX21vZGU9J25lYXJlc3QnCikKCiMgU3Vwb3NlbSBxdWUgJ3hfdHJhaW4nIGkgJ3lfdHJhaW4nIHPDs24gbGVzIGRhZGVzIGQnZW50cmVuYW1lbnQKZGF0YWdlbi5maXQoeF90cmFpbikKCm1vZGVsLmZpdChkYXRhZ2VuLmZsb3coeF90cmFpbiwgeV90cmFpbiwgYmF0Y2hfc2l6ZT0zMiksIGVwb2Nocz01MCk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.preprocessing.image import ImageDataGenerator

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Suposem que 'x_train' i 'y_train' s&oacute;n les dades d'entrenament
datagen.fit(x_train)

model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=50)</pre></div><div class='content'></div><h1><ol start="3">
<li>Estratègies Addicionals per Millorar el Rendiment</li>
</ol></h1>
<div class='content'></div><h2>3.1. Early Stopping</h2>
<div class='content'><p>L'early stopping és una tècnica que consisteix a parar l'entrenament del model quan el rendiment en les dades de validació deixa de millorar. Això ajuda a prevenir el sobreajustament.</p>
<p><strong>Exemple de codi en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmNhbGxiYWNrcyBpbXBvcnQgRWFybHlTdG9wcGluZwoKZWFybHlfc3RvcHBpbmcgPSBFYXJseVN0b3BwaW5nKG1vbml0b3I9J3ZhbF9sb3NzJywgcGF0aWVuY2U9NSkKCm1vZGVsLmZpdCh4X3RyYWluLCB5X3RyYWluLCB2YWxpZGF0aW9uX3NwbGl0PTAuMiwgZXBvY2hzPTUwLCBjYWxsYmFja3M9W2Vhcmx5X3N0b3BwaW5nXSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=5)

model.fit(x_train, y_train, validation_split=0.2, epochs=50, callbacks=[early_stopping])</pre></div><div class='content'></div><h2>3.2. Batch Normalization</h2>
<div class='content'><p>La Batch Normalization és una tècnica que normalitza les sortides de cada capa per lot (batch) durant l'entrenament. Això ajuda a accelerar l'entrenament i millorar la robustesa del model.</p>
<p><strong>Exemple de codi en Python:</strong></p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("ZnJvbSB0ZW5zb3JmbG93LmtlcmFzLmxheWVycyBpbXBvcnQgQmF0Y2hOb3JtYWxpemF0aW9uCgptb2RlbCA9IFNlcXVlbnRpYWwoWwogICAgRGVuc2UoNjQsIGlucHV0X2RpbT0xMDAsIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIEJhdGNoTm9ybWFsaXphdGlvbigpLAogICAgRGVuc2UoNjQsIGFjdGl2YXRpb249J3JlbHUnKSwKICAgIEJhdGNoTm9ybWFsaXphdGlvbigpLAogICAgRGVuc2UoMSwgYWN0aXZhdGlvbj0nc2lnbW9pZCcpCl0pCgptb2RlbC5jb21waWxlKG9wdGltaXplcj0nYWRhbScsIGxvc3M9J2JpbmFyeV9jcm9zc2VudHJvcHknLCBtZXRyaWNzPVsnYWNjdXJhY3knXSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>from tensorflow.keras.layers import BatchNormalization

model = Sequential([
    Dense(64, input_dim=100, activation='relu'),
    BatchNormalization(),
    Dense(64, activation='relu'),
    BatchNormalization(),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])</pre></div><div class='content'></div><h1>Resum</h1>
<div class='content'><p>En aquesta secció, hem explorat diverses tècniques de regularització i estratègies per millorar el rendiment dels models de deep learning. Hem après sobre la regularització L1 i L2, el Dropout, el Data Augmentation, l'early stopping i la batch normalization. Aquestes tècniques són fonamentals per construir models robustos i capaços de generalitzar bé a noves dades.</p>
<p>En el pròxim mòdul, explorarem les eines i frameworks més populars per implementar models de deep learning, com TensorFlow i PyTorch.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='05-03-transfer-learning' title="Transfer Learning">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='06-01-introduccion-tensorflow' title="Introducció a TensorFlow">
				<span class="d-none d-md-inline">Següent &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<!-- 
	<h1>Publicitat</h1>
	<p>Aquest espai està destinat a publicitat.</p>
	<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
	<p>Gràcies per col·laborar!</p>
	 -->
			









		</div>
	</div>
</div>

<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
