<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="robots" content="index, follow, noarchive">
    <title>Clustering: K-means</title>

    <link rel="alternate" href="https://campusempresa.com/mod/machine_learning/05-01-clustering-k-means" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/machine_learning/05-01-clustering-k-means" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/machine_learning/05-01-clustering-k-means" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css?v=4" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script>var DEVELOP = window.location.href.indexOf("localhost")!=-1 && true;</script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
	<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-0611338592562725" crossorigin="anonymous"></script>  	
	</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-6 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-6 p-0 text-end">
			<p class="mb-0 p-0">	<a href="https://enterprisecampus.net/mod/machine_learning/05-01-clustering-k-means" class="px-2">EN</a></b>
	|
	<a href="https://campusempresa.com/mod/machine_learning/05-01-clustering-k-means" class="px-2">ES</a></b>
	|
	<b class="px-2">CA</b>
</p>
			<p class="mb-4 mt-0 mx-2  d-none d-md-block"><cite>Tot el coneixement al teu abast</cite></p>
		</div>
	</div>
</div>
<div class="subheader container-xxl d-none d-md-block">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>
		<div class="top-bar container-fluid p-0">
	<div class="container-xxl p-0">
		<div class="row">
			<div class="col" id="left_menu">
					<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contingut del curs
	</a>

			</div>
		</div>
	</div>
</div>

<!--  
<div class="top-bar container-fluid">
	<div class="container-xxl">
		<nav class="navbar navbar-expand-md p-0">
			<div class="container-fluid">
				<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
					<span class="navbar-toggler-icon"></span>
				</button>
				
				<div class="collapse navbar-collapse" id="navbarNav">
					<div class="navbar-nav me-auto">
							<a href="/"  class="nav-link px-3">
		<i class="bi bi-house-fill"></i>
		HOME
	</a>

	<a href="./"  class="nav-link px-3">
		<i class="bi bi-journal-bookmark"></i>
		Contingut del curs
	</a>

					</div>
				</div>			
							</div>
		</nav>
	</div>
</div>
 -->				<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
				<div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-06-redes-neuronales' title="Xarxes neuronals">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
					<h2 style="text-decoration:underline">Clustering: K-means</h2>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-02-clustering-jerarquico' title="Clustering jeràrquic">
				<span class="d-none d-md-inline">Següent &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>
<div class='content'></div><h1>Introducció al Clustering</h1>
<div class='content'><p>El clustering és una tècnica de machine learning no supervisat que s'utilitza per agrupar dades en subconjunts (clusters) de manera que els elements dins de cada cluster siguin més similars entre ells que amb els elements d'altres clusters. K-means és un dels algorismes de clustering més populars i àmpliament utilitzats.</p>
</div><h1>Què és K-means?</h1>
<div class='content'><p>K-means és un algorisme de clustering iteratiu que divideix un conjunt de dades en K clusters, on K és un paràmetre definit per l'usuari. L'objectiu és minimitzar la variància dins de cada cluster.</p>
</div><h2>Passos de l'algorisme K-means</h2>
<div class='content'><ol>
<li><strong>Inicialització</strong>: Seleccionar K punts inicials (centroides) de manera aleatòria o utilitzant una tècnica específica.</li>
<li><strong>Assignació</strong>: Assignar cada punt de dades al centreide més proper.</li>
<li><strong>Actualització</strong>: Recalcular els centroides com la mitjana dels punts assignats a cada cluster.</li>
<li><strong>Iteració</strong>: Repetir els passos d'assignació i actualització fins que els centroides no canviïn significativament o es compleixi un criteri de parada.</li>
</ol>
</div><h2>Exemple de K-means</h2>
<div class='content'><p>Suposem que tenim un conjunt de dades bidimensional amb els següents punts:</p>
<table>
<thead>
<tr>
<th>Punt</th>
<th>X</th>
<th>Y</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>B</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>C</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>D</td>
<td>8</td>
<td>7</td>
</tr>
<tr>
<td>E</td>
<td>9</td>
<td>8</td>
</tr>
<tr>
<td>F</td>
<td>10</td>
<td>9</td>
</tr>
</tbody>
</table>
<p>Volem agrupar aquests punts en 2 clusters (K=2).</p>
<h4>Inicialització</h4>
<p>Seleccionem dos punts inicials com a centroides, per exemple, A (1,2) i D (8,7).</p>
<h4>Assignació</h4>
<p>Calcularem la distància euclidiana de cada punt als centroides i assignarem cada punt al centreide més proper.</p>
<table>
<thead>
<tr>
<th>Punt</th>
<th>Distància a (1,2)</th>
<th>Distància a (8,7)</th>
<th>Assignació</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>0</td>
<td>9.22</td>
<td>(1,2)</td>
</tr>
<tr>
<td>B</td>
<td>1.41</td>
<td>7.81</td>
<td>(1,2)</td>
</tr>
<tr>
<td>C</td>
<td>2.83</td>
<td>6.40</td>
<td>(1,2)</td>
</tr>
<tr>
<td>D</td>
<td>9.22</td>
<td>0</td>
<td>(8,7)</td>
</tr>
<tr>
<td>E</td>
<td>10.63</td>
<td>1.41</td>
<td>(8,7)</td>
</tr>
<tr>
<td>F</td>
<td>12.04</td>
<td>2.83</td>
<td>(8,7)</td>
</tr>
</tbody>
</table>
<h4>Actualització</h4>
<p>Recalculem els centroides com la mitjana dels punts assignats a cada cluster.</p>
<ul>
<li>Nou centreide per (1,2): mitjana de A, B, C = ((1+2+3)/3, (2+3+4)/3) = (2,3)</li>
<li>Nou centreide per (8,7): mitjana de D, E, F = ((8+9+10)/3, (7+8+9)/3) = (9,8)</li>
</ul>
<h4>Iteració</h4>
<p>Repetim els passos d'assignació i actualització fins que els centroides no canviïn significativament.</p>
</div><h1>Implementació en Python</h1>
<div class='content'><p>A continuació, es mostra una implementació bàsica de K-means utilitzant la biblioteca <code>scikit-learn</code> en Python.</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBza2xlYXJuLmNsdXN0ZXIgaW1wb3J0IEtNZWFucwoKIyBEYWRlcyBkJ2V4ZW1wbGUKWCA9IG5wLmFycmF5KFtbMSwgMl0sIFsyLCAzXSwgWzMsIDRdLCBbOCwgN10sIFs5LCA4XSwgWzEwLCA5XV0pCgojIENyZWFyIGVsIG1vZGVsIEstbWVhbnMKa21lYW5zID0gS01lYW5zKG5fY2x1c3RlcnM9MiwgcmFuZG9tX3N0YXRlPTApCgojIEFqdXN0YXIgZWwgbW9kZWwgYSBsZXMgZGFkZXMKa21lYW5zLmZpdChYKQoKIyBQcmVkaXIgZWxzIGNsdXN0ZXJzCnlfa21lYW5zID0ga21lYW5zLnByZWRpY3QoWCkKCiMgVmlzdWFsaXR6YXIgZWxzIHJlc3VsdGF0cwpwbHQuc2NhdHRlcihYWzosIDBdLCBYWzosIDFdLCBjPXlfa21lYW5zLCBzPTUwLCBjbWFwPSd2aXJpZGlzJykKY2VudHJvaWRzID0ga21lYW5zLmNsdXN0ZXJfY2VudGVyc18KcGx0LnNjYXR0ZXIoY2VudHJvaWRzWzosIDBdLCBjZW50cm9pZHNbOiwgMV0sIGM9J3JlZCcsIHM9MjAwLCBhbHBoYT0wLjc1KQpwbHQuc2hvdygp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Dades d'exemple
X = np.array([[1, 2], [2, 3], [3, 4], [8, 7], [9, 8], [10, 9]])

# Crear el model K-means
kmeans = KMeans(n_clusters=2, random_state=0)

# Ajustar el model a les dades
kmeans.fit(X)

# Predir els clusters
y_kmeans = kmeans.predict(X)

# Visualitzar els resultats
plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')
centroids = kmeans.cluster_centers_
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75)
plt.show()</pre></div><div class='content'></div><h2>Explicació del codi</h2>
<div class='content'><ol>
<li><strong>Importació de biblioteques</strong>: Importem <code>numpy</code> per a la manipulació de dades, <code>matplotlib</code> per a la visualització i <code>KMeans</code> de <code>scikit-learn</code> per a l'algorisme K-means.</li>
<li><strong>Dades d'exemple</strong>: Definim un conjunt de dades bidimensional.</li>
<li><strong>Crear el model K-means</strong>: Inicialitzem el model K-means amb 2 clusters.</li>
<li><strong>Ajustar el model</strong>: Ajustem el model a les dades.</li>
<li><strong>Predir els clusters</strong>: Utilitzem el model per predir els clusters de les dades.</li>
<li><strong>Visualitzar els resultats</strong>: Visualitzem els punts de dades i els centroides dels clusters.</li>
</ol>
</div><h1>Exercici Pràctic</h1>
<div class='content'></div><h2>Exercici</h2>
<div class='content'><p>Utilitza l'algorisme K-means per agrupar el següent conjunt de dades en 3 clusters:</p>
<table>
<thead>
<tr>
<th>Punt</th>
<th>X</th>
<th>Y</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>B</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>C</td>
<td>3</td>
<td>4</td>
</tr>
<tr>
<td>D</td>
<td>5</td>
<td>7</td>
</tr>
<tr>
<td>E</td>
<td>3</td>
<td>5</td>
</tr>
<tr>
<td>F</td>
<td>8</td>
<td>9</td>
</tr>
<tr>
<td>G</td>
<td>5</td>
<td>6</td>
</tr>
<tr>
<td>H</td>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td>I</td>
<td>6</td>
<td>8</td>
</tr>
<tr>
<td>J</td>
<td>7</td>
<td>9</td>
</tr>
</tbody>
</table>
</div><h2>Solució</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG51bXB5IGFzIG5wCmltcG9ydCBtYXRwbG90bGliLnB5cGxvdCBhcyBwbHQKZnJvbSBza2xlYXJuLmNsdXN0ZXIgaW1wb3J0IEtNZWFucwoKIyBEYWRlcyBkJ2V4ZW1wbGUKWCA9IG5wLmFycmF5KFtbMSwgMl0sIFsyLCAxXSwgWzMsIDRdLCBbNSwgN10sIFszLCA1XSwgWzgsIDldLCBbNSwgNl0sIFs0LCA1XSwgWzYsIDhdLCBbNywgOV1dKQoKIyBDcmVhciBlbCBtb2RlbCBLLW1lYW5zCmttZWFucyA9IEtNZWFucyhuX2NsdXN0ZXJzPTMsIHJhbmRvbV9zdGF0ZT0wKQoKIyBBanVzdGFyIGVsIG1vZGVsIGEgbGVzIGRhZGVzCmttZWFucy5maXQoWCkKCiMgUHJlZGlyIGVscyBjbHVzdGVycwp5X2ttZWFucyA9IGttZWFucy5wcmVkaWN0KFgpCgojIFZpc3VhbGl0emFyIGVscyByZXN1bHRhdHMKcGx0LnNjYXR0ZXIoWFs6LCAwXSwgWFs6LCAxXSwgYz15X2ttZWFucywgcz01MCwgY21hcD0ndmlyaWRpcycpCmNlbnRyb2lkcyA9IGttZWFucy5jbHVzdGVyX2NlbnRlcnNfCnBsdC5zY2F0dGVyKGNlbnRyb2lkc1s6LCAwXSwgY2VudHJvaWRzWzosIDFdLCBjPSdyZWQnLCBzPTIwMCwgYWxwaGE9MC43NSkKcGx0LnNob3coKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Dades d'exemple
X = np.array([[1, 2], [2, 1], [3, 4], [5, 7], [3, 5], [8, 9], [5, 6], [4, 5], [6, 8], [7, 9]])

# Crear el model K-means
kmeans = KMeans(n_clusters=3, random_state=0)

# Ajustar el model a les dades
kmeans.fit(X)

# Predir els clusters
y_kmeans = kmeans.predict(X)

# Visualitzar els resultats
plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')
centroids = kmeans.cluster_centers_
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75)
plt.show()</pre></div><div class='content'></div><h2>Explicació de la Solució</h2>
<div class='content'><ol>
<li><strong>Dades d'exemple</strong>: Definim el conjunt de dades proporcionat.</li>
<li><strong>Crear el model K-means</strong>: Inicialitzem el model K-means amb 3 clusters.</li>
<li><strong>Ajustar el model</strong>: Ajustem el model a les dades.</li>
<li><strong>Predir els clusters</strong>: Utilitzem el model per predir els clusters de les dades.</li>
<li><strong>Visualitzar els resultats</strong>: Visualitzem els punts de dades i els centroides dels clusters.</li>
</ol>
</div><h1>Errors Comuns i Consells</h1>
<div class='content'><ul>
<li><strong>Selecció del valor de K</strong>: Un valor inadequat de K pot resultar en clusters poc significatius. Utilitza tècniques com l'elbow method per determinar el valor òptim de K.</li>
<li><strong>Inicialització dels centroides</strong>: La selecció inicial dels centroides pot afectar el resultat final. Utilitza inicialitzacions com K-means++ per millorar la convergència.</li>
<li><strong>Escalatge de dades</strong>: Assegura't que les dades estiguin escalades (normalitzades o estandarditzades) per evitar que les dimensions amb rangs més grans dominin la distància euclidiana.</li>
</ul>
</div><h1>Conclusió</h1>
<div class='content'><p>L'algorisme K-means és una eina poderosa per agrupar dades en clusters significatius. Tot i que és senzill d'implementar, la seva eficàcia depèn de la selecció adequada del nombre de clusters i de la inicialització dels centroides. Amb una comprensió clara dels seus passos i una implementació acurada, K-means pot proporcionar insights valuosos en l'anàlisi de dades.</p>
</div><div class='row navigation'>
	<div class='col-1 col-md-2'>
					<a href='04-06-redes-neuronales' title="Xarxes neuronals">
				<span class="d-none d-md-inline">&#x25C4; Anterior</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-left-square-fill"></i></span>
			</a>
			</div>
	<div class='col-10 col-md-8 text-center'>
			</div>
	<div class='col-1 col-md-2 text-end'>
					<a href='05-02-clustering-jerarquico' title="Clustering jeràrquic">
				<span class="d-none d-md-inline">Següent &#x25BA;</span>
				<span class="d-inline d-md-none"><i class="bi bi-caret-right-square-fill"></i></span>
			</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
				<!-- 
	<h1>Publicitat</h1>
	<p>Aquest espai està destinat a publicitat.</p>
	<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
	<p>Gràcies per col·laborar!</p>
	 -->
			
	<div class="container mt-2 d-none d-md-block index">
		<h1>Curs de Machine Learning</h1>
<h2>Mòdul 1: Introducció al Machine Learning</h2>
<ul>
<li><a href="01-01-que-es-machine-learning">Què és el Machine Learning?</a></li>
<li><a href="01-02-historia-evolucion-machine-learning">Història i evolució del Machine Learning</a></li>
<li><a href="01-03-tipos-machine-learning">Tipus de Machine Learning</a></li>
<li><a href="01-04-aplicaciones-machine-learning">Aplicacions del Machine Learning</a></li>
</ul>
<h2>Mòdul 2: Fonaments d'Estadística i Probabilitat</h2>
<ul>
<li><a href="02-01-conceptos-basicos-estadistica">Conceptes bàsics d'estadística</a></li>
<li><a href="02-02-distribuciones-probabilidad">Distribucions de probabilitat</a></li>
<li><a href="02-03-inferencia-estadistica">Inferència estadística</a></li>
<li><a href="02-04-teorema-bayes">Teorema de Bayes</a></li>
</ul>
<h2>Mòdul 3: Preprocessament de Dades</h2>
<ul>
<li><a href="03-01-limpieza-datos">Neteja de dades</a></li>
<li><a href="03-02-transformacion-datos">Transformació de dades</a></li>
<li><a href="03-03-normalizacion-estandarizacion">Normalització i estandardització</a></li>
<li><a href="03-04-manejo-datos-faltantes">Gestió de dades mancants</a></li>
</ul>
<h2>Mòdul 4: Algoritmes de Machine Learning Supervisat</h2>
<ul>
<li><a href="04-01-regresion-lineal">Regressió lineal</a></li>
<li><a href="04-02-regresion-logistica">Regressió logística</a></li>
<li><a href="04-03-arboles-decision">Arbres de decisió</a></li>
<li><a href="04-04-svm">Màquines de suport vectorial (SVM)</a></li>
<li><a href="04-05-knn">K-Veïns més propers (K-NN)</a></li>
<li><a href="04-06-redes-neuronales">Xarxes neuronals</a></li>
</ul>
<h2>Mòdul 5: Algoritmes de Machine Learning No Supervisat</h2>
<ul>
<li><a href="05-01-clustering-k-means">Clustering: K-means</a></li>
<li><a href="05-02-clustering-jerarquico">Clustering jeràrquic</a></li>
<li><a href="05-03-pca">Anàlisi de components principals (PCA)</a></li>
<li><a href="05-04-dbscan">Anàlisi d'agrupament DBSCAN</a></li>
</ul>
<h2>Mòdul 6: Avaluació i Validació de Models</h2>
<ul>
<li><a href="06-01-metricas-evaluacion">Mètriques d'avaluació</a></li>
<li><a href="06-02-validacion-cruzada">Validació creuada</a></li>
<li><a href="06-03-curva-roc-auc">Corba ROC i AUC</a></li>
<li><a href="06-04-overfitting-underfitting">Overfitting i underfitting</a></li>
</ul>
<h2>Mòdul 7: Tècniques Avançades i Optimització</h2>
<ul>
<li><a href="07-01-ensemble-learning">Ensemble Learning</a></li>
<li><a href="07-02-gradient-boosting">Gradient Boosting</a></li>
<li><a href="07-03-deep-learning">Xarxes neuronals profundes (Deep Learning)</a></li>
<li><a href="07-04-optimizacion-hiperparametros">Optimització d'hiperparàmetres</a></li>
</ul>
<h2>Mòdul 8: Implementació i Desplegament de Models</h2>
<ul>
<li><a href="08-01-frameworks-bibliotecas">Frameworks i biblioteques populars</a></li>
<li><a href="08-02-implementacion-produccion">Implementació de models en producció</a></li>
<li><a href="08-03-mantenimiento-monitoreo">Manteniment i monitoratge de models</a></li>
<li><a href="08-04-etica-privacidad">Consideracions ètiques i de privacitat</a></li>
</ul>
<h2>Mòdul 9: Projectes Pràctics</h2>
<ul>
<li><a href="09-01-proyecto-prediccion-precios-viviendas">Projecte 1: Predicció de preus d'habitatges</a></li>
<li><a href="09-02-proyecto-clasificacion-imagenes">Projecte 2: Classificació d'imatges</a></li>
<li><a href="09-03-proyecto-analisis-sentimientos">Projecte 3: Anàlisi de sentiments a xarxes socials</a></li>
<li><a href="09-04-proyecto-deteccion-fraudes">Projecte 4: Detecció de fraus</a></li>
</ul>
<h2>Mòdul 10: Recursos Addicionals</h2>
<ul>
<li><a href="10-01-libros-recomendados">Llibres recomanats</a></li>
<li><a href="10-02-cursos-en-linea">Cursos en línia</a></li>
<li><a href="10-03-comunidades-foros">Comunitats i fòrums</a></li>
<li><a href="10-04-herramientas-software">Eines i programari</a></li>
</ul>

	</div>










		</div>
	</div>
</div>		
<div class="container-xxl d-block d-md-none">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
			<a href="/objective">El Projecte</a> | 
<a href="/about">Sobre nosaltres</a> | 
<a href="/contribute">Contribuir</a> | 
<a href="/donate">Donacions</a> | 
<a href="/licence">Llicència</a>
		</div>
	</div>
</div>

<div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
	<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" crossorigin="anonymous"></script>
</body>
</html>
