<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kafka amb Hadoop</title>

    <link rel="alternate" href="https://campusempresa.com/mod/kafka/06-01-kafka-hadoop" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/kafka/06-01-kafka-hadoop" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/kafka/06-01-kafka-hadoop" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="https://enterprisecampus.net/mod/kafka/06-01-kafka-hadoop" class="px-2">EN</a></b>
				|
				<a href="https://campusempresa.com/mod/kafka/06-01-kafka-hadoop" class="px-2">ES</a></b>
				|
				<b class="px-2">CA</b>
											</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Projecte</a>
				<a href="/about">Sobre nosaltres</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donacions</a>
				<a href="/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='05-04-kafka-streams-advanced' title="Kafka Streams Avançat">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Kafka amb Hadoop</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='06-02-kafka-spark' title="Kafka amb Spark">Següent &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducció</h1>
<div class='content'><p>En aquest tema, explorarem com integrar Kafka amb Hadoop per aprofitar les capacitats de processament de dades massives d'Hadoop amb la capacitat de transmissió de dades en temps real de Kafka. Aquesta combinació és molt potent per a aplicacions que necessiten processar grans volums de dades en temps real i emmagatzemar-les per a anàlisis posteriors.</p>
</div><h1>Objectius</h1>
<div class='content'><ul>
<li>Entendre la integració entre Kafka i Hadoop.</li>
<li>Configurar Kafka Connect per enviar dades de Kafka a Hadoop.</li>
<li>Utilitzar eines com Apache Flume i Apache Nifi per a la integració.</li>
<li>Realitzar un exemple pràctic d'integració.</li>
</ul>
</div><h1>Conceptes Clau</h1>
<div class='content'></div><h2>1. Integració de Kafka i Hadoop</h2>
<div class='content'><p>Kafka i Hadoop es poden integrar de diverses maneres per aprofitar les seves capacitats complementàries:</p>
<ul>
<li><strong>Kafka Connect</strong>: Un framework per moure dades entre Kafka i altres sistemes, incloent Hadoop.</li>
<li><strong>Apache Flume</strong>: Un servei distribuït per recollir, agregar i moure grans quantitats de dades de registre.</li>
<li><strong>Apache Nifi</strong>: Una eina de processament de dades que facilita la integració de dades entre sistemes.</li>
</ul>
</div><h2>2. Kafka Connect</h2>
<div class='content'><p>Kafka Connect és una eina potent per moure dades entre Kafka i altres sistemes. Inclou connectors per a diverses bases de dades, sistemes de fitxers i altres sistemes de dades.</p>
<h4>Configuració de Kafka Connect per Hadoop</h4>
<ol>
<li><strong>Instal·lació de Kafka Connect</strong>: Assegura't que Kafka Connect estigui instal·lat i configurat correctament.</li>
<li><strong>Connector HDFS</strong>: Utilitza el connector HDFS per enviar dades de Kafka a Hadoop.</li>
</ol>
</div><h2>3. Apache Flume</h2>
<div class='content'><p>Apache Flume és una eina per recollir, agregar i moure grans quantitats de dades de registre. Pot ser utilitzat per enviar dades de Kafka a Hadoop.</p>
<h4>Configuració de Flume per Kafka i Hadoop</h4>
<ol>
<li><strong>Instal·lació de Flume</strong>: Assegura't que Flume estigui instal·lat i configurat correctament.</li>
<li><strong>Agent de Flume</strong>: Configura un agent de Flume per llegir dades de Kafka i escriure-les a HDFS.</li>
</ol>
</div><h2>4. Apache Nifi</h2>
<div class='content'><p>Apache Nifi és una eina de processament de dades que facilita la integració de dades entre sistemes. Pot ser utilitzat per moure dades de Kafka a Hadoop.</p>
<h4>Configuració de Nifi per Kafka i Hadoop</h4>
<ol>
<li><strong>Instal·lació de Nifi</strong>: Assegura't que Nifi estigui instal·lat i configurat correctament.</li>
<li><strong>Processadors de Nifi</strong>: Configura processadors de Nifi per llegir dades de Kafka i escriure-les a HDFS.</li>
</ol>
</div><h1>Exemple Pràctic</h1>
<div class='content'></div><h2>Configuració de Kafka Connect per enviar dades a Hadoop</h2>
<div class='content'><ol>
<li>
<p><strong>Instal·lació del Connector HDFS</strong>:</p>
<pre><code class="language-bash">confluent-hub install confluentinc/kafka-connect-hdfs:latest
</code></pre>
</li>
<li>
<p><strong>Configuració del Connector HDFS</strong>:
Crea un fitxer de configuració <code>hdfs-sink.properties</code> amb el següent contingut:</p>
<pre><code class="language-properties">name=hdfs-sink
connector.class=io.confluent.connect.hdfs.HdfsSinkConnector
tasks.max=1
topics=your_topic
hdfs.url=hdfs://namenode:8020
flush.size=3
</code></pre>
</li>
<li>
<p><strong>Inici del Connector</strong>:</p>
<pre><code class="language-bash">connect-standalone connect-standalone.properties hdfs-sink.properties
</code></pre>
</li>
</ol>
</div><h2>Configuració de Flume per enviar dades a Hadoop</h2>
<div class='content'><ol>
<li>
<p><strong>Instal·lació de Flume</strong>:</p>
<pre><code class="language-bash">sudo apt-get install flume-ng
</code></pre>
</li>
<li>
<p><strong>Configuració de l'Agent de Flume</strong>:
Crea un fitxer de configuració <code>flume.conf</code> amb el següent contingut:</p>
<pre><code class="language-properties">agent.sources = kafka-source
agent.sinks = hdfs-sink
agent.channels = memory-channel

agent.sources.kafka-source.type = org.apache.flume.source.kafka.KafkaSource
agent.sources.kafka-source.kafka.bootstrap.servers = localhost:9092
agent.sources.kafka-source.kafka.topics = your_topic

agent.sinks.hdfs-sink.type = hdfs
agent.sinks.hdfs-sink.hdfs.path = hdfs://namenode:8020/user/flume/events
agent.sinks.hdfs-sink.hdfs.fileType = DataStream

agent.channels.memory-channel.type = memory
agent.channels.memory-channel.capacity = 1000
agent.channels.memory-channel.transactionCapacity = 100

agent.sources.kafka-source.channels = memory-channel
agent.sinks.hdfs-sink.channel = memory-channel
</code></pre>
</li>
<li>
<p><strong>Inici de l'Agent de Flume</strong>:</p>
<pre><code class="language-bash">flume-ng agent --conf ./conf --conf-file flume.conf --name agent -Dflume.root.logger=INFO,console
</code></pre>
</li>
</ol>
</div><h1>Exercici Pràctic</h1>
<div class='content'></div><h2>Objectiu</h2>
<div class='content'><p>Configurar un pipeline de dades que llegeixi missatges d'un tema de Kafka i els escrigui a HDFS utilitzant Kafka Connect.</p>
</div><h2>Passos</h2>
<div class='content'><ol>
<li>Instal·la i configura Kafka Connect.</li>
<li>Configura el connector HDFS per llegir dades de Kafka i escriure-les a HDFS.</li>
<li>Envia missatges a un tema de Kafka.</li>
<li>Verifica que els missatges es troben a HDFS.</li>
</ol>
</div><h2>Solució</h2>
<div class='content'><ol>
<li>
<p><strong>Instal·lació del Connector HDFS</strong>:</p>
<pre><code class="language-bash">confluent-hub install confluentinc/kafka-connect-hdfs:latest
</code></pre>
</li>
<li>
<p><strong>Configuració del Connector HDFS</strong>:
Crea un fitxer de configuració <code>hdfs-sink.properties</code> amb el següent contingut:</p>
<pre><code class="language-properties">name=hdfs-sink
connector.class=io.confluent.connect.hdfs.HdfsSinkConnector
tasks.max=1
topics=your_topic
hdfs.url=hdfs://namenode:8020
flush.size=3
</code></pre>
</li>
<li>
<p><strong>Inici del Connector</strong>:</p>
<pre><code class="language-bash">connect-standalone connect-standalone.properties hdfs-sink.properties
</code></pre>
</li>
<li>
<p><strong>Enviament de Missatges a Kafka</strong>:</p>
<pre><code class="language-bash">kafka-console-producer --broker-list localhost:9092 --topic your_topic
</code></pre>
</li>
<li>
<p><strong>Verificació a HDFS</strong>:</p>
<pre><code class="language-bash">hdfs dfs -ls /user/flume/events
</code></pre>
</li>
</ol>
</div><h1>Conclusió</h1>
<div class='content'><p>En aquest tema, hem après com integrar Kafka amb Hadoop utilitzant diverses eines com Kafka Connect, Apache Flume i Apache Nifi. Hem vist com configurar aquestes eines per moure dades de Kafka a Hadoop i hem realitzat un exemple pràctic per reforçar els conceptes apresos. Aquesta integració permet aprofitar les capacitats de transmissió de dades en temps real de Kafka i les capacitats de processament de dades massives d'Hadoop, oferint una solució potent per a aplicacions de dades massives.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='05-04-kafka-streams-advanced' title="Kafka Streams Avançat">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='06-02-kafka-spark' title="Kafka amb Spark">Següent &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
