<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cloud Dataflow</title>

    <link rel="alternate" href="https://campusempresa.com/mod/gcp/04-02-cloud-dataflow" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/gcp/04-02-cloud-dataflow" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/gcp/04-02-cloud-dataflow" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
							<a href="https://enterprisecampus.net/mod/gcp/04-02-cloud-dataflow" class="px-2">EN</a></b>
				|
				<a href="https://campusempresa.com/mod/gcp/04-02-cloud-dataflow" class="px-2">ES</a></b>
				|
				<b class="px-2">CA</b>
											</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Projecte</a>
				<a href="/about">Sobre nosaltres</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donacions</a>
				<a href="/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='04-01-bigquery' title="BigQuery">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Cloud Dataflow</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='04-03-cloud-dataproc' title="Cloud Dataproc">Següent &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1><p>Introducció a Cloud Dataflow</p>
</h1>
<div class='content'><p>Cloud Dataflow és un servei de processament de dades completament gestionat que permet l'execució de pipelines de dades en temps real i per lots. Utilitza el model de programació Apache Beam, que permet definir pipelines de dades de manera unificada per a diferents entorns d'execució.</p>
</div><h2><p>Objectius d'aquest tema:</p>
</h2>
<div class='content'><ol>
<li>Comprendre què és Cloud Dataflow i les seves aplicacions.</li>
<li>Aprendre a crear i executar pipelines de dades amb Apache Beam.</li>
<li>Conèixer les millors pràctiques per optimitzar el rendiment de les pipelines.</li>
</ol>
</div><h1><p>Què és Cloud Dataflow?</p>
</h1>
<div class='content'><p>Cloud Dataflow és una eina poderosa per al processament de dades que ofereix:</p>
<ul>
<li><strong>Processament en temps real i per lots</strong>: Permet processar dades en temps real (streaming) i per lots (batch) amb la mateixa API.</li>
<li><strong>Escalabilitat automàtica</strong>: S'adapta automàticament a la càrrega de treball, escalant cap amunt o cap avall segons sigui necessari.</li>
<li><strong>Integració amb altres serveis de GCP</strong>: Es pot integrar fàcilment amb altres serveis com BigQuery, Cloud Storage, Pub/Sub, entre d'altres.</li>
</ul>
</div><h1><p>Components clau de Cloud Dataflow</p>
</h1>
<div class='content'><ol>
<li><strong>Pipelines</strong>: Seqüències de transformacions que processen les dades d'entrada i produeixen dades de sortida.</li>
<li><strong>PCollections</strong>: Col·leccions de dades que flueixen a través de les pipelines.</li>
<li><strong>Transformacions</strong>: Operacions aplicades a les PCollections per transformar les dades.</li>
<li><strong>Runners</strong>: Entorns d'execució que processen les pipelines. Cloud Dataflow és un dels runners disponibles per a Apache Beam.</li>
</ol>
</div><h1><p>Exemple pràctic: Creació d'una pipeline bàsica</p>
</h1>
<div class='content'><p>A continuació, es mostra un exemple de com crear una pipeline bàsica amb Apache Beam i executar-la a Cloud Dataflow.</p>
</div><h2><p>Pas 1: Configuració del projecte</p>
</h2>
<div class='content'><p>Abans de començar, assegura't de tenir un projecte de GCP configurat i el SDK de Google Cloud instal·lat.</p>
</div><h2><p>Pas 2: Instal·lació de les dependències</p>
</h2>
<div class='content'><p>Instal·la Apache Beam i el connector de Google Cloud Dataflow:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cGlwIGluc3RhbGwgYXBhY2hlLWJlYW1bZ2NwXQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>pip install apache-beam[gcp]</pre></div><div class='content'></div><h2><p>Pas 3: Creació de la pipeline</p>
</h2>
<div class='content'><p>Crea un fitxer Python (per exemple, <code>dataflow_pipeline.py</code>) amb el següent codi:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGFwYWNoZV9iZWFtIGFzIGJlYW0KZnJvbSBhcGFjaGVfYmVhbS5vcHRpb25zLnBpcGVsaW5lX29wdGlvbnMgaW1wb3J0IFBpcGVsaW5lT3B0aW9ucywgR29vZ2xlQ2xvdWRPcHRpb25zCgojIENvbmZpZ3VyYWNpw7MgZGUgbGVzIG9wY2lvbnMgZGUgbGEgcGlwZWxpbmUKb3B0aW9ucyA9IFBpcGVsaW5lT3B0aW9ucygpCmdvb2dsZV9jbG91ZF9vcHRpb25zID0gb3B0aW9ucy52aWV3X2FzKEdvb2dsZUNsb3VkT3B0aW9ucykKZ29vZ2xlX2Nsb3VkX29wdGlvbnMucHJvamVjdCA9ICdlbC10ZXUtcHJvamVjdGUtZ2NwJwpnb29nbGVfY2xvdWRfb3B0aW9ucy5qb2JfbmFtZSA9ICdleGVtcGxlLXBpcGVsaW5lJwpnb29nbGVfY2xvdWRfb3B0aW9ucy50ZW1wX2xvY2F0aW9uID0gJ2dzOi8vZWwtdGV1LWJ1Y2tldC90ZW1wJwpnb29nbGVfY2xvdWRfb3B0aW9ucy5zdGFnaW5nX2xvY2F0aW9uID0gJ2dzOi8vZWwtdGV1LWJ1Y2tldC9zdGFnaW5nJwpvcHRpb25zLnZpZXdfYXMoUGlwZWxpbmVPcHRpb25zKS5ydW5uZXIgPSAnRGF0YWZsb3dSdW5uZXInCgojIERlZmluaWNpw7MgZGUgbGEgcGlwZWxpbmUKd2l0aCBiZWFtLlBpcGVsaW5lKG9wdGlvbnM9b3B0aW9ucykgYXMgcDoKICAgIChwCiAgICAgfCAnTGxlZ2lyIG1pc3NhdGdlcycgPj4gYmVhbS5pby5SZWFkRnJvbVRleHQoJ2dzOi8vZWwtdGV1LWJ1Y2tldC9pbnB1dC50eHQnKQogICAgIHwgJ1RyYW5zZm9ybWFyIGEgbWFqw7pzY3VsZXMnID4+IGJlYW0uTWFwKGxhbWJkYSB4OiB4LnVwcGVyKCkpCiAgICAgfCAnRXNjcml1cmUgcmVzdWx0YXRzJyA+PiBiZWFtLmlvLldyaXRlVG9UZXh0KCdnczovL2VsLXRldS1idWNrZXQvb3V0cHV0LnR4dCcpKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions

# Configuraci&oacute; de les opcions de la pipeline
options = PipelineOptions()
google_cloud_options = options.view_as(GoogleCloudOptions)
google_cloud_options.project = 'el-teu-projecte-gcp'
google_cloud_options.job_name = 'exemple-pipeline'
google_cloud_options.temp_location = 'gs://el-teu-bucket/temp'
google_cloud_options.staging_location = 'gs://el-teu-bucket/staging'
options.view_as(PipelineOptions).runner = 'DataflowRunner'

# Definici&oacute; de la pipeline
with beam.Pipeline(options=options) as p:
    (p
     | 'Llegir missatges' &gt;&gt; beam.io.ReadFromText('gs://el-teu-bucket/input.txt')
     | 'Transformar a maj&uacute;scules' &gt;&gt; beam.Map(lambda x: x.upper())
     | 'Escriure resultats' &gt;&gt; beam.io.WriteToText('gs://el-teu-bucket/output.txt'))</pre></div><div class='content'></div><h2><p>Pas 4: Executar la pipeline</p>
</h2>
<div class='content'><p>Executa la pipeline amb el següent comandament:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cHl0aG9uIGRhdGFmbG93X3BpcGVsaW5lLnB5"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>python dataflow_pipeline.py</pre></div><div class='content'></div><h1><p>Millors pràctiques per a Cloud Dataflow</p>
</h1>
<div class='content'><ol>
<li><strong>Utilitza les transformacions combinades</strong>: Per reduir la quantitat de dades transferides entre nodes.</li>
<li><strong>Optimitza l'ús de memòria</strong>: Utilitza transformacions que minimitzin l'ús de memòria, especialment per a grans volums de dades.</li>
<li><strong>Monitoritza i depura</strong>: Utilitza les eines de monitorització de Cloud Dataflow per identificar i solucionar problemes de rendiment.</li>
</ol>
</div><h1><p>Exercici pràctic</p>
</h1>
<div class='content'></div><h2><p>Objectiu:</p>
</h2>
<div class='content'><p>Crear una pipeline que llegeixi dades d'un fitxer CSV, filtri les files amb un valor específic i escrigui els resultats a un altre fitxer CSV.</p>
</div><h2><p>Instruccions:</p>
</h2>
<div class='content'><ol>
<li>Crea un fitxer CSV d'exemple amb dades.</li>
<li>Escriu una pipeline que llegeixi el fitxer, filtri les files i escrigui els resultats.</li>
<li>Executa la pipeline a Cloud Dataflow.</li>
</ol>
</div><h2><p>Solució:</p>
</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGFwYWNoZV9iZWFtIGFzIGJlYW0KZnJvbSBhcGFjaGVfYmVhbS5vcHRpb25zLnBpcGVsaW5lX29wdGlvbnMgaW1wb3J0IFBpcGVsaW5lT3B0aW9ucywgR29vZ2xlQ2xvdWRPcHRpb25zCgojIENvbmZpZ3VyYWNpw7MgZGUgbGVzIG9wY2lvbnMgZGUgbGEgcGlwZWxpbmUKb3B0aW9ucyA9IFBpcGVsaW5lT3B0aW9ucygpCmdvb2dsZV9jbG91ZF9vcHRpb25zID0gb3B0aW9ucy52aWV3X2FzKEdvb2dsZUNsb3VkT3B0aW9ucykKZ29vZ2xlX2Nsb3VkX29wdGlvbnMucHJvamVjdCA9ICdlbC10ZXUtcHJvamVjdGUtZ2NwJwpnb29nbGVfY2xvdWRfb3B0aW9ucy5qb2JfbmFtZSA9ICdmaWx0cmFyLWNzdi1waXBlbGluZScKZ29vZ2xlX2Nsb3VkX29wdGlvbnMudGVtcF9sb2NhdGlvbiA9ICdnczovL2VsLXRldS1idWNrZXQvdGVtcCcKZ29vZ2xlX2Nsb3VkX29wdGlvbnMuc3RhZ2luZ19sb2NhdGlvbiA9ICdnczovL2VsLXRldS1idWNrZXQvc3RhZ2luZycKb3B0aW9ucy52aWV3X2FzKFBpcGVsaW5lT3B0aW9ucykucnVubmVyID0gJ0RhdGFmbG93UnVubmVyJwoKIyBGdW5jacOzIHBlciBmaWx0cmFyIGxlcyBmaWxlcwpkZWYgZmlsdHJhcl9maWxlcyhyb3cpOgogICAgcmV0dXJuICd2YWxvcl9lc3BlY2lmaWMnIGluIHJvdwoKIyBEZWZpbmljacOzIGRlIGxhIHBpcGVsaW5lCndpdGggYmVhbS5QaXBlbGluZShvcHRpb25zPW9wdGlvbnMpIGFzIHA6CiAgICAocAogICAgIHwgJ0xsZWdpciBDU1YnID4+IGJlYW0uaW8uUmVhZEZyb21UZXh0KCdnczovL2VsLXRldS1idWNrZXQvaW5wdXQuY3N2JykKICAgICB8ICdGaWx0cmFyIGZpbGVzJyA+PiBiZWFtLkZpbHRlcihmaWx0cmFyX2ZpbGVzKQogICAgIHwgJ0VzY3JpdXJlIENTVicgPj4gYmVhbS5pby5Xcml0ZVRvVGV4dCgnZ3M6Ly9lbC10ZXUtYnVja2V0L291dHB1dC5jc3YnKSk="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions

# Configuraci&oacute; de les opcions de la pipeline
options = PipelineOptions()
google_cloud_options = options.view_as(GoogleCloudOptions)
google_cloud_options.project = 'el-teu-projecte-gcp'
google_cloud_options.job_name = 'filtrar-csv-pipeline'
google_cloud_options.temp_location = 'gs://el-teu-bucket/temp'
google_cloud_options.staging_location = 'gs://el-teu-bucket/staging'
options.view_as(PipelineOptions).runner = 'DataflowRunner'

# Funci&oacute; per filtrar les files
def filtrar_files(row):
    return 'valor_especific' in row

# Definici&oacute; de la pipeline
with beam.Pipeline(options=options) as p:
    (p
     | 'Llegir CSV' &gt;&gt; beam.io.ReadFromText('gs://el-teu-bucket/input.csv')
     | 'Filtrar files' &gt;&gt; beam.Filter(filtrar_files)
     | 'Escriure CSV' &gt;&gt; beam.io.WriteToText('gs://el-teu-bucket/output.csv'))</pre></div><div class='content'></div><h1><p>Conclusió</p>
</h1>
<div class='content'><p>En aquest tema, hem après què és Cloud Dataflow, com crear i executar pipelines de dades amb Apache Beam, i algunes millors pràctiques per optimitzar el rendiment. Cloud Dataflow és una eina poderosa per al processament de dades en temps real i per lots, i la seva integració amb altres serveis de GCP el fa molt versàtil per a diferents casos d'ús.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='04-01-bigquery' title="BigQuery">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='04-03-cloud-dataproc' title="Cloud Dataproc">Següent &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
