<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introducció a Spark amb Scala</title>

    <link rel="alternate" href="https://campusempresa.com/mod/scala/07-04-introduction-to-spark-with-scala" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/scala/07-04-introduction-to-spark-with-scala" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/scala/07-04-introduction-to-spark-with-scala" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="/js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-12 col-md-8 p-2 p-md-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-12 col-md-4 p-2 p-md-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-2 p-md-0 m-0 text-end">
							<a href="https://enterprisecampus.net/mod/scala/07-04-introduction-to-spark-with-scala" class="px-2">EN</a></b>
				|
				<a href="https://campusempresa.com/mod/scala/07-04-introduction-to-spark-with-scala" class="px-2">ES</a></b>
				|
				<b class="px-2">CA</b>
											</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Projecte</a>
				<a href="/about">Sobre nosaltres</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donacions</a>
				<a href="/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='07-03-introduction-to-play-framework' title="Introducció a Play Framework">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Introducció a Spark amb Scala</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='07-05-best-practices-and-code-style' title="Millors Pràctiques i Estil de Codi">Següent &#x25BA;</a>
			</div>
</div>
<div class='content'><p>Apache Spark és un motor de processament de dades de codi obert que permet processar grans volums de dades de manera ràpida i eficient. Spark és conegut per la seva velocitat i facilitat d'ús, i és àmpliament utilitzat en aplicacions de big data. En aquest tema, aprendrem com utilitzar Spark amb Scala per processar dades.</p>
</div><h1><p>Objectius del Tema</p>
</h1>
<div class='content'><ul>
<li>Entendre què és Apache Spark i les seves característiques principals.</li>
<li>Configurar un projecte Spark amb Scala.</li>
<li>Escriure i executar aplicacions Spark bàsiques.</li>
<li>Treballar amb RDDs (Resilient Distributed Datasets) i DataFrames.</li>
</ul>
</div><h1><ol>
<li>Què és Apache Spark?</li>
</ol>
</h1>
<div class='content'><p>Apache Spark és un motor de processament de dades distribuït que proporciona una interfície per a la programació de clústers complets amb paral·lelisme implícit i tolerància a fallades. Les seves característiques principals inclouen:</p>
<ul>
<li><strong>Velocitat</strong>: Spark pot processar dades a gran velocitat gràcies a la seva capacitat de mantenir dades en memòria.</li>
<li><strong>Facilitat d'ús</strong>: Proporciona APIs senzilles en Scala, Java, Python i R.</li>
<li><strong>Generalitat</strong>: Suporta una àmplia gamma de càrregues de treball, incloent-hi processament de lots, processament de fluxos, i aprenentatge automàtic.</li>
<li><strong>Compatibilitat amb Hadoop</strong>: Pot funcionar independentment o en un clúster Hadoop.</li>
</ul>
</div><h1><ol start="2">
<li>Configuració del Projecte Spark amb Scala</li>
</ol>
</h1>
<div class='content'></div><h2><p>Requisits Previs</p>
</h2>
<div class='content'><ul>
<li>Java Development Kit (JDK) instal·lat.</li>
<li>Apache Spark descarregat i configurat.</li>
<li>SBT (Scala Build Tool) instal·lat.</li>
</ul>
</div><h2><p>Configuració del Projecte</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Crear un nou projecte SBT</strong>:</p>
<pre><code class="language-bash">sbt new scala/scala-seed.g8
</code></pre>
</li>
<li>
<p><strong>Afegir dependències de Spark al fitxer <code>build.sbt</code></strong>:</p>
<pre><code class="language-scala">name := &quot;SparkWithScala&quot;

version := &quot;0.1&quot;

scalaVersion := &quot;2.12.10&quot;

libraryDependencies ++= Seq(
  &quot;org.apache.spark&quot; %% &quot;spark-core&quot; % &quot;3.1.2&quot;,
  &quot;org.apache.spark&quot; %% &quot;spark-sql&quot; % &quot;3.1.2&quot;
)
</code></pre>
</li>
<li>
<p><strong>Compilar el projecte</strong>:</p>
<pre><code class="language-bash">sbt compile
</code></pre>
</li>
</ol>
</div><h1><ol start="3">
<li>Escriure i Executar una Aplicació Spark Bàsica</li>
</ol>
</h1>
<div class='content'></div><h2><p>Exemple: Comptar Paraules</p>
</h2>
<div class='content'><ol>
<li>
<p><strong>Crear un fitxer Scala</strong>:
Crea un fitxer anomenat <code>WordCount.scala</code> dins del directori <code>src/main/scala</code>.</p>
</li>
<li>
<p><strong>Escriure el codi</strong>:</p>
<pre><code class="language-scala">import org.apache.spark.{SparkConf, SparkContext}

object WordCount {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName(&quot;WordCount&quot;).setMaster(&quot;local[*]&quot;)
    val sc = new SparkContext(conf)

    val textFile = sc.textFile(&quot;path/to/textfile.txt&quot;)
    val counts = textFile.flatMap(line =&gt; line.split(&quot; &quot;))
                         .map(word =&gt; (word, 1))
                         .reduceByKey(_ + _)

    counts.saveAsTextFile(&quot;path/to/output&quot;)
  }
}
</code></pre>
</li>
<li>
<p><strong>Executar l'aplicació</strong>:</p>
<pre><code class="language-bash">sbt run
</code></pre>
</li>
</ol>
</div><h1><ol start="4">
<li>Treballar amb RDDs i DataFrames</li>
</ol>
</h1>
<div class='content'></div><h2><p>RDDs (Resilient Distributed Datasets)</p>
</h2>
<div class='content'><p>RDDs són la unitat fonamental de dades en Spark. Són col·leccions distribuïdes d'objectes que es poden processar en paral·lel.</p>
<h4>Exemple: Operacions amb RDDs</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("dmFsIGRhdGEgPSBzYy5wYXJhbGxlbGl6ZShTZXEoMSwgMiwgMywgNCwgNSkpCnZhbCByZXN1bHQgPSBkYXRhLm1hcChfICogMikuY29sbGVjdCgpCnJlc3VsdC5mb3JlYWNoKHByaW50bG4p"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>val data = sc.parallelize(Seq(1, 2, 3, 4, 5))
val result = data.map(_ * 2).collect()
result.foreach(println)</pre></div><div class='content'></div><h2><p>DataFrames</p>
</h2>
<div class='content'><p>DataFrames són col·leccions distribuïdes de dades organitzades en columnes nominals, similars a les taules en bases de dades relacionals.</p>
<h4>Exemple: Operacions amb DataFrames</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgoKdmFsIHNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiRGF0YUZyYW1lRXhhbXBsZSIpLmdldE9yQ3JlYXRlKCkKdmFsIGRmID0gc3BhcmsucmVhZC5qc29uKCJwYXRoL3RvL2pzb25maWxlLmpzb24iKQoKZGYuc2hvdygpCmRmLnByaW50U2NoZW1hKCkKZGYuc2VsZWN0KCJuYW1lIikuc2hvdygpCmRmLmZpbHRlcihkZigiYWdlIikgPiAyMSkuc2hvdygpCmRmLmdyb3VwQnkoImFnZSIpLmNvdW50KCkuc2hvdygp"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession

val spark = SparkSession.builder.appName(&quot;DataFrameExample&quot;).getOrCreate()
val df = spark.read.json(&quot;path/to/jsonfile.json&quot;)

df.show()
df.printSchema()
df.select(&quot;name&quot;).show()
df.filter(df(&quot;age&quot;) &gt; 21).show()
df.groupBy(&quot;age&quot;).count().show()</pre></div><div class='content'></div><h1><p>Exercicis Pràctics</p>
</h1>
<div class='content'></div><h2><p>Exercici 1: Comptar Paraules en un Fitxer de Text</p>
</h2>
<div class='content'><ol>
<li>Escriu una aplicació Spark que llegeixi un fitxer de text i compti el nombre d'ocurrències de cada paraula.</li>
<li>Guarda el resultat en un fitxer de sortida.</li>
</ol>
</div><h2><p>Exercici 2: Operacions amb DataFrames</p>
</h2>
<div class='content'><ol>
<li>Crea un DataFrame a partir d'un fitxer JSON.</li>
<li>Realitza operacions de selecció, filtratge i agrupació sobre el DataFrame.</li>
</ol>
</div><h1><p>Solucions</p>
</h1>
<div class='content'></div><h2><p>Solució a l'Exercici 1</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsue1NwYXJrQ29uZiwgU3BhcmtDb250ZXh0fQoKb2JqZWN0IFdvcmRDb3VudCB7CiAgZGVmIG1haW4oYXJnczogQXJyYXlbU3RyaW5nXSk6IFVuaXQgPSB7CiAgICB2YWwgY29uZiA9IG5ldyBTcGFya0NvbmYoKS5zZXRBcHBOYW1lKCJXb3JkQ291bnQiKS5zZXRNYXN0ZXIoImxvY2FsWypdIikKICAgIHZhbCBzYyA9IG5ldyBTcGFya0NvbnRleHQoY29uZikKCiAgICB2YWwgdGV4dEZpbGUgPSBzYy50ZXh0RmlsZSgicGF0aC90by90ZXh0ZmlsZS50eHQiKQogICAgdmFsIGNvdW50cyA9IHRleHRGaWxlLmZsYXRNYXAobGluZSA9PiBsaW5lLnNwbGl0KCIgIikpCiAgICAgICAgICAgICAgICAgICAgICAgICAubWFwKHdvcmQgPT4gKHdvcmQsIDEpKQogICAgICAgICAgICAgICAgICAgICAgICAgLnJlZHVjZUJ5S2V5KF8gKyBfKQoKICAgIGNvdW50cy5zYXZlQXNUZXh0RmlsZSgicGF0aC90by9vdXRwdXQiKQogIH0KfQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.{SparkConf, SparkContext}

object WordCount {
  def main(args: Array[String]): Unit = {
    val conf = new SparkConf().setAppName(&quot;WordCount&quot;).setMaster(&quot;local[*]&quot;)
    val sc = new SparkContext(conf)

    val textFile = sc.textFile(&quot;path/to/textfile.txt&quot;)
    val counts = textFile.flatMap(line =&gt; line.split(&quot; &quot;))
                         .map(word =&gt; (word, 1))
                         .reduceByKey(_ + _)

    counts.saveAsTextFile(&quot;path/to/output&quot;)
  }
}</pre></div><div class='content'></div><h2><p>Solució a l'Exercici 2</p>
</h2>
<div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuc3Bhcmsuc3FsLlNwYXJrU2Vzc2lvbgoKb2JqZWN0IERhdGFGcmFtZUV4YW1wbGUgewogIGRlZiBtYWluKGFyZ3M6IEFycmF5W1N0cmluZ10pOiBVbml0ID0gewogICAgdmFsIHNwYXJrID0gU3BhcmtTZXNzaW9uLmJ1aWxkZXIuYXBwTmFtZSgiRGF0YUZyYW1lRXhhbXBsZSIpLmdldE9yQ3JlYXRlKCkKICAgIHZhbCBkZiA9IHNwYXJrLnJlYWQuanNvbigicGF0aC90by9qc29uZmlsZS5qc29uIikKCiAgICBkZi5zaG93KCkKICAgIGRmLnByaW50U2NoZW1hKCkKICAgIGRmLnNlbGVjdCgibmFtZSIpLnNob3coKQogICAgZGYuZmlsdGVyKGRmKCJhZ2UiKSA+IDIxKS5zaG93KCkKICAgIGRmLmdyb3VwQnkoImFnZSIpLmNvdW50KCkuc2hvdygpCiAgfQp9"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.spark.sql.SparkSession

object DataFrameExample {
  def main(args: Array[String]): Unit = {
    val spark = SparkSession.builder.appName(&quot;DataFrameExample&quot;).getOrCreate()
    val df = spark.read.json(&quot;path/to/jsonfile.json&quot;)

    df.show()
    df.printSchema()
    df.select(&quot;name&quot;).show()
    df.filter(df(&quot;age&quot;) &gt; 21).show()
    df.groupBy(&quot;age&quot;).count().show()
  }
}</pre></div><div class='content'></div><h1><p>Resum</p>
</h1>
<div class='content'><p>En aquest tema, hem après què és Apache Spark i com configurar un projecte Spark amb Scala. Hem escrit i executat una aplicació Spark bàsica per comptar paraules en un fitxer de text. També hem explorat com treballar amb RDDs i DataFrames, dues de les estructures de dades més importants en Spark. Finalment, hem proporcionat exercicis pràctics per reforçar els conceptes apresos.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='07-03-introduction-to-play-framework' title="Introducció a Play Framework">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='07-05-best-practices-and-code-style' title="Millors Pràctiques i Estil de Codi">Següent &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir cookies per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
