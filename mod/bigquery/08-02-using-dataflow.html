<!DOCTYPE html>
<html lang="ca">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ús de BigQuery amb Dataflow</title>

    <link rel="alternate" href="https://campusempresa.com/mod/bigquery/08-02-using-dataflow" hreflang="es" />
	<link rel="alternate" href="https://campusempresa.cat/mod/bigquery/08-02-using-dataflow" hreflang="ca" />
	<link rel="alternate" href="https://enterprisecampus.net/mod/bigquery/08-02-using-dataflow" hreflang="en" />
    
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons/font/bootstrap-icons.css">
	<link href="/css/site.css" rel="stylesheet">
	
    <script src="https://code.jquery.com/jquery-3.7.1.min.js"></script>
  	<script type="text/javascript" src="js/math_init.js"></script>
  	<script type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/startup.js"></script>
  	<script type="text/javascript" src="/js/cookie.js"></script>
  	<script type="text/javascript" src="/js/main.js"></script>
</head>

<body >
    <div id="content">
		<div id="header" class="container-xxl">
	<div class="row">
		<div class="col-8 p-0">
			<h1 class="m-0 p-0">
				<a href="/"><img src="/img/logo_header.png"></a>
			</h1>
		</div>
		<div class="col-4 p-0 text-end">
			<h2 id="main_title"><cite>Construint la societat d'avui i del demà</cite></h2>
			<h3 id="main_subtitle"></h3>
		</div>
	</div>
</div>
<div class="container-xxl" style="margin-top: -1em;">
	<div class="row">
		<div class="col-12 p-0 m-0 text-end">
							<a href="https://enterprisecampus.net/mod/bigquery/08-02-using-dataflow" class="px-2">EN</a></b>
				|
				<a href="https://campusempresa.com/mod/bigquery/08-02-using-dataflow" class="px-2">ES</a></b>
				|
				<b class="px-2">CA</b>
											</div>
	</div>
</div>
   <div class="top-bar container-fluid">
	<div class="container-xxl">
		<div class="row">
			<div class="col" id="left_menu">
				<a href="/objective">El Projecte</a>
				<a href="/about">Sobre nosaltres</a>
				<a href="/contribute">Contribuir</a>
				<a href="/donate">Donacions</a>
				<a href="/licence">Llicència</a>
			</div>
		</div>
	</div>
   </div>

<div class="container-xxl" id="main_content">
	<div class="row">
		<div class="col-12 col-lg-8">
			<div id="nav1" class="navigation"></div>
			<div id="inner_content">
								<div class='row navigation'>
	<div class='col-2'>
					<a href='08-01-integrating-google-cloud' title="Integració amb serveis de Google Cloud">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
					<a href="./"><h2 style="text-decoration:underline">Ús de BigQuery amb Dataflow</h2></a>
			</div>
	<div class='col-2 text-end'>
					<a href='08-03-automating-workflows' title="Automatització de fluxos de treball amb Cloud Functions">Següent &#x25BA;</a>
			</div>
</div>
<div class='content'></div><h1>Introducció</h1>
<div class='content'><p>Google Cloud Dataflow és un servei de processament de dades en temps real i per lots que permet crear i gestionar canals de dades. Integrar BigQuery amb Dataflow permet processar grans volums de dades de manera eficient i flexible. En aquest tema, aprendrem com utilitzar Dataflow per llegir dades de BigQuery, processar-les i escriure els resultats de nou a BigQuery.</p>
</div><h1>Objectius</h1>
<div class='content'><ul>
<li>Comprendre què és Google Cloud Dataflow i com es pot utilitzar amb BigQuery.</li>
<li>Aprendre a configurar un pipeline de Dataflow per llegir dades de BigQuery.</li>
<li>Processar dades utilitzant Dataflow.</li>
<li>Escriure els resultats processats de nou a BigQuery.</li>
</ul>
</div><h1>Requisits previs</h1>
<div class='content'><ul>
<li>Coneixements bàsics de BigQuery i SQL.</li>
<li>Familiaritat amb Google Cloud Platform (GCP).</li>
<li>Coneixements bàsics de programació en Python o Java (Dataflow suporta ambdós llenguatges).</li>
</ul>
</div><h1>Configuració de l'entorn</h1>
<div class='content'></div><h2>Passos previs</h2>
<div class='content'><ol>
<li><strong>Crear un projecte a Google Cloud Platform (GCP)</strong>: Si encara no tens un projecte a GCP, crea'n un des del <a href="https://console.cloud.google.com/">Google Cloud Console</a>.</li>
<li><strong>Activar l'API de Dataflow i BigQuery</strong>: Assegura't que les APIs de Dataflow i BigQuery estiguin activades al teu projecte.</li>
<li><strong>Instal·lar el SDK de Dataflow</strong>: Pots instal·lar el SDK de Dataflow utilitzant pip (per Python) o Maven (per Java).</li>
</ol>
</div><h2>Instal·lació del SDK de Dataflow (Python)</h2>
<div class='content'></div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cGlwIGluc3RhbGwgYXBhY2hlLWJlYW1bZ2NwXQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>pip install apache-beam[gcp]</pre></div><div class='content'></div><h2>Instal·lació del SDK de Dataflow (Java)</h2>
<div class='content'><p>Afegeix la següent dependència al teu fitxer <code>pom.xml</code>:</p>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("PGRlcGVuZGVuY3k+CiAgPGdyb3VwSWQ+b3JnLmFwYWNoZS5iZWFtPC9ncm91cElkPgogIDxhcnRpZmFjdElkPmJlYW0tc2Rrcy1qYXZhLWNvcmU8L2FydGlmYWN0SWQ+CiAgPHZlcnNpb24+Mi4zNC4wPC92ZXJzaW9uPgo8L2RlcGVuZGVuY3k+CjxkZXBlbmRlbmN5PgogIDxncm91cElkPm9yZy5hcGFjaGUuYmVhbTwvZ3JvdXBJZD4KICA8YXJ0aWZhY3RJZD5iZWFtLXJ1bm5lcnMtZ29vZ2xlLWNsb3VkLWRhdGFmbG93LWphdmE8L2FydGlmYWN0SWQ+CiAgPHZlcnNpb24+Mi4zNC4wPC92ZXJzaW9uPgo8L2RlcGVuZGVuY3k+CjxkZXBlbmRlbmN5PgogIDxncm91cElkPm9yZy5hcGFjaGUuYmVhbTwvZ3JvdXBJZD4KICA8YXJ0aWZhY3RJZD5iZWFtLXNka3MtamF2YS1pby1nb29nbGUtY2xvdWQtcGxhdGZvcm08L2FydGlmYWN0SWQ+CiAgPHZlcnNpb24+Mi4zNC4wPC92ZXJzaW9uPgo8L2RlcGVuZGVuY3k+"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>&lt;dependency&gt;
  &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
  &lt;artifactId&gt;beam-sdks-java-core&lt;/artifactId&gt;
  &lt;version&gt;2.34.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
  &lt;artifactId&gt;beam-runners-google-cloud-dataflow-java&lt;/artifactId&gt;
  &lt;version&gt;2.34.0&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;
  &lt;artifactId&gt;beam-sdks-java-io-google-cloud-platform&lt;/artifactId&gt;
  &lt;version&gt;2.34.0&lt;/version&gt;
&lt;/dependency&gt;</pre></div><div class='content'></div><h1>Creació d'un pipeline de Dataflow</h1>
<div class='content'></div><h2>Exemple en Python</h2>
<div class='content'><p>A continuació, es mostra un exemple de com crear un pipeline de Dataflow en Python que llegeix dades de BigQuery, les processa i escriu els resultats de nou a BigQuery.</p>
<h4>Pas 1: Importar les biblioteques necessàries</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IGFwYWNoZV9iZWFtIGFzIGJlYW0KZnJvbSBhcGFjaGVfYmVhbS5vcHRpb25zLnBpcGVsaW5lX29wdGlvbnMgaW1wb3J0IFBpcGVsaW5lT3B0aW9ucywgR29vZ2xlQ2xvdWRPcHRpb25zLCBTdGFuZGFyZE9wdGlvbnM="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions, GoogleCloudOptions, StandardOptions</pre></div><div class='content'><h4>Pas 2: Configurar les opcions del pipeline</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("b3B0aW9ucyA9IFBpcGVsaW5lT3B0aW9ucygpCmdvb2dsZV9jbG91ZF9vcHRpb25zID0gb3B0aW9ucy52aWV3X2FzKEdvb2dsZUNsb3VkT3B0aW9ucykKZ29vZ2xlX2Nsb3VkX29wdGlvbnMucHJvamVjdCA9ICdlbC10ZXUtcHJvamVjdGUnCmdvb2dsZV9jbG91ZF9vcHRpb25zLmpvYl9uYW1lID0gJ2JpZ3F1ZXJ5LWRhdGFmbG93LWpvYicKZ29vZ2xlX2Nsb3VkX29wdGlvbnMuc3RhZ2luZ19sb2NhdGlvbiA9ICdnczovL2VsLXRldS1idWNrZXQvc3RhZ2luZycKZ29vZ2xlX2Nsb3VkX29wdGlvbnMudGVtcF9sb2NhdGlvbiA9ICdnczovL2VsLXRldS1idWNrZXQvdGVtcCcKb3B0aW9ucy52aWV3X2FzKFN0YW5kYXJkT3B0aW9ucykucnVubmVyID0gJ0RhdGFmbG93UnVubmVyJw=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>options = PipelineOptions()
google_cloud_options = options.view_as(GoogleCloudOptions)
google_cloud_options.project = 'el-teu-projecte'
google_cloud_options.job_name = 'bigquery-dataflow-job'
google_cloud_options.staging_location = 'gs://el-teu-bucket/staging'
google_cloud_options.temp_location = 'gs://el-teu-bucket/temp'
options.view_as(StandardOptions).runner = 'DataflowRunner'</pre></div><div class='content'><h4>Pas 3: Definir el pipeline</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("cCA9IGJlYW0uUGlwZWxpbmUob3B0aW9ucz1vcHRpb25zKQoKcXVlcnkgPSAnU0VMRUNUICogRlJPTSBgZWwtdGV1LXByb2plY3RlLmVsLXRldS1kYXRhc2V0LmxhLXRldmEtdGF1bGFgJwoKKHAKIHwgJ1JlYWRGcm9tQmlnUXVlcnknID4+IGJlYW0uaW8uUmVhZChiZWFtLmlvLkJpZ1F1ZXJ5U291cmNlKHF1ZXJ5PXF1ZXJ5KSkKIHwgJ1Byb2Nlc3NEYXRhJyA+PiBiZWFtLk1hcChsYW1iZGEgcmVjb3JkOiB7J2ZpZWxkMSc6IHJlY29yZFsnZmllbGQxJ10sICdmaWVsZDInOiByZWNvcmRbJ2ZpZWxkMiddICogMn0pCiB8ICdXcml0ZVRvQmlnUXVlcnknID4+IGJlYW0uaW8uV3JpdGVUb0JpZ1F1ZXJ5KAogICAgICdlbC10ZXUtcHJvamVjdGU6ZWwtdGV1LWRhdGFzZXQucmVzdWx0YXRzJywKICAgICBzY2hlbWE9J2ZpZWxkMTpTVFJJTkcsIGZpZWxkMjpJTlRFR0VSJywKICAgICB3cml0ZV9kaXNwb3NpdGlvbj1iZWFtLmlvLkJpZ1F1ZXJ5RGlzcG9zaXRpb24uV1JJVEVfVFJVTkNBVEUpCikKCnAucnVuKCkud2FpdF91bnRpbF9maW5pc2goKQ=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>p = beam.Pipeline(options=options)

query = 'SELECT * FROM `el-teu-projecte.el-teu-dataset.la-teva-taula`'

(p
 | 'ReadFromBigQuery' &gt;&gt; beam.io.Read(beam.io.BigQuerySource(query=query))
 | 'ProcessData' &gt;&gt; beam.Map(lambda record: {'field1': record['field1'], 'field2': record['field2'] * 2})
 | 'WriteToBigQuery' &gt;&gt; beam.io.WriteToBigQuery(
     'el-teu-projecte:el-teu-dataset.resultats',
     schema='field1:STRING, field2:INTEGER',
     write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE)
)

p.run().wait_until_finish()</pre></div><div class='content'></div><h2>Exemple en Java</h2>
<div class='content'><p>A continuació, es mostra un exemple de com crear un pipeline de Dataflow en Java que llegeix dades de BigQuery, les processa i escriu els resultats de nou a BigQuery.</p>
<h4>Pas 1: Importar les biblioteques necessàries</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("aW1wb3J0IG9yZy5hcGFjaGUuYmVhbS5zZGsuUGlwZWxpbmU7CmltcG9ydCBvcmcuYXBhY2hlLmJlYW0uc2RrLmlvLmdjcC5iaWdxdWVyeS5CaWdRdWVyeUlPOwppbXBvcnQgb3JnLmFwYWNoZS5iZWFtLnNkay5vcHRpb25zLlBpcGVsaW5lT3B0aW9uc0ZhY3Rvcnk7CmltcG9ydCBvcmcuYXBhY2hlLmJlYW0uc2RrLm9wdGlvbnMuUGlwZWxpbmVPcHRpb25zOwppbXBvcnQgb3JnLmFwYWNoZS5iZWFtLnNkay50cmFuc2Zvcm1zLk1hcEVsZW1lbnRzOwppbXBvcnQgb3JnLmFwYWNoZS5iZWFtLnNkay50cmFuc2Zvcm1zLlNpbXBsZUZ1bmN0aW9uOwppbXBvcnQgb3JnLmFwYWNoZS5iZWFtLnNkay52YWx1ZXMuVHlwZURlc2NyaXB0b3I7"))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>import org.apache.beam.sdk.Pipeline;
import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;
import org.apache.beam.sdk.options.PipelineOptionsFactory;
import org.apache.beam.sdk.options.PipelineOptions;
import org.apache.beam.sdk.transforms.MapElements;
import org.apache.beam.sdk.transforms.SimpleFunction;
import org.apache.beam.sdk.values.TypeDescriptor;</pre></div><div class='content'><h4>Pas 2: Configurar les opcions del pipeline</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("UGlwZWxpbmVPcHRpb25zIG9wdGlvbnMgPSBQaXBlbGluZU9wdGlvbnNGYWN0b3J5LmZyb21BcmdzKGFyZ3MpLndpdGhWYWxpZGF0aW9uKCkuY3JlYXRlKCk7Cm9wdGlvbnMuc2V0Sm9iTmFtZSgiYmlncXVlcnktZGF0YWZsb3ctam9iIik7Cm9wdGlvbnMuc2V0UHJvamVjdCgiZWwtdGV1LXByb2plY3RlIik7Cm9wdGlvbnMuc2V0VGVtcExvY2F0aW9uKCJnczovL2VsLXRldS1idWNrZXQvdGVtcCIpOw=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>PipelineOptions options = PipelineOptionsFactory.fromArgs(args).withValidation().create();
options.setJobName(&quot;bigquery-dataflow-job&quot;);
options.setProject(&quot;el-teu-projecte&quot;);
options.setTempLocation(&quot;gs://el-teu-bucket/temp&quot;);</pre></div><div class='content'><h4>Pas 3: Definir el pipeline</h4>
</div><div style='position:relative'><a class='copy_button' href='#' onclick='navigator.clipboard.writeText(decodeURIComponent(escape(atob("UGlwZWxpbmUgcCA9IFBpcGVsaW5lLmNyZWF0ZShvcHRpb25zKTsKClN0cmluZyBxdWVyeSA9ICJTRUxFQ1QgKiBGUk9NIGBlbC10ZXUtcHJvamVjdGUuZWwtdGV1LWRhdGFzZXQubGEtdGV2YS10YXVsYWAiOwoKcC5hcHBseSgiUmVhZEZyb21CaWdRdWVyeSIsIEJpZ1F1ZXJ5SU8ucmVhZFRhYmxlUm93cygpLmZyb21RdWVyeShxdWVyeSkudXNpbmdTdGFuZGFyZFNxbCgpKQogLmFwcGx5KCJQcm9jZXNzRGF0YSIsIE1hcEVsZW1lbnRzLmludG8oVHlwZURlc2NyaXB0b3Iub2YoVGFibGVSb3cuY2xhc3MpKQogICAgIC52aWEoKFRhYmxlUm93IHJvdykgLT4gewogICAgICAgICBUYWJsZVJvdyByZXN1bHQgPSBuZXcgVGFibGVSb3coKTsKICAgICAgICAgcmVzdWx0LnNldCgiZmllbGQxIiwgcm93LmdldCgiZmllbGQxIikpOwogICAgICAgICByZXN1bHQuc2V0KCJmaWVsZDIiLCAoTG9uZykgcm93LmdldCgiZmllbGQyIikgKiAyKTsKICAgICAgICAgcmV0dXJuIHJlc3VsdDsKICAgICB9KSkKIC5hcHBseSgiV3JpdGVUb0JpZ1F1ZXJ5IiwgQmlnUXVlcnlJTy53cml0ZVRhYmxlUm93cygpCiAgICAgLnRvKCJlbC10ZXUtcHJvamVjdGU6ZWwtdGV1LWRhdGFzZXQucmVzdWx0YXRzIikKICAgICAud2l0aFNjaGVtYShuZXcgVGFibGVTY2hlbWEoKS5zZXRGaWVsZHMoQXJyYXlzLmFzTGlzdCgKICAgICAgICAgbmV3IFRhYmxlRmllbGRTY2hlbWEoKS5zZXROYW1lKCJmaWVsZDEiKS5zZXRUeXBlKCJTVFJJTkciKSwKICAgICAgICAgbmV3IFRhYmxlRmllbGRTY2hlbWEoKS5zZXROYW1lKCJmaWVsZDIiKS5zZXRUeXBlKCJJTlRFR0VSIikKICAgICApKSkKICAgICAud2l0aFdyaXRlRGlzcG9zaXRpb24oQmlnUXVlcnlJTy5Xcml0ZS5Xcml0ZURpc3Bvc2l0aW9uLldSSVRFX1RSVU5DQVRFKSk7CgpwLnJ1bigpLndhaXRVbnRpbEZpbmlzaCgpOw=="))));alert("Copiat!");return false;'><i class='bi bi-copy'></i></a><pre class='code'>Pipeline p = Pipeline.create(options);

String query = &quot;SELECT * FROM `el-teu-projecte.el-teu-dataset.la-teva-taula`&quot;;

p.apply(&quot;ReadFromBigQuery&quot;, BigQueryIO.readTableRows().fromQuery(query).usingStandardSql())
 .apply(&quot;ProcessData&quot;, MapElements.into(TypeDescriptor.of(TableRow.class))
     .via((TableRow row) -&gt; {
         TableRow result = new TableRow();
         result.set(&quot;field1&quot;, row.get(&quot;field1&quot;));
         result.set(&quot;field2&quot;, (Long) row.get(&quot;field2&quot;) * 2);
         return result;
     }))
 .apply(&quot;WriteToBigQuery&quot;, BigQueryIO.writeTableRows()
     .to(&quot;el-teu-projecte:el-teu-dataset.resultats&quot;)
     .withSchema(new TableSchema().setFields(Arrays.asList(
         new TableFieldSchema().setName(&quot;field1&quot;).setType(&quot;STRING&quot;),
         new TableFieldSchema().setName(&quot;field2&quot;).setType(&quot;INTEGER&quot;)
     )))
     .withWriteDisposition(BigQueryIO.Write.WriteDisposition.WRITE_TRUNCATE));

p.run().waitUntilFinish();</pre></div><div class='content'></div><h1>Exercici pràctic</h1>
<div class='content'></div><h2>Descripció</h2>
<div class='content'><p>Crea un pipeline de Dataflow que llegeixi dades d'una taula de BigQuery, realitzi una transformació simple (per exemple, multiplicar un camp numèric per 2) i escrigui els resultats en una nova taula de BigQuery.</p>
</div><h2>Solució</h2>
<div class='content'><p>La solució es troba en els exemples de codi proporcionats anteriorment. Pots adaptar-los segons les teves necessitats específiques.</p>
</div><h1>Errors comuns i consells</h1>
<div class='content'><ul>
<li><strong>Error de permisos</strong>: Assegura't que el compte de servei que utilitza Dataflow tingui els permisos necessaris per accedir a BigQuery i als buckets de Google Cloud Storage.</li>
<li><strong>Especificació incorrecta del runner</strong>: Si estàs provant el pipeline localment, utilitza <code>DirectRunner</code> en lloc de <code>DataflowRunner</code>.</li>
<li><strong>Esquema incorrecte</strong>: Assegura't que l'esquema de la taula de destinació a BigQuery coincideixi amb les dades que estàs escrivint.</li>
</ul>
</div><h1>Conclusió</h1>
<div class='content'><p>Integrar BigQuery amb Dataflow permet processar grans volums de dades de manera eficient i flexible. En aquest tema, hem après a configurar un pipeline de Dataflow per llegir dades de BigQuery, processar-les i escriure els resultats de nou a BigQuery. Aquesta habilitat és essencial per a qualsevol professional que treballi amb grans volums de dades i necessiti processar-les de manera eficient.</p>
</div><div class='row navigation'>
	<div class='col-2'>
					<a href='08-01-integrating-google-cloud' title="Integració amb serveis de Google Cloud">&#x25C4;Anterior</a>
			</div>
	<div class='col-8 text-center'>
			</div>
	<div class='col-2 text-end'>
					<a href='08-03-automating-workflows' title="Automatització de fluxos de treball amb Cloud Functions">Següent &#x25BA;</a>
			</div>
</div>

			</div>
		</div>
		<div class="col-12 col-lg-4 publi" id="div_publi">
			<h1>Publicitat</h1>
			<p>Aquest espai està destinat a publicitat.</p>
			<p>Si vols ser patrocinador, contacta amb nosaltres per incloure enllaços en aquesta zona: <a href='mailto:admin@campusempresa.cat'>admin@campusempresa.cat</a></p>
			<p>Gràcies per col·laborar!</p>
		</div>
	</div>
</div>

   <div class="container-xxl my-3">
	<div class="row">
		<div class="col">
			<footer>&copy; Copyright 2024. Tots els drets reservats</footer>
		</div>
	</div>
</div>	

<div id="cookies_adv" style="display:none;">
	Fem servir galetes per millorar la teva experiència d'ús i oferir continguts adaptats als teus interessos
    <a href="#" id="btn_accept_cookies" class="button">Acceptar</a>
    <a href="/cookies">Més informació</a>
</div>	

	</div>    
</body>
</html>
